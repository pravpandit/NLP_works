{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5bcee9-6588-4d29-bbb9-6fb351ef6630",
   "metadata": {},
   "source": [
    "# अध्याय 2 भाषा मॉडल, प्रश्नोत्तरी प्रतिमान और टोकन\n",
    "\n",
    "- [आई. पर्यावरण विन्यास](#आई. पर्यावरण विन्यास)\n",
    "- [1.1 एपीआई कुंजी और कुछ पायथन लाइब्रेरीज़ लोड हो रही है।)\n",
    "- [1.2 हेल्पर फ़ंक्शन सहायक फ़ंक्शन](#1.2-हेल्पर-फ़ंक्शन-सहायक फ़ंक्शन)\n",
    "- [II. मॉडल से प्रश्न पूछने का प्रयास करें और परिणाम प्राप्त करें](#II. मॉडल से प्रश्न पूछने का प्रयास करें और परिणाम प्राप्त करें)\n",
    "- [III. टोकन](#III. टोकन)\n",
    "- [IV. सहायक कार्य सहायक कार्य (प्रश्न)tioning प्रतिमान)](#IV। सहायक-कार्य-सहायक कार्य-(प्रश्न प्रतिमान))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf0c21",
   "metadata": {},
   "source": [
    "इस अध्याय में, हम आपके साथ साझा करेंगे कि बड़े भाषा मॉडल (एलएलएम) कैसे काम करते हैं, उन्हें कैसे प्रशिक्षित किया जाता है, और टोकनाइज़र जैसे विवरण एलएलएम आउटपुट को कैसे प्रभावित करते हैं। हम एलएलएम के चैट प्रारूप, सिस्टम संदेशों और उपयोगकर्ता संदेशों को निर्दिष्ट करने का एक तरीका भी पेश करेंगे , और आपको दिखाएंगे कि इस क्षमता का लाभ कैसे उठाया जाए।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797991-8486-4d79-8c1d-5dc0c1289c2f",
   "metadata": {},
   "source": [
    "## 1. पर्यावरण विन्यास"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33004b0",
   "metadata": {},
   "source": [
    "### 1.1 एपीआई कुंजी और कुछ पायथन लाइब्रेरी लोड हो रही है।\n",
    "इस कोर्स में, आपको OpenAI API कुंजी लोड करने के लिए कुछ कोड प्रदान किए जाते हैं।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cd4e96",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# आयात टिकटोकन इसका बाद में उपयोग नहीं किया जाएगा। यदि आप इसके उपयोग में रुचि रखते हैं, तो आप संबंधित सामग्री के लिए इस लेख को देख सकते हैं: https://zhuanlan.zhihu.com/p/629776230\n",
    "\n",
    "# dotenv से आयात करेंload_dotenv, ढूंढें_dotenv\n",
    "# _ =load_dotenv(find_dotenv()) # स्थानीय .env पर्यावरण फ़ाइल पढ़ें (भविष्य में इस पद्धति का उपयोग करने और अपनी कुंजी की सुरक्षा के लिए कुंजी को .env फ़ाइल में डालने की अनुशंसा की जाती है)\n",
    "\n",
    "openai.api_key  = 'sk-***' # 更换成您自己的key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba0938-7ca5-46c4-a9d1-b55708d4dc7c",
   "metadata": {},
   "source": [
    "### 1.2 सहायक कार्य\n",
    "यदि आपने पहले \"चैटजीपीटी प्रॉम्प्ट इंजीनियरिंग फॉर डेवलपर्स\" पाठ्यक्रम लिया है, तो आप इससे अपेक्षाकृत परिचित होंगे।\n",
    "इस फ़ंक्शन को कॉल करें और प्रॉम्प्ट दर्ज करें, और यह संबंधित पूर्णता देगा।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed96988",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# आधिकारिक दस्तावेज़ लेखन https://platform.openai.com/overview\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    使用 OpenAI 的模型生成聊天回复。\n",
    "\n",
    "    参数:\n",
    "    prompt: 用户的输入，即聊天的提示。\n",
    "    model: 使用的模型，默认为\"gpt-3.5-turbo\"。\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"] # 模型生成的回复"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a390-2461-447d-bf8b-8498db404c44",
   "metadata": {},
   "source": [
    "## 2. मॉडल प्रश्न पूछने और परिणाम प्राप्त करने का प्रयास करें"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50317bec",
   "metadata": {},
   "source": [
    "एलएलएम पर्यवेक्षित शिक्षण का उपयोग करके बनाया जा सकता है, जहां वे बार-बार अगले शब्द की भविष्यवाणी करके सीखते हैं और, एक बड़े प्रशिक्षण सेट, दसियों अरबों या अधिक शब्दों को देखते हुए, आप एक बड़े पैमाने पर प्रशिक्षण सेट बना सकते हैं जहां आप एक वाक्य से शुरू करते हैं। किसी पाठ का भाग और बार-बार भाषा मॉडल से यह अनुमान लगाना सीखें कि अगला शब्द क्या है।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325afca0",
   "metadata": {},
   "source": [
    "एलएलएम के दो मुख्य प्रकार हैं: बेस एलएलएम और इंस्ट्रक्शन ट्यून्ड एलएलएम, जो तेजी से लोकप्रिय हो रहे हैं। बेस एलएलएम को बार-बार अगले शब्द की भविष्यवाणी करके प्रशिक्षित किया जाता है, इसलिए यदि हम इसे एक संकेत देते हैं जैसे \"एक बार एक गेंडा था,\"। \"यह शब्द दर शब्द भविष्यवाणी करके एक जादुई जंगल में अपने अन्य गेंडा दोस्तों के साथ गेंडा के जीवन के बारे में एक कहानी को पूरा करने में सक्षम हो सकता है।\n",
    "\n",
    "हालाँकि, इस दृष्टिकोण का नकारात्मक पक्ष यह है कि यदि आप इसे \"चीन की राजधानी क्या है?\" जैसा संकेत देते हैं, तो यह'संभावना है कि इसके डेटा में इंटरनेट से चीन के बारे में प्रश्नोत्तरी प्रश्नों की एक सूची है, इस बिंदु पर, यह इस प्रश्न का उत्तर दे सकता है कि \"चीन का सबसे बड़ा शहर कौन सा है? चीन की जनसंख्या कितनी है?\" लेकिन वास्तव में, आप केवल यह जानना चाहते हैं कि चीन की राजधानी क्या है, इन सभी प्रश्नों को सूचीबद्ध नहीं करना है, हालांकि, एक इंस्ट्रक्शन ट्यून्ड एलएलएम संकेत का पालन करने और उत्तर देने का प्रयास करेगा \"चीन की राजधानी बीजिंग है।\"\n",
    "\n",
    "तो आप बेस एलएलएम को इंस्ट्रक्शन ट्यून्ड एलएलएम में कैसे बदल सकते हैं?यह एक इंस्ट्रक्शन ट्यून्ड एलएलएम (जैसे चैटजीपीटी) को प्रशिक्षित करने की प्रक्रिया है, सबसे पहले, आपको बेस एलएलएम को बहुत सारे डेटा पर प्रशिक्षित करने की आवश्यकता है, इसलिए आपको सैकड़ों अरब शब्दों की आवश्यकता है, या इससे भी अधिक बड़े सुपरकंप्यूटिंग सिस्टम। बेस भाषा मॉडल को प्रशिक्षित करने के बाद, आप इसे मॉडल के आउटपुट को इनपुट से मेल खाने के लिए उदाहरणों के एक छोटे सेट पर प्रशिक्षित करते हैं। उदाहरण के लिए, आप एक ठेकेदार से निर्देशों के कई उदाहरण लिखने और मॉडल को प्रशिक्षित करने में मदद करने के लिए कह सकते हैं कोर परयह उन निर्देशों के प्रति प्रतिक्रियाएँ जोड़ता है। यह फ़ाइन-ट्यूनिंग के लिए एक प्रशिक्षण सेट बनाता है, जहाँ मॉडल निर्देशों का पालन करते समय अगले शब्द की भविष्यवाणी करना सीखता है।\n",
    "\n",
    "बाद में, भाषा मॉडल आउटपुट की गुणवत्ता में सुधार करने के लिए, एक सामान्य दृष्टिकोण यह है कि मनुष्य कई अलग-अलग आउटपुट को रेट करें, जैसे कि उपयोगी, सच्चा, हानिरहित, आदि। फिर आप उच्च रेटिंग उत्पन्न करने की संभावना बढ़ाने के लिए भाषा मॉडल को और अधिक ट्यून कर सकते हैं। आउटपुट। यह अक्सर सुदृढीकरण सीखने वाली मानव प्रतिक्रिया (आरएलएचएफ) का उपयोग करके किया जाता है।तकनीकें। एक आधार भाषा मॉडल को प्रशिक्षित करने में लगने वाले महीनों की तुलना में, छोटे डेटासेट और कंप्यूटिंग संसाधनों का उपयोग करके, एक आधार भाषा मॉडल से एक निर्देश-सुसंस्कृत भाषा मॉडल में संक्रमण में केवल कुछ दिन लग सकते हैं।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1cc57b2",
   "metadata": {
    "height": 72
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of China is Beijing.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"What is the capital of China?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f34f3b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是北京。\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"中国的首都是哪里？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d4e38-3e3c-4c5a-a949-040a27f29d63",
   "metadata": {},
   "source": [
    "##टोकन"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76233527",
   "metadata": {},
   "source": [
    "एलएलएम के अब तक के विवरण में, हमने इसे एक समय में एक शब्द की भविष्यवाणी के रूप में वर्णित किया है, लेकिन वास्तव में एक अधिक महत्वपूर्ण तकनीकी विवरण है, **`एलएलएम वास्तव में अगले शब्द की बार-बार भविष्यवाणी नहीं करता है, बल्कि बार-बार भविष्यवाणी करता है अगला टोकन`**। जब एलएलएम इनपुट प्राप्त करता है, तो यह इसे टोकन की एक श्रृंखला में परिवर्तित करता है, जहां प्रत्येक टोकन वर्णों के एक सामान्य अनुक्रम का प्रतिनिधित्व करता है, उदाहरण के लिए, वाक्य के लिए \"नई चीजें सीखना मजेदार है!\", प्रत्येक शब्द में परिवर्तित हो जाता है एक टोकन, और कम आम के लिएजैसे शब्द \"प्रॉम्पटिंग को शक्तिशाली डेवलपर टूल के रूप में\", \"प्रॉम्पटिंग\" शब्द को तीन टोकन में विभाजित किया गया है, अर्थात् \"प्रोम\", \"पीटी\", और \"आईएनजी\"।\n",
    "\n",
    "जब आप ChatGPT को \"लॉलीपॉप\" के अक्षरों को उलटने के लिए कहते हैं, तो ChatGPT को अक्षरों का सही क्रम आउटपुट करने में कठिनाई होती है क्योंकि टोकनाइज़र \"लॉलीपॉप\" को तीन टोकन में तोड़ देता है, अर्थात् \"l\", \"oll\", \"ipop\"। चैटजीपीटी किसी शब्द के प्रत्येक अक्षर को बेहतर ढंग से पहचानता है और अक्षरों के बीच हाइफ़न या रिक्त स्थान जोड़कर उन्हें सही ढंग से आउटपुट करता है ताकि टोकननाइज़रप्रत्येक अक्षर को अलग-अलग टोकन में तोड़ता है.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc2d9e40",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "# प्रभाव को बेहतर ढंग से प्रदर्शित करने के लिए, यहां कोई संकेत चीनी भाषा में अनुवादित नहीं किया गया है\n",
    "# ध्यान दें कि यहां अक्षर फ़्लिप करना गलत है। एंड्रयू एनजी इस उदाहरण का उपयोग यह समझाने के लिए करते हैं कि टोकन की गणना कैसे की जाती है।\n",
    "response = get_completion(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b14d0-749d-4a79-9812-7b00ace9ae6f",
   "metadata": {},
   "source": [
    "\"लॉलीपॉप\" का उल्टा \"पोपिलोल\" होना चाहिए"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37cab84f",
   "metadata": {
    "height": 88
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6cb95",
   "metadata": {},
   "source": [
    "![Tokens.png](../../figures/Tokens.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46bc72",
   "metadata": {},
   "source": [
    "अंग्रेजी इनपुट के लिए, एक टोकन आम तौर पर 4 अक्षरों या एक शब्द के तीन चौथाई से मेल खाता है; चीनी इनपुट के लिए, एक टोकन आम तौर पर एक या आधे शब्द से मेल खाता है।\n",
    "\n",
    "विभिन्न मॉडलों में अलग-अलग टोकन सीमाएं होती हैं। यह ध्यान दिया जाना चाहिए कि यहां टोकन सीमा इनपुट प्रॉम्प्ट और आउटपुट पूर्णता टोकन का योग है। इसलिए, इनपुट प्रॉम्प्ट जितना लंबा होगा, आउटपुट की पूर्णता की ऊपरी सीमा उतनी ही कम होगी।\n",
    "\n",
    "ChatGPT3.5-टर्बो की टोकन ऊपरी सीमा 4096 है।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b88940-d3ab-4c00-b5c0-31531deaacbd",
   "metadata": {},
   "source": [
    "## 4. सहायक कार्य (प्रश्न प्रतिमान)\n",
    "पाठ्यक्रम में प्रयुक्त सहायक कार्य निम्नलिखित हैं।\n",
    "निम्नलिखित आंकड़ा ओपनएआई द्वारा प्रदान किया गया एक प्रतिमान है। इसके बाद, श्री एंड्रयू एनजी दर्शाते हैं कि बेहतर प्रश्न पूछने के लिए इस प्रतिमान का उपयोग कैसे किया जाए\n",
    "![Chat-format.png](../../figures/Chat-format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b6b3d",
   "metadata": {},
   "source": [
    "सिस्टम जानकारी का उपयोग मॉडल के नियमों को निर्दिष्ट करने के लिए किया जाता है, जैसे सेटिंग्स और उत्तर मानदंड, जबकि सहायक जानकारी मॉडल को पूरा करने के लिए विशिष्ट निर्देश है।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f89efad",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    '''\n",
    "    封装一个支持更多参数的自定义访问 OpenAI GPT3.5 的函数\n",
    "\n",
    "    参数: \n",
    "    messages: 这是一个消息列表，每个消息都是一个字典，包含 role(角色）和 content(内容)。角色可以是'system'、'user' 或 'assistant’，内容是角色的消息。\n",
    "    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4\n",
    "    temperature: 这决定模型输出的随机程度，默认为0，表示输出将非常确定。增加温度会使输出更随机。\n",
    "    max_tokens: 这决定模型输出的最大的 token 数。\n",
    "    '''\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # 这决定模型输出的随机程度\n",
    "        max_tokens=max_tokens, # 这决定模型输出的最大的 token 数\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28c3424",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden so bright, a carrot would sprout,\n",
      "With a cheery orange hue, without a doubt.\n",
      "With a leafy green top, it danced in the breeze,\n",
      "A happy carrot, so eager to please.\n",
      "\n",
      "It grew in the soil, oh so deep and grand,\n",
      "Stretching its roots, reaching far and expand.\n",
      "With a joyful smile, it soaked up the sun,\n",
      "Growing tall and strong, its journey begun.\n",
      "\n",
      "Days turned to weeks, as it grew day and night,\n",
      "Round and plump, it was quite a delight.\n",
      "With every raindrop that fell from above,\n",
      "The carrot grew sweeter, spreading more love.\n",
      "\n",
      "At last, the day came when it was time to eat,\n",
      "With a grin on my face, I took a seat.\n",
      "I chopped and I sliced, so grateful, you see,\n",
      "For this happy carrot, bringing joy to me.\n",
      "\n",
      "So let us remember, when times may get tough,\n",
      "A happy carrot's journey, it's enough.\n",
      "For even in darkness, there's always delight,\n",
      "Just like a carrot, shining so bright.\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d0ef08f",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在海洋的深处，有一只小鲸鱼，\n",
      "她快乐又聪明，灵感从不匮乏。\n",
      "她游遍五大洲，探索未知的秘密，\n",
      "用歌声传递喜悦，令人心旷神怡。\n",
      "\n",
      "她跃出海面，高高的飞翔，\n",
      "尾巴抽空着水花，像梦幻般的画。\n",
      "她和海豚一起，跳跃在太阳下，\n",
      "与海洋中的生命，在欢乐中共舞。\n",
      "\n",
      "她喜欢和海龟一起，缓缓漫游，\n",
      "看美丽的珊瑚，和色彩鲜艳的鱼群。\n",
      "她欢迎每个新朋友，无论大或小，\n",
      "因为在她眼中，每个人都独特而珍贵。\n",
      "\n",
      "她知道快乐是如此简单，如此宝贵，\n",
      "在每个时刻中，她都努力传达幸福的表情。\n",
      "所以当你感到疲惫，沮丧或者低落，\n",
      "想起小鲸鱼的快乐，让你心中再次充满鲜活。\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':'你是一个助理， 并以 Seuss 苏斯博士的风格作出回答。'},    \n",
    "{'role':'user', \n",
    " 'content':'就快乐的小鲸鱼为主题给我写一首短诗'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c6978d",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Charlie who always brightened everyone's day with his vibrant orange color and contagious laughter.\n"
     ]
    }
   ],
   "source": [
    "# लंबाई\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'All your responses must be \\\n",
    "one sentence long.'},    \n",
    "{'role':'user',\n",
    " 'content':'write me a story about a happy carrot'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e34c399e",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在追随波浪的起伏中，小鲸鱼快乐地跳跃着，因为它知道游泳的真正乐趣不仅仅在目的地，而是在于享受整个旅程。\n"
     ]
    }
   ],
   "source": [
    "#लंबाई नियंत्रण\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'你的所有答复只能是一句话'},    \n",
    "{'role':'user',\n",
    " 'content':'写一个关于快乐的小鲸鱼的故事'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14fd6331",
   "metadata": {
    "height": 217
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a carrot so happy and bright, it danced and sang from morning till night.\n"
     ]
    }
   ],
   "source": [
    "#संयुक्त\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who \\\n",
    "responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n",
    "] \n",
    "response = get_completion_from_messages(messages, \n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ca678de",
   "metadata": {
    "height": 181
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在蓝色的大海里，有一只小鲸鱼，无忧无虑，快乐游泳，一切因快乐而变得光辉。\n"
     ]
    }
   ],
   "source": [
    "# उपरोक्त का संयोजन\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'你是一个助理， 并以 Seuss 苏斯博士的风格作出回答，只回答一句话'},    \n",
    "{'role':'user',\n",
    " 'content':'写一个关于快乐的小鲸鱼的故事'},\n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a70c79",
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-3.5-turbo\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \"\"\"\n",
    "    使用 OpenAI 的 GPT-3 模型生成聊天回复，并返回生成的回复内容以及使用的 token 数量。\n",
    "\n",
    "    参数:\n",
    "    messages: 聊天消息列表。\n",
    "    model: 使用的模型名称。默认为\"gpt-3.5-turbo\"。\n",
    "    temperature: 控制生成回复的随机性。值越大，生成的回复越随机。默认为 0。\n",
    "    max_tokens: 生成回复的最大 token 数量。默认为 500。\n",
    "\n",
    "    返回:\n",
    "    content: 生成的回复内容。\n",
    "    token_dict: 包含'prompt_tokens'、'completion_tokens'和'total_tokens'的字典，分别表示提示的 token 数量、生成的回复的 token 数量和总的 token 数量。\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "'completion_tokens':response['usage']['completion_tokens'],\n",
    "'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a64cf3c6",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden so bright, with colors so cheery,\n",
      "There lived a carrot, oh so merry!\n",
      "With a vibrant orange hue, and a leafy green top,\n",
      "This happy carrot just couldn't stop.\n",
      "\n",
      "It danced in the breeze, with a joyful sway,\n",
      "Spreading happiness throughout the day.\n",
      "With a smile so wide, and eyes full of glee,\n",
      "This carrot was as happy as can be.\n",
      "\n",
      "It loved the sunshine, and the rain's gentle touch,\n",
      "Growing tall and strong, oh so much!\n",
      "From the earth it sprouted, reaching for the sky,\n",
      "A happy carrot, oh my, oh my!\n",
      "\n",
      "So if you're feeling down, just remember this tale,\n",
      "Of a carrot so happy, it'll never fail.\n",
      "Find joy in the little things, and let your heart sing,\n",
      "Just like that carrot, oh what joy it will bring!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who responds\\\n",
    " in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem \\ \n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfd8fbd4",
   "metadata": {
    "height": 146
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':'你是一个助理， 并以 Seuss 苏斯博士的风格作出回答。'},    \n",
    "{'role':'user', \n",
    " 'content':'就快乐的小鲸鱼为主题给我写一首短诗'},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "352ad320",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 37, 'completion_tokens': 173, 'total_tokens': 210}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f65685",
   "metadata": {},
   "source": [
    "अंत में, हमारा मानना ​​​​है कि एआई एप्लिकेशन विकास पर प्रॉम्प्ट के क्रांतिकारी प्रभाव को अभी भी कम सराहा गया है, पारंपरिक पर्यवेक्षित मशीन लर्निंग वर्कफ़्लो में, यदि आप एक क्लासिफायरियर बनाना चाहते हैं जो रेस्तरां समीक्षाओं को सकारात्मक या नकारात्मक के रूप में वर्गीकृत कर सकता है, तो आपको पहले एक बड़ा प्राप्त करना होगा। लेबल किए गए डेटा की मात्रा, शायद उनमें से सैकड़ों, और इस प्रक्रिया में सप्ताह या एक महीना भी लग सकता है, फिर आपको इस डेटा पर एक मॉडल को प्रशिक्षित करने, एक उपयुक्त ओपन सोर्स मॉडल ढूंढने और मॉडल ट्यूनिंग करने की आवश्यकता हैमूल्यांकन, जिसमें दिन, सप्ताह या महीने भी लग सकते हैं, अंत में, आपको मॉडल को तैनात करने, मॉडल को क्लाउड पर अपलोड करने और अंततः अपने मॉडल को कॉल करने से पहले इसे चलाने की आवश्यकता हो सकती है इसे पूरा करने में एक टीम को कई महीने लग जाते हैं।\n",
    "\n",
    "इसके विपरीत, प्रॉम्प्ट-आधारित मशीन लर्निंग दृष्टिकोण के साथ, जब आपके पास एक टेक्स्ट एप्लिकेशन होता है, तो आप बस एक साधारण प्रॉम्प्ट प्रदान करते हैं। इस प्रक्रिया में केवल कुछ मिनट या अधिकतम कुछ घंटे लग सकते हैं यदि इसमें कई पुनरावृत्तियाँ लगती हैंएक वैध संकेत। कुछ दिनों के भीतर (हालांकि व्यवहार में यह आमतौर पर कुछ घंटों का होता है), आप एपीआई कॉल के माध्यम से मॉडल चला सकते हैं और इसका उपयोग शुरू कर सकते हैं। एक बार जब आप इस चरण पर पहुंच जाते हैं, तो कॉल शुरू करने में केवल कुछ मिनट या घंटे लगते हैं अनुमान के लिए मॉडल। परिणामस्वरूप, जिन अनुप्रयोगों को बनाने में पहले छह महीने या यहां तक ​​कि एक वर्ष लगता था, उन्हें अब मिनटों, घंटों या अधिकतम दिनों में बनाया जा सकता है, आप इसे प्रॉम्प्ट का उपयोग करके बना सकते हैं एआई अनुप्रयोगों के निर्माण का तरीका बदल रहा हैजल्दी करो.\n",
    "\n",
    "यह ध्यान रखना महत्वपूर्ण है कि यह दृष्टिकोण कई असंरचित डेटा अनुप्रयोगों, विशेष रूप से पाठ अनुप्रयोगों और तेजी से बढ़ते दृष्टि अनुप्रयोगों के लिए काम करता है, हालांकि वर्तमान दृष्टि तकनीक अभी भी विकसित हो रही है, यह संरचित डेटा अनुप्रयोगों, यानी मशीन लर्निंग अनुप्रयोगों के लिए काम नहीं करती है जो बड़ी प्रक्रिया करते हैं एक्सेल स्प्रेडशीट में मूल्यों की संख्या हालांकि, इस दृष्टिकोण के लिए उपयुक्त अनुप्रयोगों के लिए, एआई घटकों को जल्दी से बनाया जा सकता है और सह को बदल रहे हैंसंपूर्ण सिस्टम के निर्माण कार्यप्रवाह में अभी भी दिन, सप्ताह या अधिक समय लग सकता है, लेकिन कम से कम यह भाग तेजी से किया जा सकता है।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe248d6",
   "metadata": {},
   "source": [
    "अगले अध्याय में, हम दिखाएंगे कि ग्राहक सेवा सहायक के इनपुट का मूल्यांकन करने के लिए इन घटकों का उपयोग कैसे करें।\n",
    "यह एक ऑनलाइन रिटेलर के लिए ग्राहक सेवा सहायक के निर्माण के इस पाठ्यक्रम में एक अधिक संपूर्ण उदाहरण का हिस्सा होगा।"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
