# Chapter 6 Conclusion and Outlook

Congratulations on completing this course! We hope you have mastered the skills to build, evaluate, and iterate your retrieval augmentation generation (RAG) applications to make them more suitable for production environments. Whether you come from a data science, machine learning background, or traditional software development background, learning these core development principles is necessary, which will make you a top AI engineer who can build robust large-scale language model (LLM) software systems.

### üìö Course Summary

This course deeply explored RAG techniques and introduced how to reduce the illusion phenomenon of LLM, which is a priority for every developer as the field develops. We are excited about the improvements in basic models and the reduction in the cost of large-scale evaluation and how it has become easier to set up and run.

### üõ†Ô∏è Deeper Exploration

We recommend that you have a deeper understanding of your data pipeline, retrieval strategy, and LLM tips to help improve RAG performance. The two techniques we showed are just the tip of the iceberg. You should study everything from block size to retrieval techniques such as hybrid search and LLM-based reasoning such as thought chaining.

### üìà Further Evaluation

RAG triplets are an excellent starting point for evaluating RAG-based LLM applications. Next, we encourage you to dig deeper into evaluating LLMs and the application domains they support. This includes topics such as evaluating model confidence, calibration, uncertainty, interpretability, privacy, fairness, and toxicity in both benign and adversarial settings.

###üöÄ Future Outlook

After studying this course, are you now ready to start building exciting applications and exploring new areas of AI?

Congratulations again on completing the course, and I wish you great success in your journey of exploration in the field of AI!