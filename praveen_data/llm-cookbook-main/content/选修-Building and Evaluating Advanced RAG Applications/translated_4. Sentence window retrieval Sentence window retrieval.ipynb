{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Sentence Sliding Window Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/人工智能.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "7 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: b03a0e50-2e8a-49bf-82f0-4a3909364809\n",
      "Text: 2/2/24, 2:43 PM ⼈⼯智能  - 维基百科，⾃由的百科全书\n",
      "https://zh.wikipedia.org/wiki/ ⼈⼯智能 2/13“⼈⼯智能”的各地常⽤名称 中国⼤陆⼈⼯智能 台湾⼈⼯智慧\n",
      "港澳⼈⼯智能 新⻢⼈⼯智能、⼈⼯智慧 ⽇韩⼈⼯知能 越南智慧⼈造 [展开] [展开] [展开] [展开] [展开] [展开]⼈⼯智能系列内容\n",
      "主要⽬标 实现⽅式 ⼈⼯智能哲学 历史 技术 术语⼈⼯智能（英语：artiﬁcial intelligence ，缩写为\n",
      "AI）亦称机器智能，指由⼈制造出来的机器所表现出来的智能。通常⼈⼯\n",
      "智能是指⽤普通计算机程序来呈现⼈类智能的技术。该词也指出研究这样的智能系统是否能够实现，以及如何实现。同 时，通过 医学 、神经科学\n",
      "、机器⼈学 及...\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents_en = SimpleDirectoryReader(\n",
    "    input_files=[\"data/eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 5ab262c9-a207-4f2d-9513-fc4d5c350cf5\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents_en), \"\\n\")\n",
    "print(len(documents_en), \"\\n\")\n",
    "print(type(documents_en[0]))\n",
    "print(documents_en[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the text of each document in documents is concatenated into a string, and then a Document instance is created, which represents the entire document collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "document_en = Document(text=\"\\n\\n\".join([doc.text for doc in documents_en]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Chinese punctuation marks with English punctuation marks for easy subsequent processing\n",
    "# If it is an English document, you can skip this step\n",
    "# If not processed, it will lead to the inability to correctly segment Chinese sentences, which will affect the size of the subsequent sentence_window and cause the input length to exceed the maximum limit of gpt-3.5-turbo\n",
    "document.text=document.text.replace('。','. ')\n",
    "document.text=document.text.replace('！','! ')\n",
    "document.text=document.text.replace('？','? ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentence sliding window search settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parser object named node_parser is created, the window size is specified as 3, and the original text metadata key is set to ``original_text``. The parser created in this way can be used to extract nodes from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Chinese text string\n",
    "Use the get_nodes_from_documents method of node_parser to extract nodes from the provided text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"你好. 你怎么样? 我很好!  \"\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([Document(text=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_en = \"hello. how are you? I am fine!  \"\n",
    "\n",
    "nodes_en = node_parser.get_nodes_from_documents([Document(text=text_en)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each individual word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你好. ', '你怎么样? ', '我很好!  ']\n",
      "['hello. ', 'how are you? ', 'I am fine!  ']\n"
     ]
    }
   ],
   "source": [
    "print([x.text for x in nodes])\n",
    "print([x.text for x in nodes_en])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好.  你怎么样?  我很好!  \n",
      "hello.  how are you?  I am fine!  \n"
     ]
    }
   ],
   "source": [
    "print(nodes[1].metadata[\"window\"])\n",
    "print(nodes_en[1].metadata[\"window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"你好. 吧台. 猫狗. 老鼠\"\n",
    "text_en2 = 'hello. bar. cat. dog. mouse.'\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([Document(text=text)])\n",
    "nodes_en2 = node_parser.get_nodes_from_documents([Document(text=text_en2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你好. ', '吧台. ', '猫狗. ', '老鼠']\n",
      "['hello. ', 'how are you? ', 'I am fine!  ']\n"
     ]
    }
   ],
   "source": [
    "print([x.text for x in nodes])\n",
    "print([x.text for x in nodes_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好.  吧台.  猫狗. \n",
      "hello.  bar.  cat. \n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].metadata[\"window\"])\n",
    "print(nodes_en2[0].metadata[\"window\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance of a language model is created using the `GPT-3.5-turbo` model from `OpenAI`, with the temperature parameter set to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ServiceContext` object is created using the `ServiceContext.from_defaults` method, which contains service-related context information for index construction, including language model, embedding model, and node parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "sentence_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")\n",
    "\n",
    "sentence_context_en = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `VectorStoreIndex` object is created using the `VectorStoreIndex.from_documents` method, which is used to store and retrieve vector information related to documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "sentence_index = VectorStoreIndex.from_documents(\n",
    "    [document], service_context=sentence_context\n",
    ")\n",
    "\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "sentence_index_en = VectorStoreIndex.from_documents(\n",
    "    [document_en], service_context=sentence_context_en\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the created index to the specified directory (\"./sentence_index\") . This allows the index to be reloaded in subsequent runs without having to rebuild it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")\n",
    "sentence_index_en.storage_context.persist(persist_dir=\"./sentence_index_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks if the index file exists and rebuilds it if it does not. If it does exist, it will use the `load_index_from_storage` method to load the index from the existing index file instead of rebuilding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is optional to check\n",
    "# if an index file exists, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "import os\n",
    "from llama_index import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "if not os.path.exists(\"./sentence_index\"):\n",
    "    sentence_index = VectorStoreIndex.from_documents(\n",
    "        [document], service_context=sentence_context\n",
    "    )\n",
    "\n",
    "    sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")\n",
    "else:\n",
    "    sentence_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=\"./sentence_index\"),\n",
    "        service_context=sentence_context\n",
    "    )\n",
    "\n",
    "if not os.path.exists(\"./sentence_index_en\"):\n",
    "    sentence_index_en = VectorStoreIndex.from_documents(\n",
    "        [document_en], service_context=sentence_context_en\n",
    "    )\n",
    "\n",
    "    sentence_index_en.storage_context.persist(persist_dir=\"./sentence_index_en\")\n",
    "else:\n",
    "    sentence_index_en = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=\"./sentence_index_en\"),\n",
    "        service_context=sentence_context_en\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Post-creation processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A post-processor instance is created using the `MetadataReplacementPostProcessor` class, and the target metadata key is set to `window`. The function of this post-processor is to replace the content of the target metadata key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "postproc = MetadataReplacementPostProcessor(\n",
    "    target_metadata_key=\"window\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `NodeWithScore` class to associate a score with each node in the original node list to form a node list with scores. \n",
    "Use the `deepcopy` function to create a deep copy of the original node list for subsequent comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import NodeWithScore\n",
    "from copy import deepcopy\n",
    "\n",
    "scored_nodes = [NodeWithScore(node=x, score=1.0) for x in nodes]\n",
    "nodes_old = [deepcopy(n) for n in nodes]\n",
    "\n",
    "scored_nodes_en = [NodeWithScore(node=x, score=1.0) for x in nodes_en2]\n",
    "nodes_old_en = [deepcopy(n) for n in nodes_en2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吧台. \n",
      "bar. \n"
     ]
    }
   ],
   "source": [
    "print(nodes_old[1].text)\n",
    "print(nodes_old_en[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `postprocess_nodes` method of the postprocessor, the contents of the target metadata key in the list of nodes with scores are replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_nodes = postproc.postprocess_nodes(scored_nodes)\n",
    "replaced_nodes_en = postproc.postprocess_nodes(scored_nodes_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好.  吧台.  猫狗.  老鼠\n",
      "hello.  bar.  cat.  dog. \n"
     ]
    }
   ],
   "source": [
    "print(replaced_nodes[1].text)\n",
    "print(replaced_nodes_en[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Adding a reordering block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A post-processor instance is created using the `SentenceTransformerRerank` class, the parameter `top_n` is set to 2, and the model used is \"BAAI/bge-reranker-base\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "# BAAI/bge-reranker-base\n",
    "# link: https://huggingface.co/BAAI/bge-reranker-base\n",
    "rerank = SentenceTransformerRerank(\n",
    "    top_n=2, model=\"BAAI/bge-reranker-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `QueryBundle` object is created containing the query text \"I want a dog.\". \n",
    "A list of two nodes with scores is created, representing text nodes containing the text \"This is a cat\" and \"This is a dog\", with scores of 0.6 and 0.4 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import QueryBundle\n",
    "from llama_index.schema import TextNode, NodeWithScore\n",
    "\n",
    "query = QueryBundle(\"我想要只狗.\")\n",
    "\n",
    "scored_nodes = [\n",
    "    NodeWithScore(node=TextNode(text=\"这是只猫\"), score=0.6),\n",
    "    NodeWithScore(node=TextNode(text=\"这是只狗\"), score=0.4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import QueryBundle\n",
    "from llama_index.schema import TextNode, NodeWithScore\n",
    "\n",
    "query_en = QueryBundle(\"I want a dog.\")\n",
    "\n",
    "scored_nodes_en = [\n",
    "    NodeWithScore(node=TextNode(text=\"This is a cat\"), score=0.6),\n",
    "    NodeWithScore(node=TextNode(text=\"This is a dog\"), score=0.4),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `postprocess_nodes` method of the `SentenceTransformerRerank` class, rerank the list of nodes with scores, taking into account the query text. The reranked nodes will be based on the pre-trained sentence transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_nodes = rerank.postprocess_nodes(\n",
    "    scored_nodes, query_bundle=query\n",
    ")\n",
    "\n",
    "reranked_nodes_en = rerank.postprocess_nodes(\n",
    "    scored_nodes_en, query_bundle=query_en\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text and scores in the re-ranked node list are output. This shows the effect of the sentence transformation model on node re-ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('这是只狗', 0.9660425), ('这是只猫', 0.06396222)]\n",
      "[('This is a dog', 0.9182736), ('This is a cat', 0.0014040753)]\n"
     ]
    }
   ],
   "source": [
    "print([(x.text, x.score) for x in reranked_nodes])\n",
    "print([(x.text, x.score) for x in reranked_nodes_en])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Running the Index Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `as_query_engine` method to convert `sentence_index` to a query engine object `sentence_window_engine`. \n",
    "Here, the `top k` of `similarity` is set to 6, and the `node_postprocessors` parameter is passed in, which contains the `postproc` and `rerank` postprocessors created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=6, node_postprocessors=[postproc, rerank]\n",
    ")\n",
    "\n",
    "sentence_window_engine_en = sentence_index_en.as_query_engine(\n",
    "    similarity_top_k=6, node_postprocessors=[postproc, rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query engine's `query` method executes a query, \"What is the key to success in the field of artificial intelligence?\" The query engine will use the previously set post-processor to post-process the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"在人工智能领域建功立业的关键是什么?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response_en = sentence_window_engine_en.query(\n",
    "    \"What are the keys to building a career in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `display_response` function provided by the `LLAMA` framework displays the response results of the query. This usually includes a set of nodes that match the query, as well as their text, scores, and other information. \n",
    "This way, the results of the query can be better visualized and understood in the `Notebook` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** 在人工智能领域建功立业的关键是系统能够正确解释外部数据，从中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_response\n",
    "\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Learning foundational technical skills, working on projects, finding a job, and being part of a supportive community are the keys to building a career in AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_response\n",
    "\n",
    "display_response(window_response_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge the above operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`documents`: list of documents to build index for. \n",
    "`llm`: OpenAI language model instance. \n",
    "`embed_model`: name or path to embedding model. \n",
    "`sentence_window_size`: size of sentence window. \n",
    "`save_dir`: directory to persist index. \n",
    "\n",
    "Create a node_parser for sentence window. \n",
    "Create a ServiceContext with context information such as language model and node_parser. \n",
    "If index does not exist in the specified directory, create a VectorStoreIndex based on the provided documents and persist it to the specified directory. \n",
    "If index file already exists in the directory, load index from file. \n",
    "Return the constructed sentence window index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index import ServiceContext, VectorStoreIndex, StorageContext\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "# create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "def build_sentence_window_index_en(\n",
    "    documents_en,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_en\",\n",
    "):\n",
    "# create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index_en = VectorStoreIndex.from_documents(\n",
    "            documents_en, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index_en.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index_en = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index_en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentence_index`: constructed sentence window index. \n",
    "`similarity_top_k`: top k for similarity query. \n",
    "`rerank_top_n`: reranked top n. \n",
    "\n",
    "Defines two postprocessors: `postproc` for replacing metadata keys, `rerank` for reranking nodes using sentence transformation model. \n",
    "Creates a query engine `sentence_window_engine`, converts sentence window index to query engine, and uses defined postprocessors. \n",
    "Returns the constructed query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "# define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "def get_sentence_window_query_engine_en(\n",
    "    sentence_index_en, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "# define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine_en = sentence_index_en.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the previously defined `build_sentence_window_index` function, passing in the document list, language model instance, and save directory to build the sentence window index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "index = build_sentence_window_index(\n",
    "    [document],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./sentence_index\",\n",
    ")\n",
    "\n",
    "index_en = build_sentence_window_index_en(\n",
    "    [document_en],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./sentence_index_en\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the previously defined `get_sentence_window_query_engine` function, passing in the constructed sentence window index and similarity `top k` to get the query engine for the sentence window. \n",
    "Here, `similarity_top_k` is set to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_sentence_window_query_engine(index, similarity_top_k=6)\n",
    "query_engine_en = get_sentence_window_query_engine(index_en, similarity_top_k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TruLens Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the generated questions from the file named 'generated_questions.text' and store them in the `eval_questions` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('data/generated_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "# Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)\n",
    "\n",
    "eval_questions_en = []\n",
    "with open('data/generated_questions_en.txt', 'r') as file:\n",
    "    for line in file:\n",
    "# Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function `run_evals` is defined that accepts the generated list of questions, the `TruLens` recorder, and the query engine as parameters. For each question, a recording is started using the `TruLens` recorder, and then the query is executed using the query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "def run_evals(eval_questions, tru_recorder, query_engine):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)\n",
    "\n",
    "\n",
    "def run_evals_en(eval_questions_en, tru_recorder, query_engine):\n",
    "    for question in eval_questions_en:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the `TruLens` database using the `reset_database` method of the Tru class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set the sliding window size to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the previously defined functions `build_sentence_window_index` and `get_sentence_window_query_engine` to build the sentence window index and query engine respectively. Here, the window size is set to 1, and the save directory is specified as \"sentence_index_1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_1 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1\",\n",
    ")\n",
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")\n",
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_1_en = build_sentence_window_index_en(\n",
    "    documents_en,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1_en\",\n",
    ")\n",
    "sentence_window_engine_1_en = get_sentence_window_query_engine(\n",
    "    sentence_index_1_en\n",
    ")\n",
    "tru_recorder_1_en = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1_en,\n",
    "    app_id='sentence window engine 1_en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the previously defined evaluation function `run_evals`, pass in the generated question list, `TruLens` recorder `tru_recorder_1` and the constructed query engine `sentence_window_engine_1`, and run the evaluation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 58250, Requested 1999. Please try again in 249ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 59832, Requested 502. Please try again in 334ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 58502, Requested 1922. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 59610, Requested 1723. Please try again in 1.333s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)\n",
    "run_evals(eval_questions_en, tru_recorder_1, sentence_window_engine_1_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")\n",
    "\n",
    "tru_recorder_1_en = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1_en,\n",
    "    app_id='sentence window engine 1_en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_87b8d0d554e7d74fa19c16f4692d69cf</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...</td>\n",
       "      <td>\"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_87b8d0d554e7d74fa19...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:30:49.113462\", \"...</td>\n",
       "      <td>2024-03-12T10:31:02.269094</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...</td>\n",
       "      <td>[{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_b9425d9aa02130eec6c73f7cc6f700f8</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...</td>\n",
       "      <td>\"The self-updating and self-improving capabili...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_b9425d9aa02130eec6c...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:02.914647\", \"...</td>\n",
       "      <td>2024-03-12T10:31:09.293573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...</td>\n",
       "      <td>[{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_8c266922b3864f14c5aa3fd4fc98923c</td>\n",
       "      <td>\"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...</td>\n",
       "      <td>\"Management should consider adjusting their wo...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_8c266922b3864f14c5a...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:09.505494\", \"...</td>\n",
       "      <td>2024-03-12T10:31:12.333074</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': '管理者如何管理AI？', 'response':...</td>\n",
       "      <td>[{'args': {'prompt': '管理者如何管理AI？', 'response':...</td>\n",
       "      <td>[{'args': {'source': '任何的科技都会有瓶颈， 摩尔定律 到⽬前也遇到相...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_48957156666710cd55d5059c9ed69b56</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_48957156666710cd55d...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:12.872050\", \"...</td>\n",
       "      <td>2024-03-12T10:31:21.471832</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[{'args': {'prompt': '强人工智能是什么？', 'response': ...</td>\n",
       "      <td>[{'args': {'prompt': '强人工智能是什么？', 'response': ...</td>\n",
       "      <td>[{'args': {'source': 'The Behavioral and Brain...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_c3d563072ae3ef443e6e102c53e1677e</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...</td>\n",
       "      <td>\"The misuse of artificial intelligence can lea...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_c3d563072ae3ef443e6...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:21.670386\", \"...</td>\n",
       "      <td>2024-03-12T10:31:28.646002</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...</td>\n",
       "      <td>[{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0  sentence window engine 1   \n",
       "1  sentence window engine 1   \n",
       "2  sentence window engine 1   \n",
       "3  sentence window engine 1   \n",
       "4  sentence window engine 1   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_87b8d0d554e7d74fa19c16f4692d69cf   \n",
       "1  record_hash_b9425d9aa02130eec6c73f7cc6f700f8   \n",
       "2  record_hash_8c266922b3864f14c5aa3fd4fc98923c   \n",
       "3  record_hash_48957156666710cd55d5059c9ed69b56   \n",
       "4  record_hash_c3d563072ae3ef443e6e102c53e1677e   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...   \n",
       "1  \"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...   \n",
       "2  \"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...   \n",
       "4  \"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...    -   \n",
       "1  \"The self-updating and self-improving capabili...    -   \n",
       "2  \"Management should consider adjusting their wo...    -   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...    -   \n",
       "4  \"The misuse of artificial intelligence can lea...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_87b8d0d554e7d74fa19...   \n",
       "1  {\"record_id\": \"record_hash_b9425d9aa02130eec6c...   \n",
       "2  {\"record_id\": \"record_hash_8c266922b3864f14c5a...   \n",
       "3  {\"record_id\": \"record_hash_48957156666710cd55d...   \n",
       "4  {\"record_id\": \"record_hash_c3d563072ae3ef443e6...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "2  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "3  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "4  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-03-12T10:30:49.113462\", \"...   \n",
       "1  {\"start_time\": \"2024-03-12T10:31:02.914647\", \"...   \n",
       "2  {\"start_time\": \"2024-03-12T10:31:09.505494\", \"...   \n",
       "3  {\"start_time\": \"2024-03-12T10:31:12.872050\", \"...   \n",
       "4  {\"start_time\": \"2024-03-12T10:31:21.670386\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-03-12T10:31:02.269094               0.9               0.40   \n",
       "1  2024-03-12T10:31:09.293573               1.0               0.60   \n",
       "2  2024-03-12T10:31:12.333074               0.8               0.25   \n",
       "3  2024-03-12T10:31:21.471832               0.8               0.80   \n",
       "4  2024-03-12T10:31:28.646002               0.9               0.50   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0      1.000000  [{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...   \n",
       "1      0.800000  [{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...   \n",
       "2      1.000000  [{'args': {'prompt': '管理者如何管理AI？', 'response':...   \n",
       "3      0.333333  [{'args': {'prompt': '强人工智能是什么？', 'response': ...   \n",
       "4      1.000000  [{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...   \n",
       "1  [{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...   \n",
       "2  [{'args': {'prompt': '管理者如何管理AI？', 'response':...   \n",
       "3  [{'args': {'prompt': '强人工智能是什么？', 'response': ...   \n",
       "4  [{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...       13             0   \n",
       "1  [{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...        6             0   \n",
       "2  [{'args': {'source': '任何的科技都会有瓶颈， 摩尔定律 到⽬前也遇到相...        2             0   \n",
       "3  [{'args': {'source': 'The Behavioral and Brain...        8             0   \n",
       "4  [{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...        6             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Set the sliding window size to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previously defined function is called to build the sentence window index, query engine, and `TruLens` recorder. The window size is set to 3, and the save directory is specified as \"sentence_index_3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_3 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3\",\n",
    ")\n",
    "sentence_window_engine_3 = get_sentence_window_query_engine(\n",
    "    sentence_index_3\n",
    ")\n",
    "\n",
    "tru_recorder_3 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3,\n",
    "    app_id='sentence window engine 3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_3_en = build_sentence_window_index_en(\n",
    "    documents_en,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3_en\",\n",
    ")\n",
    "sentence_window_engine_3_en = get_sentence_window_query_engine(\n",
    "    sentence_index_3_en\n",
    ")\n",
    "\n",
    "tru_recorder_3_en = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3_en,\n",
    "    app_id='sentence window engine 3_en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `run_evals` function, passing in the generated question list `eval_questions`, the `TruLens` recorder `tru_recorder_3`, and the constructed query engine `sentence_window_engine_3` to run the evaluation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)\n",
    "run_evals(eval_questions_en, tru_recorder_3_en, sentence_window_engine_3_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_e9815da1c66c0943f4d155a06f94e9c4</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...</td>\n",
       "      <td>\"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_e9815da1c66c0943f4d...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:55:51.162029\", \"...</td>\n",
       "      <td>2024-03-10T22:56:03.820730</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...</td>\n",
       "      <td>[{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_140932cb020d95e0554ecf0489eb42f2</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...</td>\n",
       "      <td>\"The self-updating and self-improving capabili...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_140932cb020d95e0554...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:04.085254\", \"...</td>\n",
       "      <td>2024-03-10T22:56:10.348414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...</td>\n",
       "      <td>[{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_5bd9fa7d1b1997c136b9d1d4ce3d2684</td>\n",
       "      <td>\"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...</td>\n",
       "      <td>\"Management should consider adjusting their wo...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_5bd9fa7d1b1997c136b...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:10.552787\", \"...</td>\n",
       "      <td>2024-03-10T22:56:13.694339</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': '管理者如何管理AI？', 'response':...</td>\n",
       "      <td>[{'args': {'prompt': '管理者如何管理AI？', 'response':...</td>\n",
       "      <td>[{'args': {'source': '任何的科技都会有瓶颈， 摩尔定律 到⽬前也遇到相...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_cd9a2aa2bdf60288d1b04cdbeac630f3</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_cd9a2aa2bdf60288d1b...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:13.882046\", \"...</td>\n",
       "      <td>2024-03-10T22:56:21.948222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': '强人工智能是什么？', 'response': ...</td>\n",
       "      <td>[{'args': {'prompt': '强人工智能是什么？', 'response': ...</td>\n",
       "      <td>[{'args': {'source': 'The Behavioral and Brain...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_736205619e133e5333d36a19a29293fe</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...</td>\n",
       "      <td>\"The misuse of artificial intelligence can lea...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_736205619e133e5333d...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:22.140156\", \"...</td>\n",
       "      <td>2024-03-10T22:56:28.835570</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...</td>\n",
       "      <td>[{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0  sentence window engine 1   \n",
       "1  sentence window engine 1   \n",
       "2  sentence window engine 1   \n",
       "3  sentence window engine 1   \n",
       "4  sentence window engine 1   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_e9815da1c66c0943f4d155a06f94e9c4   \n",
       "1  record_hash_140932cb020d95e0554ecf0489eb42f2   \n",
       "2  record_hash_5bd9fa7d1b1997c136b9d1d4ce3d2684   \n",
       "3  record_hash_cd9a2aa2bdf60288d1b04cdbeac630f3   \n",
       "4  record_hash_736205619e133e5333d36a19a29293fe   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...   \n",
       "1  \"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...   \n",
       "2  \"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...   \n",
       "4  \"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...    -   \n",
       "1  \"The self-updating and self-improving capabili...    -   \n",
       "2  \"Management should consider adjusting their wo...    -   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...    -   \n",
       "4  \"The misuse of artificial intelligence can lea...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_e9815da1c66c0943f4d...   \n",
       "1  {\"record_id\": \"record_hash_140932cb020d95e0554...   \n",
       "2  {\"record_id\": \"record_hash_5bd9fa7d1b1997c136b...   \n",
       "3  {\"record_id\": \"record_hash_cd9a2aa2bdf60288d1b...   \n",
       "4  {\"record_id\": \"record_hash_736205619e133e5333d...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "2  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "3  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "4  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-03-10T22:55:51.162029\", \"...   \n",
       "1  {\"start_time\": \"2024-03-10T22:56:04.085254\", \"...   \n",
       "2  {\"start_time\": \"2024-03-10T22:56:10.552787\", \"...   \n",
       "3  {\"start_time\": \"2024-03-10T22:56:13.882046\", \"...   \n",
       "4  {\"start_time\": \"2024-03-10T22:56:22.140156\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-03-10T22:56:03.820730               0.9                0.4   \n",
       "1  2024-03-10T22:56:10.348414               1.0                0.5   \n",
       "2  2024-03-10T22:56:13.694339               0.8                0.3   \n",
       "3  2024-03-10T22:56:21.948222               0.9                0.7   \n",
       "4  2024-03-10T22:56:28.835570               0.9                0.3   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           1.0  [{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...   \n",
       "1           0.8  [{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...   \n",
       "2           0.9  [{'args': {'prompt': '管理者如何管理AI？', 'response':...   \n",
       "3           1.0  [{'args': {'prompt': '强人工智能是什么？', 'response': ...   \n",
       "4           0.0  [{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': '人工智能中的先验知识是如何被存储的？', 're...   \n",
       "1  [{'args': {'prompt': '人工智能的自我更新和自我提升是否可能导致其脱离人...   \n",
       "2  [{'args': {'prompt': '管理者如何管理AI？', 'response':...   \n",
       "3  [{'args': {'prompt': '强人工智能是什么？', 'response': ...   \n",
       "4  [{'args': {'prompt': '人工智能被滥用带来的危害？', 'respons...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...       12             0   \n",
       "1  [{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...        6             0   \n",
       "2  [{'args': {'source': '任何的科技都会有瓶颈， 摩尔定律 到⽬前也遇到相...        3             0   \n",
       "3  [{'args': {'source': 'The Behavioral and Brain...        8             0   \n",
       "4  [{'args': {'source': '2/2/24, 2:43 PM ⼈⼯智能  - ...        6             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
