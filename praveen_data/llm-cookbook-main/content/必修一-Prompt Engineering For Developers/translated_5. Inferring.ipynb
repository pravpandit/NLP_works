{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3630c235-f891-4874-bd0a-5277d4d6aa82",
   "metadata": {},
   "source": [
    "# Chapter 5 Inference\n",
    "\n",
    "In this lesson, you will infer sentiment and topics from product reviews and news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0eaf6",
   "metadata": {},
   "source": [
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#一引言\" data-toc-modified-id=\"一、引言\">一、引言</a></span></li>\n",
    "<li>\n",
    "<span><a href=\"#二情感因而信息抽取\" data-toc-modified-id=\"二、情感因而信息抽取\">二、情感因而信息抽取</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#21-情感偏偏分析\" data-toc-modified-id=\"2.1 情感偏偏分析\">2.1 情感偏偏分析</a></span></li> \n",
    "<li><span><a href=\"#22-识别情感型\" data-toc-modified-id=\"2.2 识别情感型\">2.2 识别情感型</a></span></li>\n",
    "<li><span><a href=\"#23-Identify anger\" data-toc-modified-id=\"2.3 Identify anger\">2.3 Identify anger</a></span></li>\n",
    "<li><span><a href=\"#24-Product information extraction\" data-toc-modified-id=\"2.4 Product information extraction\">2.4 Product information extraction</a></span></li>\n",
    "<li><span><a href=\"#25-Comprehensive completion of tasks\" data-toc-modified-id=\"2.5 Comprehensive completion of tasks\">2.5 Comprehensive completion of tasks</a></span></li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Three topic inference\" data-toc-modified-id=\"Three, topic inference\">Three, topic inference</a></span></li>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#31-Infer discussion topic\" data-toc-modified-id=\"3.1 Infer discussion topic\">3.1 Infer the topic of discussion</a></span></li> \n",
    "<li><span><a href=\"#32-Make news alerts for specific topics\" data-toc-modified-id=\"3.2 Make news alerts for specific topics\">3.2 Make news alerts for specific topics</a></span></li>\n",
    "</ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3abbee",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "An inference task can be thought of as a process where a model receives text as input and performs some kind of analysis. This involves extracting labels, extracting entities, understanding text sentiment, and so on. If you want to extract positive or negative sentiment from a piece of text, in a traditional machine learning workflow, you need to collect a labeled dataset, train a model, figure out how to deploy the model in the cloud, and perform inference. This may work well, but it takes a lot of work to perform the entire process. And for each task, such as sentiment analysis, extracting entities, and so on, you need to train and deploy a separate model.\n",
    "\n",
    "A very good feature of LLM is that for many of these tasks, you only need to write a prompt to start producing results without doing a lot of work. This greatly speeds up application development. You can also use only one model and one API to perform many different tasks without having to figure out how to train and deploy many different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a821d943",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "# Import third-party libraries\n",
    "\n",
    "openai.api_key = \"sk-...\"\n",
    "# Set API_KEY, please replace it with your own API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82f5577",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2fdfa-c99f-4750-8574-dba7712cd7f0",
   "metadata": {},
   "source": [
    "## 2. Sentiment Inference and Information Extraction\n",
    "### 2.1 Sentiment Classification\n",
    "\n",
    "Take the comments about a desk lamp on an e-commerce platform as an example, the emotions it conveys can be classified into two categories (positive/negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f3b49b",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6260f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese\n",
    "lamp_review_zh = \"\"\"\n",
    "我需要一盏漂亮的卧室灯，这款灯具有额外的储物功能，价格也不算太高。\\\n",
    "我很快就收到了它。在运输过程中，我们的灯绳断了，但是公司很乐意寄送了一个新的。\\\n",
    "几天后就收到了。这款灯很容易组装。我发现少了一个零件，于是联系了他们的客服，他们很快就给我寄来了缺失的零件！\\\n",
    "在我看来，Lumina 是一家非常关心顾客和产品的优秀公司！\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ec4ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d6e4bd-3337-45a3-8c99-a734cdd06743",
   "metadata": {},
   "source": [
    "Now let's write a prompt to classify the sentiment of this review. If I want the system to tell me what the sentiment of this review is, I just write the prompt \"What is the sentiment of the following product review\" with the usual separators and the review text, etc.\n",
    "\n",
    "Then let's run it. The results show that the sentiment of this product review is positive, which seems to be very correct. Although this lamp is not perfect, this customer seems to be very satisfied. This seems to be a great company that cares about its customers and products, and it can be assumed that positive sentiment seems to be the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3157601",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the product review is positive.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5b0bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情感是积极的/正面的。\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "以下用三个反引号分隔的产品评论的情感是什么？\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562e656",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76be2320",
   "metadata": {},
   "source": [
    "If you want to give a more concise answer so that it is easier to post-process, you can add another command to the above prompt: *Answer with one word: \"Positive\" or \"Negative\"*. This will only print the word \"positive\", which makes the output more uniform and convenient for subsequent processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf9ca16",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a761b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正面\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "以下用三个反引号分隔的产品评论的情感是什么？\n",
    "\n",
    "用一个单词回答：「正面」或「负面」。\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2a973-1fa4-4a35-ae35-a2e746c0e91b",
   "metadata": {},
   "source": [
    "### 2.2 Identify sentiment type\n",
    "\n",
    "Still using the lamp comment, let’s try another prompt. This time I need the model to identify the sentiment expressed by the comment author and summarize it into a list of no more than five items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa7934b",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied, grateful, impressed, content, pleased\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e615c13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "满意,感激,信任,赞扬,愉快\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "识别以下评论的作者表达的情感。包含不超过五个项目。将答案格式化为以逗号分隔的单词列表。\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7743a53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc4444f7",
   "metadata": {},
   "source": [
    "Large language models are very good at extracting specific things from a piece of text. In the example above, the sentiment expressed by the reviews helps understand how customers view a specific product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428d093-51c9-461c-b41e-114e80876409",
   "metadata": {},
   "source": [
    "### 2.3 Identifying Anger\n",
    "\n",
    "For many businesses, it is important to know if a customer is very angry. So the following classification question arises: Is the author of the following review expressing anger? Because if someone is really angry, it may be worth paying extra attention and having the customer support or customer success team contact the customer to understand the situation and resolve the issue for the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba1a538",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bad324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "否\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "以下评论的作者是否表达了愤怒？评论用三个反引号分隔。给出是或否的答案。\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77905fd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ca57a2",
   "metadata": {},
   "source": [
    "In the example above, the customer is not angry. Note that if you were to build all of these classifiers using regular supervised learning, you wouldn't be able to do this in a few minutes. We encourage you to try changing some of these prompts, perhaps asking if the customer expressed joy, or asking if there were any missing parts, and see if you can get the prompt to make different inferences about this light fixture review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a771e-ca78-4e55-8088-2da6f3820ddc",
   "metadata": {},
   "source": [
    "### 2.4 Product Information Extraction\n",
    "\n",
    "Next, let's extract richer information from customer reviews. Information extraction is a part of Natural Language Processing (NLP) that is concerned with extracting certain things you want to know from text. So in this prompt, I asked it to identify the following: the name of the company that bought the item and the one that made it.\n",
    "\n",
    "Similarly, if you are trying to summarize many reviews for an online shopping e-commerce site, for those reviews, figuring out what the item is, who made the item, and figuring out the positive and negative sentiments can help track user sentiment trends for a particular item or manufacturer.\n",
    "\n",
    "In the example below, we ask it to format the response as a JSON object with item and brand as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a13bea1b",
   "metadata": {
    "height": 285
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"lamp with additional storage\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ffe056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"物品\": \"卧室灯\",\n",
      "  \"品牌\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "从评论文本中识别以下项目：\n",
    "- 评论者购买的物品\n",
    "- 制造该物品的公司\n",
    "\n",
    "评论文本用三个反引号分隔。将你的响应格式化为以 “物品” 和 “品牌” 为键的 JSON 对象。\n",
    "如果信息不存在，请使用 “未知” 作为值。\n",
    "让你的回应尽可能简短。\n",
    "  \n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342c732",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "954d125d",
   "metadata": {},
   "source": [
    "As shown above, it will say that the item is a bedroom lamp and the brand is Luminar, which you can easily load into a Python dictionary and then do other things with this output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38880a5-088f-4609-9913-f8fa41fb7ba0",
   "metadata": {},
   "source": [
    "### 2.5 Comprehensive Task Completion\n",
    "\n",
    "It took 3 or 4 prompts to extract all the above information, but it is actually possible to write a single prompt to extract all of this information at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7dda9e5",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"lamp with additional storage\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: ```{lamp_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "939c2b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"正面\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"卧室灯\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "从评论文本中识别以下项目：\n",
    "- 情绪（正面或负面）\n",
    "- 审稿人是否表达了愤怒？（是或否）\n",
    "- 评论者购买的物品\n",
    "- 制造该物品的公司\n",
    "\n",
    "评论用三个反引号分隔。将您的响应格式化为 JSON 对象，以 “Sentiment”、“Anger”、“Item” 和 “Brand” 作为键。\n",
    "如果信息不存在，请使用 “未知” 作为值。\n",
    "让你的回应尽可能简短。\n",
    "将 Anger 值格式化为布尔值。\n",
    "\n",
    "评论文本: ```{lamp_review_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09a673",
   "metadata": {},
   "source": [
    "In this example, we tell it to format the outrage value as a boolean and then output a JSON. You can try different variations on your own, or even try completely different comments to see if you can still extract the content accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235fc223-2c89-49ec-ac2d-78a8e74a43ac",
   "metadata": {},
   "source": [
    "## 3. Topic Inference\n",
    "\n",
    "Another cool application of large language models is to infer topics. Given a long text, what is this text about? What are the topics? Take the following fictional newspaper report as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a74cc3e",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811ff13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese\n",
    "story_zh = \"\"\"\n",
    "在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。\n",
    "调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。\n",
    "\n",
    "一位 NASA 员工 John Smith 对这一发现发表了评论，他表示：\n",
    "“我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”\n",
    "\n",
    "NASA 的管理团队也对这一结果表示欢迎，主管 Tom Johnson 表示：\n",
    "“我们很高兴听到我们的员工对 NASA 的工作感到满意。\n",
    "我们拥有一支才华横溢、忠诚敬业的团队，他们为实现我们的目标不懈努力，看到他们的辛勤工作得到回报是太棒了。”\n",
    "\n",
    "调查还显示，社会保障管理局的满意度最低，只有 45％的员工表示他们对工作满意。\n",
    "政府承诺解决调查中员工提出的问题，并努力提高所有部门的工作满意度。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea91d6-e841-4ee2-bed9-ca4a36df177f",
   "metadata": {},
   "source": [
    "### 3.1 Inferring Discussion Topics\n",
    "\n",
    "The above is a fictitious newspaper article about how government workers feel about the agency they work for. We can have it identify five topics being discussed, describe each topic in one or two words, and format the output as a comma-delimited list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c267cbe",
   "metadata": {
    "height": 217
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government survey, public sector employees, job satisfaction, NASA, Social Security Administration\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: ```{story}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f92f90fe",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['government survey',\n",
       " ' public sector employees',\n",
       " ' job satisfaction',\n",
       " ' NASA',\n",
       " ' Social Security Administration']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.split(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab27b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调查结果, NASA, 社会保障管理局, 员工满意度, 政府承诺\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "确定以下给定文本中讨论的五个主题。\n",
    "\n",
    "每个主题用1-2个单词概括。\n",
    "\n",
    "输出时用逗号分割每个主题。\n",
    "\n",
    "给定文本: ```{story_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d1435",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34be1d2a-1309-4512-841a-b6f67338938b",
   "metadata": {},
   "source": [
    "### 3.2 Making news alerts for specific topics\n",
    "\n",
    "Suppose we have a news site or something similar, and here are the topics we are interested in: NASA, local government, engineering, employee satisfaction, federal government, etc. Suppose we want to figure out, given a news article, what topics are covered in it. We can use a prompt like this: Determine whether each item in the following list of topics is a topic in the following text. Give a list of answers as 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94b8fa65",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\", \n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626c5b8e",
   "metadata": {
    "height": 234
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa: 1\n",
      "local government: 0\n",
      "engineering: 0\n",
      "employee satisfaction: 1\n",
      "federal government: 1\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: ```{story}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902a7c74",
   "metadata": {
    "height": 79
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT: New NASA story!\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['nasa'] == 1:\n",
    "    print(\"ALERT: New NASA story!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f53d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美国航空航天局：1\n",
      "当地政府：0\n",
      "工程：0\n",
      "员工满意度：1\n",
      "联邦政府：1\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "prompt = f\"\"\"\n",
    "判断主题列表中的每一项是否是给定文本中的一个话题，\n",
    "\n",
    "以列表的形式给出答案，每个主题用 0 或 1。\n",
    "\n",
    "主题列表：美国航空航天局、当地政府、工程、员工满意度、联邦政府\n",
    "\n",
    "给定文本: ```{story_zh}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39f24a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08247dbf",
   "metadata": {},
   "source": [
    "As you can see, the story is about NASA, employee satisfaction, and the federal government, but not about local government, engineering. This is sometimes called a zero-shot learning algorithm in machine learning because we didn't give it any labeled training data. Just from the prompt, it can determine which topics are covered in the news article.\n",
    "\n",
    "If we want to generate a news alert, we can also use this process to process news. Let's say I really like the work NASA does, and I can build a system like this to output a reminder every time NASA news comes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53bf1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提醒: 关于美国航空航天局的新消息\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {i.split('：')[0]: int(i.split('：')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['美国航空航天局'] == 1:\n",
    "    print(\"提醒: 关于美国航空航天局的新消息\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2c643",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ccd189",
   "metadata": {},
   "source": [
    "That’s all about inference, in just a few minutes we can build multiple systems for reasoning about text, which previously took a skilled machine learning developer days or even weeks. This is very exciting, both for skilled machine learning developers and for beginners, you can use Prompt to build and get started with fairly complex natural language processing tasks very quickly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
