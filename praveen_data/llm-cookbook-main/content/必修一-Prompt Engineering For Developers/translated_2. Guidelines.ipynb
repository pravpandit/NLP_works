{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Principles of Writing Prompts\n",
    "\n",
    "The main content of this chapter is the principles of writing prompts. In this chapter, we will give two principles of writing prompts and some related strategies. You can practice writing efficient prompts, so as to use LLM conveniently and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#一环境配置\" data-toc-modified-id=\"一、环境配置\">一、环境配置</a></span></li>\n",
    "<li>\n",
    "<span><a href=\"#二二基本原则\" data-toc-modified-id=\"二、两基本原则\">二、两基本原则</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#21-Principle 1 Write clear and specific instructions\" data-toc-modified-id=\"2.1 Principle 1: Write clear and specific instructions\">2.1 Principle 1: Write clear and specific instructions</a></span></li>\n",
    "<li><span><a href=\"#22-Give the model time to think\" data-toc-modified-id=\"2.2 Principle 2: Give the model time to think\">2.2 Principle 2: Give the model timeTo think</a></span></li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#三限量\" data-toc-modified-id=\"三、限量\">三、限量</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses the ChatGPT API provided by OpenAI, so you need to have a ChatGPT API_KEY first (you can also visit the official website to test it online), and then install OpenAI's third-party library. In order to balance simplicity and compatibility, this tutorial will introduce the configuration based on the ```openai.api_key``` method in the ```Python 3``` environment. There is also a configuration method based on environment variables, please refer to [OpenAI official documentation](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety) for details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to install the OpenAI library:\n",
    "```bash\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# Import third-party libraries\n",
    "\n",
    "openai.api_key  = \"sk-...\"\n",
    "# Set API_KEY, please replace it with your own API_KEY\n",
    "\n",
    "# The following is an example of a configuration method based on environment variables, which is safer. It is for reference only and will not be covered later.\n",
    "# import openai\n",
    "# import os\n",
    "# OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire course will take the gpt-3.5-turbo model as an example. We will explore the usage of the [Chat Completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api) provided by OpenAI in subsequent courses. Here, we first encapsulate it into a function. You don’t need to know its internal mechanism. You only need to know to call the function, take Prompt as the input parameter, and it will output the corresponding Completion (answer result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that encapsulates the OpenAI interface, with a parameter of Prompt and returns the corresponding result\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    '''\n",
    "    prompt: 对应的提示词\n",
    "    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4\n",
    "    '''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # 模型输出的温度系数，控制输出的随机程度\n",
    "    )\n",
    "# Call OpenAI's ChatCompletion interface\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Two basic principles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Principle 1: Write clear and specific instructions\n",
    "\n",
    "You should express what you want the model to do by providing instructions that are as clear and specific as possible. This will guide the model to give the correct output and reduce the likelihood that you will get irrelevant or incorrect responses. Clear instructions do not mean they must be short. In many cases, longer prompts are actually clearer and provide more context, which may produce more detailed and relevant output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.1 Use delimiters to clearly indicate different parts of the input**\n",
    "\n",
    "Delimiters can be: ```, \"\", <>, :, \\<tag> \\</tag>, etc.\n",
    "\n",
    "You can use any obvious punctuation to separate a specific part of the text from the rest of the prompt. The form of the markup is not limited, just let the model know clearly that this is a separate part. Using delimiters can effectively avoid prompt injection. Prompt injection means that if the user is allowed to add certain inputs to the (developer-predefined) prompt, the instructions provided may conflict with the actions the developer wants to perform, causing LLM to follow the instructions entered by the user instead of performing the actions the developer expects. That is, the input may contain other instructions that will override your instructions. Using delimiters is a good strategy for this.\n",
    "\n",
    "In the following example, we give a paragraph and ask GPT to summarize it. In this example, we use ``` as a delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese version see next cell\n",
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear and specific instructions should be provided to guide a model towards the desired output, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "您应该提供尽可能清晰、具体的指示，以表达您希望模型执行的任务。\\\n",
    "这将引导模型朝向所需的输出，并降低收到无关或不正确响应的可能性。\\\n",
    "不要将写清晰的提示词与写简短的提示词混淆。\\\n",
    "在许多情况下，更长的提示词可以为模型提供更多的清晰度和上下文信息，从而导致更详细和相关的输出。\n",
    "\"\"\"\n",
    "# The text content to be summarized\n",
    "prompt = f\"\"\"\n",
    "把用三个反引号括起来的文本总结成一句话。\n",
    "```{text}```\n",
    "\"\"\"\n",
    "# Instruction content, use ``` to separate the instruction and the content to be summarized\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide clear and specific instructions to avoid irrelevant or incorrect responses. Do not confuse writing clearly with writing briefly. Longer prompts can provide more clarity and contextual information, leading to more detailed and relevant output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.2 Seek structured output**\n",
    "\n",
    "The output can be in Json, HTML, etc.\n",
    "\n",
    "The second strategy is to ask for a structured output, which can make the output of the model easier for us to parse, for example, you can read it into a dictionary or list in Python.\n",
    "\n",
    "In the following example, we ask GPT to generate the title, author, and category of three books, and ask GPT to return it to us in Json format. For easy parsing, we specify the key of Json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"book_id\": 1,\n",
      "    \"title\": \"The Lost City of Zorath\",\n",
      "    \"author\": \"Aria Blackwood\",\n",
      "    \"genre\": \"Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 2,\n",
      "    \"title\": \"The Last Survivors\",\n",
      "    \"author\": \"Ethan Stone\",\n",
      "    \"genre\": \"Science Fiction\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 3,\n",
      "    \"title\": \"The Secret Life of Bees\",\n",
      "    \"author\": \"Lila Rose\",\n",
      "    \"genre\": \"Romance\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"book_id\": 1,\n",
      "      \"title\": \"The Shadow of the Wind\",\n",
      "      \"author\": \"Carlos Ruiz Zafón\",\n",
      "      \"genre\": \"Mystery\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 2,\n",
      "      \"title\": \"The Name of the Wind\",\n",
      "      \"author\": \"Patrick Rothfuss\",\n",
      "      \"genre\": \"Fantasy\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 3,\n",
      "      \"title\": \"The Hitchhiker's Guide to the Galaxy\",\n",
      "      \"author\": \"Douglas Adams\",\n",
      "      \"genre\": \"Science Fiction\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "请生成包括书名、作者和类别的三本虚构书籍清单，\\\n",
    "并以 JSON 格式提供，其中包含以下键:book_id、title、author、genre。\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.3 Ask the model to check if conditions are met**\n",
    "\n",
    "If the task contains assumptions (conditions) that may not be met, we can tell the model to check these assumptions first, and if they are not met, it will point out and stop executing the subsequent complete process. You can also consider possible edge cases and the model's response to avoid unexpected results or errors.\n",
    "\n",
    "In the following example, we will give the model two texts, one is the steps to make tea, and the other is a text without clear steps. We will ask the model to determine whether it contains a series of instructions. If so, rewrite the instructions in a given format, and if not, answer \"no steps provided\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - Add some sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \\\n",
    "singing. It's a beautiful day to go for a \\ \n",
    "walk in the park. The flowers are blooming, and the \\ \n",
    "trees are swaying gently in the breeze. People \\ \n",
    "are out and about, enjoying the lovely weather. \\ \n",
    "Some are having picnics, while others are playing \\ \n",
    "games or simply relaxing on the grass. It's a \\ \n",
    "perfect day to spend time outdoors and appreciate the \\ \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 的总结:\n",
      "第一步 - 把水烧开。\n",
      "第二步 - 拿一个杯子并把茶包放进去。\n",
      "第三步 - 把烧开的水倒在茶包上。\n",
      "第四步 - 等待几分钟，让茶叶浸泡。\n",
      "第五步 - 取出茶包。\n",
      "第六步 - 如果你愿意，可以加一些糖或牛奶调味。\n",
      "第七步 - 就这样，你可以享受一杯美味的茶了。\n"
     ]
    }
   ],
   "source": [
    "# Input that satisfies the conditions (steps are provided in the text)\n",
    "text_1 = f\"\"\"\n",
    "泡一杯茶很容易。首先，需要把水烧开。\\\n",
    "在等待期间，拿一个杯子并把茶包放进去。\\\n",
    "一旦水足够热，就把它倒在茶包上。\\\n",
    "等待一会儿，让茶叶浸泡。几分钟后，取出茶包。\\\n",
    "如果您愿意，可以加一些糖或牛奶调味。\\\n",
    "就这样，您可以享受一杯美味的茶了。\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "您将获得由三个引号括起来的文本。\\\n",
    "如果它包含一系列的指令，则需要按照以下格式重新编写这些指令：\n",
    "\n",
    "第一步 - ...\n",
    "第二步 - …\n",
    "…\n",
    "第N步 - …\n",
    "\n",
    "如果文本中不包含一系列的指令，则直接写“未提供步骤”。\"\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Text 1 的总结:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2 的总结:\n",
      "未提供步骤。\n"
     ]
    }
   ],
   "source": [
    "# Input that does not meet the conditions (no expected instructions are provided in text)\n",
    "text_2 = f\"\"\"\n",
    "今天阳光明媚，鸟儿在歌唱。\\\n",
    "这是一个去公园散步的美好日子。\\\n",
    "鲜花盛开，树枝在微风中轻轻摇曳。\\\n",
    "人们外出享受着这美好的天气，有些人在野餐，有些人在玩游戏或者在草地上放松。\\\n",
    "这是一个完美的日子，可以在户外度过并欣赏大自然的美景。\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "您将获得由三个引号括起来的文本。\\\n",
    "如果它包含一系列的指令，则需要按照以下格式重新编写这些指令：\n",
    "\n",
    "第一步 - ...\n",
    "第二步 - …\n",
    "…\n",
    "第N步 - …\n",
    "\n",
    "如果文本中不包含一系列的指令，则直接写“未提供步骤”。\"\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Text 2 的总结:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.4 Provide a few examples** (Few-shot prompting)\n",
    "\n",
    "That is, before asking the model to perform the actual task, provide it with a few examples of successful task execution.\n",
    "\n",
    "For example, in the following example, we tell the model that its task is to answer questions in a consistent style, and first give it an example of a conversation between a child and a grandfather. The child says, \"Please teach me what patience is,\" and the grandfather responds with a metaphor in the following style. Since we have already told the model to answer in a consistent tone, now we ask \"Please teach me what resilience is,\" and since the model already has this few-shot example, it will answer the next task in a similar tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Resilience is like a tree that bends with the wind but never breaks. It is the ability to bounce back from adversity and keep moving forward, even when things get tough. Just like a tree that grows stronger with each storm it weathers, resilience is a quality that can be developed and strengthened over time.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<祖父母>: 韧性就像是一棵树，它需要经历风吹雨打、寒冬酷暑，才能成长得更加坚强。在生活中，我们也需要经历各种挫折和困难，才能锻炼出韧性。记住，不要轻易放弃，坚持下去，你会发现自己变得更加坚强。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "您的任务是以一致的风格回答问题。\n",
    "\n",
    "<孩子>: 教我耐心。\n",
    "\n",
    "<祖父母>: 挖出最深峡谷的河流源于一处不起眼的泉眼；最宏伟的交响乐从单一的音符开始；最复杂的挂毯以一根孤独的线开始编织。\n",
    "\n",
    "<孩子>: 教我韧性。\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Give the model time to think\n",
    "\n",
    "If you find that the model reasoning process is too hasty and leads to wrong conclusions, you should try to rethink the prompt to require the model to carry out a **chain of thinking**, or a chain or series of relevant reasoning before providing the final answer. In other words, if you give the model a complex task that cannot be completed in a short time or with a small number of words, its output is prone to errors. This is similar to the situation for people: if you ask someone to complete a complex math problem and do not give them enough time to calculate the answer, they may also make mistakes. Therefore, in these cases, you should instruct the model to spend more time thinking about the problem and let it spend more computing resources on the task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.1 Specify the steps required to complete the task**\n",
    "\n",
    "Next, we will demonstrate the effectiveness of this strategy by giving a complex task and a series of steps to complete it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we describe the story of Jack and Jill and are given a prompt to do the following: First, summarize the text delimited by three backticks in one sentence. Second, translate the summary into French. Third, list each name in the French summary. Fourth, output a JSON object with the following keys: French summary and number of names. The output is required to be separated by newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "Two siblings, Jack and Jill, go on a quest to fetch water from a well on a hilltop, but misfortune strikes and they both tumble down the hill, returning home slightly battered but with their adventurous spirits undimmed.\n",
      "\n",
      "Deux frères et sœurs, Jack et Jill, partent en quête d'eau d'un puits sur une colline, mais un malheur frappe et ils tombent tous les deux de la colline, rentrant chez eux légèrement meurtris mais avec leurs esprits aventureux intacts. \n",
      "Noms: Jack, Jill.\n",
      "\n",
      "{\n",
      "  \"french_summary\": \"Deux frères et sœurs, Jack et Jill, partent en quête d'eau d'un puits sur une colline, mais un malheur frappe et ils tombent tous les deux de la colline, rentrant chez eux légèrement meurtris mais avec leurs esprits aventureux intacts.\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt 1:\n",
      "1-兄妹在山顶井里打水时发生意外，但仍然保持冒险精神。\n",
      "2-Dans un charmant village, les frère et sœur Jack et Jill partent chercher de l'eau dans un puits au sommet de la montagne. Malheureusement, Jack trébuche sur une pierre et tombe de la montagne, suivi de près par Jill. Bien qu'ils soient légèrement blessés, ils retournent chez eux chaleureusement. Malgré cet accident, leur esprit d'aventure ne diminue pas et ils continuent à explorer joyeusement.\n",
      "3-Jack, Jill\n",
      "4-{\n",
      "   \"French_summary\": \"Dans un charmant village, les frère et sœur Jack et Jill partent chercher de l'eau dans un puits au sommet de la montagne. Malheureusement, Jack trébuche sur une pierre et tombe de la montagne, suivi de près par Jill. Bien qu'ils soient légèrement blessés, ils retournent chez eux chaleureusement. Malgré cet accident, leur esprit d'aventure ne diminue pas et ils continuent à explorer joyeusement.\",\n",
      "   \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "在一个迷人的村庄里，兄妹杰克和吉尔出发去一个山顶井里打水。\\\n",
    "他们一边唱着欢乐的歌，一边往上爬，\\\n",
    "然而不幸降临——杰克绊了一块石头，从山上滚了下来，吉尔紧随其后。\\\n",
    "虽然略有些摔伤，但他们还是回到了温馨的家中。\\\n",
    "尽管出了这样的意外，他们的冒险精神依然没有减弱，继续充满愉悦地探索。\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "执行以下操作：\n",
    "1-用一句话概括下面用三个反引号括起来的文本。\n",
    "2-将摘要翻译成法语。\n",
    "3-在法语摘要中列出每个人名。\n",
    "4-输出一个 JSON 对象，其中包含以下键：French_summary，num_names。\n",
    "\n",
    "请用换行符分隔您的答案。\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output still has some problems, for example, the key \"Name\" will be replaced by French (Translator's note: In the original English version, the output of the third step of the corresponding instruction is 'Noms:', which is the French for Name. This behavior is unpredictable and may cause difficulties in exporting)\n",
    "\n",
    "Therefore, we improved the prompt, which keeps the first half of the prompt unchanged and **exactly specifies the format of the output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Summary: 兄妹杰克和吉尔在山顶井里打水时发生意外，但他们仍然保持冒险精神继续探索。\n",
      "Translation: Jack and Jill, deux frères et sœurs, ont eu un accident en allant chercher de l'eau dans un puits de montagne, mais ils ont continué à explorer avec un esprit d'aventure.\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\"french_summary\": \"Jack and Jill, deux frères et sœurs, ont eu un accident en allant chercher de l'eau dans un puits de montagne, mais ils ont continué à explorer avec un esprit d'aventure.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in French summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prompt 2:\n",
      "摘要：兄妹杰克和吉尔在迷人的村庄里冒险，不幸摔伤后回到家中，但仍然充满冒险精神。\n",
      "翻译：In a charming village, siblings Jack and Jill set out to fetch water from a mountaintop well. While climbing and singing, Jack trips on a stone and tumbles down the mountain, with Jill following closely behind. Despite some bruises, they make it back home safely. Their adventurous spirit remains undiminished as they continue to explore with joy.\n",
      "名称：Jack，Jill\n",
      "输出 JSON：{\"English_summary\": \"In a charming village, siblings Jack and Jill set out to fetch water from a mountaintop well. While climbing and singing, Jack trips on a stone and tumbles down the mountain, with Jill following closely behind. Despite some bruises, they make it back home safely. Their adventurous spirit remains undiminished as they continue to explore with joy.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "1-用一句话概括下面用<>括起来的文本。\n",
    "2-将摘要翻译成英语。\n",
    "3-在英语摘要中列出每个名称。\n",
    "4-输出一个 JSON 对象，其中包含以下键：English_summary，num_names。\n",
    "\n",
    "请使用以下格式：\n",
    "文本：<要总结的文本>\n",
    "摘要：<摘要>\n",
    "翻译：<摘要的翻译>\n",
    "名称：<英语摘要中的名称列表>\n",
    "输出 JSON：<带有 English_summary 和 num_names 的 JSON>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(\"\\nprompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2 Guide the model to find a solution before jumping to a conclusion**\n",
    "\n",
    "Explicitly guide the model to think of a solution before rushing to make a decision. Sometimes this will get better results. This is similar to the idea mentioned above, that is, giving the model time to think.\n",
    "\n",
    "Next, we will give a question and a student's answer, and ask the model to judge whether the answer is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学生的解决方案是正确的。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "判断学生的解决方案是否正确。\n",
    "\n",
    "问题:\n",
    "我正在建造一个太阳能发电站，需要帮助计算财务。\n",
    "\n",
    "    土地费用为 100美元/平方英尺\n",
    "    我可以以 250美元/平方英尺的价格购买太阳能电池板\n",
    "    我已经谈判好了维护合同，每年需要支付固定的10万美元，并额外支付每平方英尺10美元\n",
    "    作为平方英尺数的函数，首年运营的总费用是多少。\n",
    "\n",
    "学生的解决方案：\n",
    "设x为发电站的大小，单位为平方英尺。\n",
    "费用：\n",
    "\n",
    "    土地费用：100x\n",
    "    太阳能电池板费用：250x\n",
    "    维护费用：100,000美元+100x\n",
    "    总费用：100x+250x+100,000美元+100x=450x+100,000美元\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that the student's solution is actually wrong. (*Maintenance cost item 100x should be 10x, total cost 450x should be 360x*)\n",
    "\n",
    "We can solve this problem by instructing the model to find a solution on its own first.\n",
    "\n",
    "In the next prompt, we ask the model to solve the problem on its own first, and then compare its own solution with the student's solution to determine whether the student's solution is correct. At the same time, we give the output format requirements. By splitting the task and clarifying the steps, giving the model more time to think, sometimes more accurate results can be obtained. In this example, the student's answer is wrong, but if we don't let the model calculate it first, it may be misled into thinking that the student is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "No\n",
      "\n",
      "Student grade:\n",
      "Incorrect\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确的解决方案和步骤：\n",
      "    1. 计算土地费用：100美元/平方英尺 * x平方英尺 = 100x美元\n",
      "    2. 计算太阳能电池板费用：250美元/平方英尺 * x平方英尺 = 250x美元\n",
      "    3. 计算维护费用：10万美元 + 10美元/平方英尺 * x平方英尺 = 10万美元 + 10x美元\n",
      "    4. 计算总费用：100x美元 + 250x美元 + 10万美元 + 10x美元 = 360x + 10万美元\n",
      "\n",
      "学生的解决方案和实际解决方案是否相同：否\n",
      "\n",
      "学生的成绩：不正确\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "请判断学生的解决方案是否正确，请通过如下步骤解决这个问题：\n",
    "\n",
    "步骤：\n",
    "首先，自己解决问题，解决问题时列数学表达式。\n",
    "然后将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。\n",
    "在自己完成问题之前，请勿决定学生的解决方案是否正确。\n",
    "\n",
    "使用以下格式：\n",
    "\n",
    "问题：问题文本\n",
    "学生的解决方案：学生的解决方案文本\n",
    "实际解决方案和步骤：实际解决方案和步骤文本\n",
    "**学生的计算结果：学生的计算结果文本\n",
    "实际计算结果：实际计算结果文本\n",
    "学生的计算结果和实际计算结果是否相同：是或否\n",
    "学生的解决方案和实际解决方案是否相同：是或否**\n",
    "学生的成绩：正确或不正确\n",
    "\n",
    "问题：\n",
    "我正在建造一个太阳能发电站，需要帮助计算财务。\n",
    "- 土地费用为每平方英尺100美元\n",
    "- 我可以以每平方英尺250美元的价格购买太阳能电池板\n",
    "- 我已经谈判好了维护合同，每年需要支付固定的10万美元，并额外支付每平方英尺10美元\n",
    "作为平方英尺数的函数，首年运营的总费用是多少。\n",
    "\n",
    "学生的解决方案：\n",
    "\n",
    "设x为发电站的大小，单位为平方英尺。\n",
    "费用：\n",
    "1. 土地费用：100x\n",
    "2. 太阳能电池板费用：250x\n",
    "3. 维护费用：100,000+100x\n",
    "总费用：100x+250x+100,000+100x=450x+100,000\n",
    "\n",
    "实际解决方案和步骤：\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limitations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When developing applications for large models, please keep in mind:**\n",
    "\n",
    "**False knowledge**: Models occasionally generate knowledge that looks real but is actually made up\n",
    "\n",
    "Although the model is exposed to a lot of knowledge during training, it does not *fully* remember the information it sees, so it is not very clear about the boundaries of its knowledge. This means that it may try to answer questions about obscure topics and make up answers that sound reasonable but are actually incorrect. We call these made-up ideas hallucinations.\n",
    "\n",
    "The following example shows a hallucination of a large model. We asked for information about the *AeroGlide UltraSlim Smart Toothbrush* product produced by Boie, a real company, but a made-up product, and the model provided its made-up knowledge in a very deceptive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AeroGlide UltraSlim Smart Toothbrush by Boie is a high-tech toothbrush that uses advanced sonic technology to provide a deep and thorough clean. It features a slim and sleek design that makes it easy to hold and maneuver, and it comes with a range of smart features that help you optimize your brushing routine.\n",
      "\n",
      "One of the key features of the AeroGlide UltraSlim Smart Toothbrush is its advanced sonic technology, which uses high-frequency vibrations to break up plaque and bacteria on your teeth and gums. This technology is highly effective at removing even the toughest stains and buildup, leaving your teeth feeling clean and fresh.\n",
      "\n",
      "In addition to its sonic technology, the AeroGlide UltraSlim Smart Toothbrush also comes with a range of smart features that help you optimize your brushing routine. These include a built-in timer that ensures you brush for the recommended two minutes, as well as a pressure sensor that alerts you if you're brushing too hard.\n",
      "\n",
      "Overall, the AeroGlide UltraSlim Smart Toothbrush by Boie is a highly advanced and effective toothbrush that is perfect for anyone looking to take their oral hygiene to the next level. With its advanced sonic technology and smart features, it provides a deep and thorough clean that leaves your teeth feeling fresh and healthy.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boie公司生产的AeroGlide UltraSlim Smart Toothbrush是一款智能牙刷，具有以下特点：\n",
      "\n",
      "1. 超薄设计：刷头仅有0.8毫米的厚度，可以更容易地进入口腔深处，清洁更彻底。\n",
      "\n",
      "2. 智能感应：牙刷配备了智能感应技术，可以自动识别刷头的位置和方向，确保每个部位都得到充分的清洁。\n",
      "\n",
      "3. 高效清洁：牙刷采用了高速振动技术，每分钟可达到40000次，可以有效去除牙菌斑和污渍。\n",
      "\n",
      "4. 轻松携带：牙刷采用了便携式设计，可以轻松放入口袋或旅行包中，随时随地进行口腔清洁。\n",
      "\n",
      "5. 环保材料：牙刷采用了环保材料制造，不含有害物质，对环境友好。\n",
      "\n",
      "总之，Boie公司生产的AeroGlide UltraSlim Smart Toothbrush是一款高效、智能、环保的牙刷，可以帮助用户轻松保持口腔健康。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "告诉我 Boie 公司生产的 AeroGlide UltraSlim Smart Toothbrush 的相关信息\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is easy to mistake a fake for a real one, readers are encouraged to use what they have learned in this series of tutorials to avoid hallucinations when building their own applications. Hallucinations are a known flaw of large models (note: as of July 2023), and OpenAI is also working on addressing this issue.\n",
    "\n",
    "When you want the model to generate answers based on text, another strategy to reduce hallucinations is to first ask the model to get all the citations from the text (any relevant quotes), and then ask it to answer questions based on the quoted information. This allows us to trace the source document based on the answer, which is usually very helpful in reducing hallucinations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on the use of backslashes:**\n",
    "\n",
    "In this tutorial, we use backslashes \\ to make the text fit the screen size to improve the reading experience, instead of newline characters \\n . GPT-3 is not affected by newline characters, but when you call other large models, you need to consider whether newline characters will affect model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
