# Chapter 1 Introduction

**Author Professor Andrew Ng**

Welcome to this course where we will introduce ChatGPT prompt engineering for developers. This course is taught by Professor Isa Fulford and me. Isa is a member of the technical team at OpenAI, has developed the popular ChatGPT retrieval plugin, and has made great contributions to teaching the application of LLM (Large Language Model) technology in products. She also participated in writing the OpenAI cookbook that teaches people to use prompts.

There is a lot of material on the Internet about prompts (I will keep this term in this tutorial), such as articles like "30 prompts everyone has to know". These articles mainly focus on the web interface of ChatGPT, and many people use it to perform specific, usually one-off tasks. However, I think the more powerful feature of LLM for developers is the ability to quickly build software applications through API calls. I think this aspect has not been fully appreciated. In fact, our team at DeepLearning.AIâ€™s sister company, AI Fund, has been working with a number of startups to apply these techniques toMany applications. It's exciting to see that the LLM API allows developers to build applications very quickly.

In this course, we will share with you some tips to tap into the potential of LLM and provide best practices for application. There will be a lot of material along the way. First, you will learn prompt best practices for software development, then you will touch on several common use cases including generalization, inference, transformation and extension, and finally build a chatbot with LLM. Hopefully this will inspire your imagination to explore new applications.

As LLMs have evolved, they can be roughly divided into two types, which will be called basic LLMs and instruction tuned LLMs. Basic LLMs are models that are trained to predict the next word based on text training data. They are usually trained on large amounts of data from the Internet and other sources to determine the most likely word to appear next. For example, if you use "Once upon a time, there was a unicorn" as a prompt, the basic LLM may go on to predict "She lived in a magical forest with her unicorn friend." However, if you use "What is the capital of France" as the prompt, the basic LLM may predict the answer as "What is the largest city in France? What is the population of France?" based on the article on the Internet, because the article on the Internet is likely to be a question-and-answer topic about the country of France.List.

There is a lot of research and practice on instruction-fine-tuned LLMs, which are trained to follow instructions. So if you ask it, "What is the capital of France?", it will most likely output "The capital of France is Paris". Instruction-fine-tuned LLMs are usually trained on pre-trained LLMs, i.e., models that have been trained on a large amount of text data. They are then further trained and fine-tuned using data including inputs and ideal outputs (the inputs are instructions and the outputs are good answers to follow those instructions). They are then further improved, usually using a technique called RLHF (reinforcement learning from human feedback), to make the system more capable of helpfully following instructions.

Because instruction-fine-tuned LLMs have been trained to be helpful, honest, and harmless, they are less likely to output problematic text, such as harmful outputs, than base LLMs. Many real-world use cases have turned to instruction-fine-tuned LLMs. Some of the best practices you find on the internet may be more applicable to basic LLMs, but for most practical applications today, we recommend focusing on instruction-fine-tuned LLMs, which are easier to use and are becoming safer and more coordinated thanks to the work of OpenAI and other LLM companies.

Therefore, this course will focus onHere are some best practices for fine-tuning an LLM for instructions, which we recommend for most use cases. Before I go on, I want to thank the OpenAI and DeepLearning.ai teams for their contributions to the materials Isa and I have provided. I am very grateful to Andrew Main, Joe Palermo, Boris Power, Ted Sanders, and Lillian Weng at OpenAI, who participated in the development and review of our brainstorming materials and the development of the syllabus for this short course. I am also grateful to Geoff Ladwig, Eddy Shyu, and Tommy Nelson on Deep Learning for their work.

When you fine-tune an LLM with instructions, you can think of it as giving instructions to another person (who is smart but does not know the specific details of your task). So when an LLM doesn't work well, sometimes it's because the instructions are not clear enough. For example, if you want to ask "Please write something about Alan Turing for me", it may be more helpful to clearly indicate whether you want the text to focus on his scientific work, personal life, historical role, or other aspects. You can also specify the tone of the answer to better suit your needs. Options include *Professional journalist writing*, or *Essay written to a friend*, etc..

If you treat the LLM as a new college graduate and ask him to complete this task, you can even specify in advance which text fragments they should read to write a text about Alan Turing, which can help the new graduate to complete this task better. In the next chapter, you will see two principles for creating prompt words, one is **clear and specific**, and the other is **giving LLM time to think**.