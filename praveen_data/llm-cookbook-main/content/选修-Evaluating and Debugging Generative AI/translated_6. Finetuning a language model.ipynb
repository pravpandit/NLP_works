{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfae479-9399-492d-acaa-d9751615ee86",
   "metadata": {
    "id": "1dfae479-9399-492d-acaa-d9751615ee86",
    "tags": []
   },
   "source": [
    "# Chapter 6 Fine-tuning the language model\n",
    "\n",
    "- [I. Importance of fine-tuning the language model](#I.-Importance of fine-tuning the language model)\n",
    "- [II. Fine-tuning the language model using Hugging Face](#II.-Using-Hugging-Face-Fine-tuning the language model)\n",
    "- [2.1 Data processing](#2.1--Data processing)\n",
    "- [2.2 Model training](#2.2-Model training)\n",
    "- [III. Real-time viewing and analysis of model training results](#III.-Real-time viewing and analysis of model training results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80133889",
   "metadata": {
    "id": "80133889"
   },
   "source": [
    "## 1. The Importance of Fine-tuning Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c1725",
   "metadata": {},
   "source": [
    "![compare-method.png](../../figures/compare-method.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b15293",
   "metadata": {
    "id": "60b15293"
   },
   "source": [
    "Training a language model from scratch is time-consuming and resource-intensive, and evaluating these models is equally complex and resource-intensive. Therefore, it is important to keep a close eye on the training process and use `checkpoints` to properly respond to unexpected issues that may arise. The dashboard (`dashboard`) is a valuable tool that can display the progress and metrics of training and provide `checkpoints` when needed. This can help you understand the performance of the model in a timely manner and ensure that the training process is smooth.\n",
    "\n",
    "Fine-tuning a language model is a more cost-effective way to optimize, especially when computing resources are limited. However, caution still needs to be exercised during the evaluation process. Depending on the goals of using the language model, you can develop an appropriate evaluation strategy to ensure that the model reaches the desired performance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28313d52",
   "metadata": {
    "id": "28313d52"
   },
   "source": [
    "## 2. Fine-tune a language model using Hugging Face\n",
    "\n",
    "In this course, we will show how to fine-tune a language model using Hugging Face. To do this efficiently on the CPU, we will use a small language model called `TinyStories`, which has 33 million parameters. We will fine-tune this lightweight model on a dataset of character backstories from the Dungeons & Dragons game world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f0e67f",
   "metadata": {
    "height": 149,
    "id": "a1f0e67f"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import transformers\n",
    "transformers.set_seed(42)\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79c25e3-5f18-4457-84e1-ed2c0d262222",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "f79c25e3-5f18-4457-84e1-ed2c0d262222",
    "outputId": "114817d7-e8e4-49f8-f13e-9aca370cf89d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-moose-980007700204230807\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1b5e0",
   "metadata": {},
   "source": [
    "AutoClasses guesses the architecture to use from the name or path of a pretrained model provided to the from_pretrained() method.\n",
    "\n",
    "AutoConfig, AutoModel, and AutoTokenizer can automatically retrieve the relevant model based on the name/path.\n",
    "\n",
    "- Remote: root-level representation in the huggingface.co repository, such as bert-base-uncased, or namespaced under a user or organization name, such as roneneldan/TinyStories-33M\n",
    "- Local: the directory saved with the save_pretrained() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2286ae41-213d-480d-a4ba-8c4e2e1c4771",
   "metadata": {
    "height": 30,
    "id": "2286ae41-213d-480d-a4ba-8c4e2e1c4771"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"roneneldan/TinyStories-33M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd80268-c4a1-4e1a-aed3-cd5c3ab4d48f",
   "metadata": {
    "id": "3fd80268-c4a1-4e1a-aed3-cd5c3ab4d48f"
   },
   "source": [
    "### 2.1 Data Processing\n",
    "\n",
    "First, we will load a dataset containing the backstories of Dungeons & Dragons characters from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7535b8b-d220-44e8-a56c-97e250c36596",
   "metadata": {
    "height": 30,
    "id": "a7535b8b-d220-44e8-a56c-97e250c36596"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset('MohamedRashad/characters_backstories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13caeb7f-8a07-4ca2-a770-5b627238c2ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "13caeb7f-8a07-4ca2-a770-5b627238c2ac",
    "outputId": "3c3e8c39-da3c-4bd4-b49e-8753104ca66f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Generate Backstory based on following information\\nCharacter Name: Dewin \\nCharacter Race: Halfling\\nCharacter Class: Sorcerer bard\\n\\nOutput:\\n',\n",
       " 'target': 'Dewin thought he was a wizard, but it turned out it was the draconic blood in his veins that brought him eldritch power.  Music classes in wizarding college taught him yet another use for his power, and when he was expelled he took up adventuring'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at an example\n",
    "ds[\"train\"][400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1XC0CU0Sidb",
   "metadata": {
    "id": "z1XC0CU0Sidb"
   },
   "source": [
    "This dataset contains two columns: one is the text, which requires the model to generate a background story; the other is the target, which stores the character's background story.\n",
    "\n",
    "We will split the dataset to create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dae9106-8015-43da-a6d9-1124dee4bdde",
   "metadata": {
    "height": 47,
    "id": "7dae9106-8015-43da-a6d9-1124dee4bdde"
   },
   "outputs": [],
   "source": [
    "# Since this dataset does not have a pre-split validation set, we need to create one ourselves\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R3jGH1eRLPGu",
   "metadata": {
    "id": "R3jGH1eRLPGu"
   },
   "source": [
    "Before training the model, we need to concatenate the text (character information) and target (background story) and make sure they are properly segmented and padded.\n",
    "\n",
    "During this process, the Hugging Face framework automatically assigns the corresponding correct label to each input token and uses it for model training. Since the model needs to predict the next token in the sequence, Hugging Face automatically uses the original content as the label and moves these labels one position to the right so that the model can correctly predict the next token in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f42f7",
   "metadata": {},
   "source": [
    "[AutoTokenizer](https://huggingface.co/learn/nlp-course/zh-CN/chapter6/1?fw=pt) will help us get the tokenizer corresponding to the pre-trained model so that the model processing expectations are consistent with those during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea1602d-504b-43de-87ad-fcb35b9e61f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77,
     "referenced_widgets": [
      "392a389d2b3e4469a4d97e25905db827",
      "2687806020864ec8a02e9c237b168a1b",
      "e7b21c44f91d41acbeeb9a5b756de8db",
      "e844acd81ba64610b5a489d678ca83ec",
      "b0e68cd5eef94c87b9d694777f4d4bd6",
      "efc62b9109b64216b0e1463c4aad5edf",
      "67c75cf288834525a38d4779d9344515",
      "ac69ce5800a44e2e88ac6e0db675f770",
      "008d4419e82f46be82d2a5f50ba1bd86",
      "a6768ce6f36740f39bd3866ffb6339fe",
      "98928bfce80146d889963509e0d43f88"
     ]
    },
    "height": 268,
    "id": "7ea1602d-504b-43de-87ad-fcb35b9e61f7",
    "outputId": "a424c9de-3452-42fa-f60a-ccf056a1d104"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392a389d2b3e4469a4d97e25905db827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will create a tokenizer from the model checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=False)\n",
    "\n",
    "# We need to pad the samples so that we have sequences of the same length in the batch\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# First concatenate the text and the target. Then use the tokenizer to tokenize the concatenated string.\n",
    "def tokenize_function(example):\n",
    "    merged = example[\"text\"] + \" \" + example[\"target\"]\n",
    "    batch = tokenizer(merged, padding='max_length', truncation=True, max_length=128)\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "    return batch\n",
    "\n",
    "# Apply this to our dataset and remove the text columns\n",
    "tokenized_datasets = ds.map(tokenize_function, remove_columns=[\"text\", \"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9288a8e-b19b-4bd2-a72c-7dda03632282",
   "metadata": {
    "id": "c9288a8e-b19b-4bd2-a72c-7dda03632282"
   },
   "source": [
    "> You may get some warnings here, that's okay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62488d0c",
   "metadata": {
    "id": "62488d0c"
   },
   "source": [
    "Before we start training the model, we will verify the quality of the generated samples to make sure everything is working fine. When we decode the output, you will first see some instructions, followed by the generated background story. If everything looks good, we can continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42417b8-ffa8-4d96-92ea-d8d949d87d5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "a42417b8-ffa8-4d96-92ea-d8d949d87d5e",
    "outputId": "20b687ad-bae8-4052-d4e8-23d29e5a6a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Backstory based on following information\n",
      "Character Name: Mr. Gale\n",
      "Character Race: Half-orc\n",
      "Character Class: Cleric\n",
      "\n",
      "Output:\n",
      " Growing up the only half-orc in a small rural town was rough. His mother didn't survive childbirth and so was raised in a church in a high mountain pass, his attention was always drawn by airships passing through, and dreams of an escape. Leaving to strike out on his own as early as he could he made a living for most of his life as an airship sailor, and occasionally a pirate. A single storm visits him throughout his life, marking every major\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a prepared example\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][900]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d6b17-a63d-41f1-92cf-416064b52156",
   "metadata": {
    "id": "2e8d6b17-a63d-41f1-92cf-416064b52156"
   },
   "source": [
    "### 2.2 Model Training\n",
    "We will use Hugging Face's Transformers, and its wandb integration to fine-tune a pre-trained language model on the dataset.\n",
    "\n",
    "The model we create is for causal language modeling, which means it is an autoregressive language model, similar to GPT. Its task is to predict the next word in a sequence. We will start a new Weights & Biases run with the job type set to training. Next, we need to define some training parameters, such as the number of training epochs, learning rate, weight decay, and very importantly, we will set up `wandb` as a reporting mechanism. This means that all your results will be brought together in the same centralized dashboard. This is all you need to do to ensure a flowing display of metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb6f719",
   "metadata": {},
   "source": [
    "[AutoModelForCausalLM](https://huggingface.co/learn/nlp-course/zh-CN/chapter2/3) will automatically load the corresponding causal language model from the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f131eb-979e-40f6-9e28-19756beaa8e4",
   "metadata": {
    "height": 47,
    "id": "b4f131eb-979e-40f6-9e28-19756beaa8e4"
   },
   "outputs": [],
   "source": [
    "# We will train a causal (autoregressive) language model based on the pre-trained checkpoints\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7345ab23-8d12-4d4c-a39d-bb2202bff218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "height": 47,
    "id": "7345ab23-8d12-4d4c-a39d-bb2202bff218",
    "outputId": "419b1376-d8c8-41ee-cb1c-614a239bd86a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20230813_134429-8o77rmiz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">sandy-river-2</a></strong> to <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start a new wandb run\n",
    "run = wandb.init(project='dlai_lm_tuning', job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74ee155-3c30-4ef2-9c4d-fd8ee222c50c",
   "metadata": {
    "height": 217,
    "id": "d74ee155-3c30-4ef2-9c4d-fd8ee222c50c"
   },
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-characters-backstories\",\n",
    "    report_to=\"wandb\", # 我们需要一行来跟踪 wandb 中的实验\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    no_cuda=True, # 强制使用 CPU，将改为 use_cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af62105f-a478-436f-88a2-5c1d78b9d20a",
   "metadata": {
    "height": 132,
    "id": "af62105f-a478-436f-88a2-5c1d78b9d20a"
   },
   "outputs": [],
   "source": [
    "# We will use HF Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01958a56-c22a-4a27-bc71-41c59fc97f05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "height": 47,
    "id": "01958a56-c22a-4a27-bc71-41c59fc97f05",
    "outputId": "0e6a2ddb-a6f4-4a7a-85b7-deb77e7e657f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='233' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [233/233 31:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.804500</td>\n",
       "      <td>3.350718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=233, training_loss=3.7419421836541957, metrics={'train_runtime': 1912.6777, 'train_samples_per_second': 0.971, 'train_steps_per_second': 0.122, 'total_flos': 40423258718208.0, 'train_loss': 3.7419421836541957, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5eb6e0",
   "metadata": {
    "id": "7d5eb6e0"
   },
   "source": [
    "## 3. Real-time viewing and analysis of model training results\n",
    "\n",
    "During the model training process, we can view the results in real time by clicking on the link. Over time, we can observe the changes in various indicators. Among them, the indicator we are most concerned about is the training loss, and we will continue to pay attention to its changing trend. When debugging the model training run, it is very useful to check whether the loss continues to decrease. Therefore, you want to see this curve move down and to the right.\n",
    "\n",
    "For some very large language models, training may take days or even weeks. Therefore, it is very helpful to have a function that can view the chart remotely. This ensures that our model continues to improve and effectively utilizes GPU resources to avoid waste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fce60d",
   "metadata": {},
   "source": [
    "![charts.png](../../figures/charts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ec04d",
   "metadata": {},
   "source": [
    "| loss0| loss1 \n",
    "|:------:|:------:|\n",
    "| ![loss0](../../figures/loss0.png) | ![loss1](../../figures/loss1.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf53a5",
   "metadata": {
    "id": "73cf53a5"
   },
   "source": [
    "After training the model, we will use it to generate samples. We define some prompts and use them to generate background stories for our characters. Next, we create a new table to record the generated results. Call `model.generate` on each prompt to generate the corresponding text. We can pass various parameters here, such as `top_p` or temperature coefficient (`temperature`) to guide model generation. The generated results are added to the table and finally recorded in `wandb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7911e43f-f4ce-4855-9f68-662438af8d24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 336,
    "id": "7911e43f-f4ce-4855-9f68-662438af8d24",
    "outputId": "e642ca95-4ec7-47e4-c248-dc5ebd4ac9a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error() # 抑制 tokenizer 警告\n",
    "\n",
    "prefix = \"Generate Backstory based on following information Character Name: \"\n",
    "\n",
    "prompts = [\n",
    "    \"Frogger Character Race: Aarakocra Character Class: Ranger Output: \",\n",
    "    \"Smarty Character Race: Aasimar Character Class: Cleric Output: \",\n",
    "    \"Volcano Character Race: Android Character Class: Paladin Output: \",\n",
    "]\n",
    "\n",
    "table = wandb.Table(columns=[\"prompt\", \"generation\"])\n",
    "# Call \"model.generate\" on each prompt to generate the corresponding text.\n",
    "for prompt in prompts:\n",
    "    input_ids = tokenizer.encode(prefix + prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids, do_sample=True, max_new_tokens=50, top_p=0.3)\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    table.add_data(prefix + prompt, output_text)\n",
    "\n",
    "wandb.log({'tiny_generations': table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7caafaf-dfb7-413d-a329-8520aea5f73a",
   "metadata": {
    "id": "a7caafaf-dfb7-413d-a329-8520aea5f73a"
   },
   "source": [
    "**NOTE**: LLM does not always generate the same results. Your generated character and backstory may differ from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3083c6a3-fdb8-44ab-a028-c0a222a2fdef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 956,
     "referenced_widgets": [
      "267e282e0a0f4c4f83a46898804199c4",
      "c87dda5bd52c45ac861bea6cf6d10a7a",
      "79fe43a750624fc5b0c8b524c9bb4fde",
      "c39faa4d0eed4c6b9788bcbe0d73dac4",
      "6af93ffbbf404a5da28e1d7115291083",
      "4002ea385a98418dbfd509c22f520f72",
      "27df8e9973d045e691a18328c6779b3b",
      "1668bbfb2e6d4705987149a9928de48f"
     ]
    },
    "height": 30,
    "id": "3083c6a3-fdb8-44ab-a028-c0a222a2fdef",
    "outputId": "5a07bdd1-9ece-40cd-ec05-278fbf2d43b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267e282e0a0f4c4f83a46898804199c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.655475…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▃▃▂▃▃▃▂▂▃▃▂▃▂▂▃▃▂▃▂▂▂▂▃▃▂▃▂▂▂▂▁▂▂▁▂▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.35072</td></tr><tr><td>eval/runtime</td><td>158.3652</td></tr><tr><td>eval/samples_per_second</td><td>2.936</td></tr><tr><td>eval/steps_per_second</td><td>0.373</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>233</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.8045</td></tr><tr><td>train/total_flos</td><td>40423258718208.0</td></tr><tr><td>train/train_loss</td><td>3.74194</td></tr><tr><td>train/train_runtime</td><td>1912.6777</td></tr><tr><td>train/train_samples_per_second</td><td>0.971</td></tr><tr><td>train/train_steps_per_second</td><td>0.122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-river-2</strong> at: <a href='https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88' target=\"_blank\">https://wandb.ai/anony-moose-980007700204230807/dlai_lm_tuning/runs/8o77rmiz?apiKey=cadfeaf15a42dc5744f2716fd33a69a37a35ac88</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230813_134429-8o77rmiz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f48e73",
   "metadata": {
    "id": "f0f48e73"
   },
   "source": [
    "We can see the prompts and the generated samples in the dashboard. From this, we can observe that there are some issues with this small model. This is understandable because we tuned it to optimize for speed rather than performance. From the messages and outputs you provided, you can tell whether the model is performing well or not. We encourage you to come up with metrics that may be relevant to your specific use case, implement them, and record them. For example, you could measure the number of unique words. In the sample generated by the third prompt, we can see that it only uses three words, namely `the tribe of`. This may not be a very good output.\n",
    "\n",
    "So the next time you train or fine-tune your model, we hope that you can take advantage of these tools to get better results faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3bfcc-2885-4eb8-8a18-a236c69e1a98",
   "metadata": {
    "height": 30,
    "id": "dfa3bfcc-2885-4eb8-8a18-a236c69e1a98"
   },
   "source": [
    "![tiny-generations.png](../../figures/tiny-generations.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008d4419e82f46be82d2a5f50ba1bd86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1668bbfb2e6d4705987149a9928de48f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "267e282e0a0f4c4f83a46898804199c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c87dda5bd52c45ac861bea6cf6d10a7a",
       "IPY_MODEL_79fe43a750624fc5b0c8b524c9bb4fde"
      ],
      "layout": "IPY_MODEL_c39faa4d0eed4c6b9788bcbe0d73dac4"
     }
    },
    "2687806020864ec8a02e9c237b168a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efc62b9109b64216b0e1463c4aad5edf",
      "placeholder": "​",
      "style": "IPY_MODEL_67c75cf288834525a38d4779d9344515",
      "value": "Map: 100%"
     }
    },
    "27df8e9973d045e691a18328c6779b3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "392a389d2b3e4469a4d97e25905db827": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2687806020864ec8a02e9c237b168a1b",
       "IPY_MODEL_e7b21c44f91d41acbeeb9a5b756de8db",
       "IPY_MODEL_e844acd81ba64610b5a489d678ca83ec"
      ],
      "layout": "IPY_MODEL_b0e68cd5eef94c87b9d694777f4d4bd6"
     }
    },
    "4002ea385a98418dbfd509c22f520f72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67c75cf288834525a38d4779d9344515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6af93ffbbf404a5da28e1d7115291083": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79fe43a750624fc5b0c8b524c9bb4fde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27df8e9973d045e691a18328c6779b3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1668bbfb2e6d4705987149a9928de48f",
      "value": 1
     }
    },
    "98928bfce80146d889963509e0d43f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6768ce6f36740f39bd3866ffb6339fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac69ce5800a44e2e88ac6e0db675f770": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0e68cd5eef94c87b9d694777f4d4bd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c39faa4d0eed4c6b9788bcbe0d73dac4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c87dda5bd52c45ac861bea6cf6d10a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6af93ffbbf404a5da28e1d7115291083",
      "placeholder": "​",
      "style": "IPY_MODEL_4002ea385a98418dbfd509c22f520f72",
      "value": "0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "e7b21c44f91d41acbeeb9a5b756de8db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac69ce5800a44e2e88ac6e0db675f770",
      "max": 465,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_008d4419e82f46be82d2a5f50ba1bd86",
      "value": 465
     }
    },
    "e844acd81ba64610b5a489d678ca83ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6768ce6f36740f39bd3866ffb6339fe",
      "placeholder": "​",
      "style": "IPY_MODEL_98928bfce80146d889963509e0d43f88",
      "value": " 465/465 [00:01&lt;00:00, 432.95 examples/s]"
     }
    },
    "efc62b9109b64216b0e1463c4aad5edf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
