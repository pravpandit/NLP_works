{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a786c77c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# अध्याय 3 भंडारण\n",
    "\n",
    "- [1. ओपनएआई एपीआई कुंजी सेट करें](#1. ओपनएआई-एपीआई-कुंजी सेट करें)\n",
    "- [2. डायलॉग कैश स्टोरेज](#2. डायलॉग कैश स्टोरेज)\n",
    "- [2.1 अंग्रेजी संस्करण](#2.1-अंग्रेजी संस्करण)\n",
    "- [2.1.1 इनिशियलाइज़ डायलॉग मॉडल](#2.1.1-इनिशियलाइज़ डायलॉग मॉडल)\n",
    "- [2.1.2 पहले दौर का संवाद](#2.1.2-पहले दौर का संवाद)\n",
    "- [2.1.3 दूसरे दौर का संवाद](#2.1.3-दूसरे दौर का संवाद)\n",
    "- [2.1.4 तीसरे दौर का संवाद](#2.1.4-तीसरे दौर का संवाद)\n",
    "- [2.1.5 व्यू स्टोरेज कैश](#2.1.5-व्यू स्टोरेज कैश)\n",
    "- [2.1.6 सामग्री जोड़ेंसीधे स्टोरेज कैश में प्रवेश करें](#2.1.6-सामग्री को सीधे स्टोरेज कैश में जोड़ें)\n",
    "- [2.2 चीनी संस्करण](#2.2-चीनी संस्करण)\n",
    "- [2.1.1 संवाद मॉडल आरंभ करें](#2.1.1- संवाद मॉडल आरंभ करें)\n",
    "- [2.1.2 संवाद का पहला दौर](#2.1.2-संवाद का पहला दौर)\n",
    "- [2.1.3 वार्ता का दूसरा दौर](#2.1.3-संवाद का दूसरा दौर)\n",
    "- [2.1.4 वार्ता का तीसरा दौर](#2.1.4-संवाद का तीसरा दौर)\n",
    "- [2.1.5 स्टोरेज कैश देखें](#2.1.5-स्टोरेज कैश देखें)\n",
    "- [2.1.6 सामग्री को सीधे स्टोरेज में जोड़ें सीदर्द](#2.1.6-सामग्री को सीधे स्टोरेज कैश में जोड़ें)\n",
    "- [2.3 सारांश](#2.3-सारांश)\n",
    "- [तीन, डायलॉग कैश विंडो स्टोरेज](#तीन, डायलॉग कैश विंडो स्टोरेज)\n",
    "- [3.1 अंग्रेजी संस्करण](#3.1-अंग्रेजी संस्करण)\n",
    "- [3.1.1 विंडो स्टोरेज में संवाद के दो राउंड जोड़ें](#3.1.1-विंडो स्टोरेज में डायलॉग के दो राउंड जोड़ें)\n",
    "- [3.1.2 संवाद श्रृंखला में विंडो स्टोरेज लागू करें](#3.1.2-संवाद श्रृंखला में विंडो स्टोरेज लागू करें)\n",
    "- [3.2 चीनी संस्करण](#3.2-चीनी संस्करण)\n",
    "- [3.1.1 बातचीत के दो दौर जोड़ेंo विंडो स्टोरेज](#3.1.1-विंडो स्टोरेज में बातचीत के दो दौर जोड़ें)\n",
    "- [3.1.2 वार्तालाप श्रृंखला में विंडो स्टोरेज लागू करें](#3.1.2-वार्तालाप श्रृंखला में विंडो स्टोरेज लागू करें)\n",
    "- [IV. वार्तालाप टोकन कैश संग्रहण](#IV. वार्तालाप टोकन कैश संग्रहण)\n",
    "- [4.1 अंग्रेजी संस्करण](#4.1-अंग्रेजी संस्करण)\n",
    "- [4.2 चीनी संस्करण](#4.2-चीनी संस्करण)\n",
    "- [4.3 अनुपूरक](#4.3-पूरक)\n",
    "- [वी. वार्तालाप सारांश कैश संग्रहण](#वी. वार्तालाप सारांश कैश संग्रहण)\n",
    "- [5.1 अंग्रेजी संस्करण](#5.1-ईअंग्रेजी संस्करण)\n",
    "- [5.1.1 वार्तालाप सारांश कैश संग्रहण का उपयोग करें](#5.1.1-वार्तालाप सारांश कैश संग्रहण का उपयोग करें)\n",
    "- [5.1.2 वार्तालाप सारांश कैश संग्रहण पर आधारित वार्तालाप श्रृंखला](#5.1.2-बातचीत सारांश कैश संग्रहण पर आधारित वार्तालाप श्रृंखला)\n",
    "- [5.2 चीनी संस्करण](#5.2-चीनी संस्करण)\n",
    "- [5.2.1 वार्तालाप सारांश कैश संग्रहण का उपयोग करें](#5.2.1-वार्तालाप सारांश कैश संग्रहण का उपयोग करें)\n",
    "- [5.1.2 वार्तालाप श्रृंखला वार्तालाप सारांश कैश संग्रहण पर आधारित](#5.1.2-बातचीत श्रृंखला आधारवार्तालाप सारांश कैश संग्रहण पर संपादित)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10db6f",
   "metadata": {},
   "source": [
    "जब आप उन भाषा मॉडलों के साथ बातचीत करते हैं, तो उन्हें याद नहीं रहता कि आपने उनके साथ पहले क्या संचार किया था, जो एक बड़ी समस्या है जब हम कुछ एप्लिकेशन (जैसे चैटबॉट) बनाते हैं - इसलिए, इसमें यह पर्याप्त स्मार्ट नहीं लगता है! अनुभाग में हम लैंगचेन में स्टोरेज मॉड्यूल पेश करेंगे, यानी, पिछली बातचीत को भाषा मॉडल में कैसे एम्बेड करें ताकि इसमें निरंतर बातचीत की क्षमता हो।\n",
    "\n",
    "लैंगचेन में स्टोरेज (मेमोरी) मॉड्यूल का उपयोग करते समय, यह सहेजने और प्रबंधित करने में मदद कर सकता हैऐतिहासिक चैट संदेश, साथ ही विशिष्ट संस्थाओं के बारे में ज्ञान का निर्माण करते हैं। ये घटक बातचीत के कई दौरों में जानकारी संग्रहीत कर सकते हैं और बातचीत के दौरान विशिष्ट जानकारी और संदर्भ को ट्रैक करने की अनुमति दे सकते हैं।\n",
    "\n",
    "लैंगचेन कई स्टोरेज प्रकार प्रदान करता है, उनमें से बफर स्टोरेज सबसे हालिया चैट संदेशों को बनाए रखने की अनुमति देता है, और सारांश स्टोरेज संपूर्ण वार्तालाप का सारांश प्रदान करता है जो विशिष्ट संस्थाओं के बारे में जानकारी को बनाए रखने की अनुमति देता हैबातचीत के कई दौरों में डी। ये मेमोरी घटक मॉड्यूलर हैं और रोबोट की वार्तालाप प्रबंधन क्षमताओं को बढ़ाने के लिए अन्य घटकों के साथ संयोजन में उपयोग किया जा सकता है। स्टोरेज मॉड्यूल को सरल एपीआई कॉल के माध्यम से एक्सेस और अपडेट किया जा सकता है, जिससे डेवलपर्स को अधिक आसानी से प्रबंधन और रखरखाव करने की अनुमति मिलती है बातचीत का इतिहास।\n",
    "\n",
    "यह पाठ्यक्रम मुख्य रूप से चार स्टोरेज मॉड्यूल का परिचय देता है, और अन्य मॉड्यूल को सीखने के लिए दस्तावेज़ में देखा जा सकता है।\n",
    "- वार्तालाप बफर मेमोरी\n",
    "- बातचीतबफ़रविंडोमेमोरीपर बफ़रविंडोमेमोरी)\n",
    "- वार्तालाप टोकन बफर मेमोरी\n",
    "- वार्तालाप सारांश बफ़र मेमोरी\n",
    "\n",
    "लैंगचेन में, स्टोरेज बड़े भाषा मॉडल (एलएलएम) की अल्पकालिक मेमोरी को संदर्भित करता है। यह अल्पकालिक मेमोरी क्यों है? ऐसा इसलिए है क्योंकि एलएलएम प्रशिक्षित होने के बाद (कुछ दीर्घकालिक मेमोरी प्राप्त होती है), इसके पैरामीटर नहीं बदलेंगे उपयोगकर्ता इनपुट के कारण जब उपयोगकर्ता प्रशिक्षित एलएलएम से बात करता है, तो एलएलएम अस्थायी रूप से उपयोगकर्ता के इनपुट और उसके द्वारा उत्पन्न आउटपुट को याद रखेगा।बाद के आउटपुट की भविष्यवाणी करें, और मॉडल आउटपुट पूरा होने के बाद, यह पिछले उपयोगकर्ता के इनपुट और उसके आउटपुट को \"भूल\" जाएगा, इसलिए इस जानकारी को केवल एलएलएम की अल्पकालिक मेमोरी कहा जा सकता है।\n",
    "\n",
    "एलएलएम अल्पकालिक मेमोरी के अवधारण समय को बढ़ाने के लिए, इसे याद रखने के लिए कुछ बाहरी भंडारण विधियों का उपयोग करना आवश्यक है, ताकि जब उपयोगकर्ता एलएलएम से बात करता है, तो एलएलएम ऐतिहासिक बातचीत के बारे में जितना संभव हो उतना जान सके। उपयोगकर्ता और उसके बीच की जानकारी।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca56e6b-1e07-4405-a1ca-f4237f20fa75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. OpenAI API कुंजी सेट करें\n",
    "\n",
    "एपीआई कुंजी प्राप्त करने के लिए [ओपनएआई खाते] (https://platform.openai.com/account/api-keys) में लॉग इन करें, और फिर इसे एक पर्यावरण चर के रूप में सेट करें।\n",
    "\n",
    "- यदि आप इसे वैश्विक पर्यावरण चर के रूप में सेट करना चाहते हैं, तो आप [ज़िहु लेख] (https://zhuanlan.zhihu.com/p/627665725) का संदर्भ ले सकते हैं।\n",
    "\n",
    "- यदि आप इसे स्थानीय/प्रोजेक्ट पर्यावरण चर के रूप में सेट करना चाहते हैं, तो इस फ़ाइल निर्देशिका में एक `.env` फ़ाइल बनाएं, फ़ाइल खोलें और निम्नलिखित सामग्री दर्ज करें।\n",
    "\n",
    "<p style='font-family:verdana; फ़ॉन्ट-आकार:12px;colया:हरा\">\n",
    "OPENAI_API_KEY='आपका_api_key'\n",
    "</p>\n",
    "\n",
    "\"your_api_key\" को अपनी स्वयं की API कुंजी से बदलें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932bd47-c6d5-4794-8102-a12b84412a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# आवश्यक पैकेज Python-dotenv और openai डाउनलोड करें\n",
    "# यदि आपको इंस्टॉलेशन प्रक्रिया लॉग देखने की आवश्यकता है, तो आप -q हटा सकते हैं\n",
    "!pip install -q python-dotenv\n",
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10446712-9fa6-4d71-94ce-2ea4cf197e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# स्थानीय/परियोजना पर्यावरण चर पढ़ें।\n",
    "\n",
    "# find_dotenv() .env फ़ाइल का पथ ढूंढता है और उसका पता लगाता है\n",
    "#load_dotenv() .env फ़ाइल को पढ़ता है और उसमें मौजूद पर्यावरण चर को वर्तमान चल रहे वातावरण में लोड करता है\n",
    "# यदि आप एक वैश्विक पर्यावरण चर सेट करते हैं, तो कोड की इस पंक्ति का कोई प्रभाव नहीं पड़ेगा।\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# पर्यावरण चर OPENAI_API_KEY प्राप्त करें\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297dcd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. वार्तालाप कैश संग्रहण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8cd26-45c5-4bae-90b2-b07d23bf3bb2",
   "metadata": {},
   "source": [
    "### 2.1 अंग्रेजी संस्करण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e77a3d-7aaa-48c1-b219-19bd6f4eb674",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.1 संवाद मॉडल प्रारंभ करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20ad6fe2",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88bdf13d",
   "metadata": {
    "height": 133
   },
   "outputs": [],
   "source": [
    "# यहां हमने उत्पन्न उत्तरों की यादृच्छिकता को कम करने के लिए पैरामीटर तापमान को 0.0 पर सेट किया है।\n",
    "# अगर आप हर बार अलग और इनोवेटिव जवाब पाना चाहते हैं तो इस पैरामीटर को बढ़ाकर देख सकते हैं।\n",
    "llm = ChatOpenAI(temperature=0.0)  \n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# एक नया कन्वर्सेशनचेन क्लास इंस्टेंस बनाएं\n",
    "# जब वर्बोज़ पैरामीटर को सही पर सेट किया जाता है, तो प्रोग्राम अधिक डिबगिंग या रनटाइम जानकारी प्रदान करने के लिए अधिक विस्तृत जानकारी आउटपुट करेगा।\n",
    "# इसके विपरीत, जब वर्बोज़ पैरामीटर को गलत पर सेट किया जाता है, तो प्रोग्राम अधिक संक्षिप्त तरीके से चलेगा और केवल कुंजी जानकारी आउटपुट करेगा।\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea83837",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.2 संवाद का पहला दौर"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b4c42",
   "metadata": {},
   "source": [
    "जब हमने भविष्यवाणी (<font style='font-family:verdana;font-size:13.5px;color:#0055AA'>predict</font>) चलाई, तो कुछ संकेत उत्पन्न हुए, जैसा कि आप नीचे देख सकते हैं, उन्होंने कहा \"निम्नलिखित एक मानव और एक एआई के बीच एक दोस्ताना बातचीत है, एआई बातूनी है\" और इसी तरह, यह वास्तव में सिस्टम को एक आशावादी और मैत्रीपूर्ण बातचीत बनाने के लिए लैंगचेन द्वारा उत्पन्न संकेत है, और बातचीत अवश्य होनी चाहिए सहेजा जाए, और वर्तमान पूर्ण मॉडल श्रृंखला के लिए संकेत।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db24677d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71564ad",
   "metadata": {},
   "source": [
    "#### 2.1.3 संवाद का दूसरा दौर"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d006bd",
   "metadata": {},
   "source": [
    "जब हमारी बातचीत का दूसरा दौर होगा, तो यह उपरोक्त संकेत देगा"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc3ef937",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb734b",
   "metadata": {},
   "source": [
    "#### 2.1.4 संवाद का तीसरा दौर"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393df3d",
   "metadata": {},
   "source": [
    "यह सत्यापित करने के लिए कि क्या उसे पिछली बातचीत याद है, हमने उससे (मेरा नाम) पहले कही गई बात का उत्तर देने के लिए कहा, हम देख सकते हैं कि उसने सही नाम दिया है, इसलिए यह बातचीत श्रृंखला जैसे-जैसे आगे बढ़ती जाएगी, लंबी होती जाएगी ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acf3339a",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 is equal to 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96a8d9",
   "metadata": {},
   "source": [
    "#### 2.1.5 स्टोरेज कैश देखें\n",
    "\n",
    "संग्रहण कैश (<font style='font-family:verdana; फ़ॉन्ट-आकार:13.5px'>मेमोरी।</font><font style='font-family:verdana; फ़ॉन्ट-आकार:13.5px;रंग:#0055AA \">बफर</font>)\n",
    "अब तक की सभी बातचीत की जानकारी संग्रहीत करता है"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2529400d",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 is equal to 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5de846",
   "metadata": {},
   "source": [
    "लोड_मेमोरी_वेरिएबल्स({}) के साथ कैश में संदेशों के इतिहास को प्रिंट करना भी संभव है। यहां {} एक खाली शब्दकोश है, कुछ और उन्नत सुविधाएं हैं जो उपयोगकर्ता को अधिक जटिल इनपुट का उपयोग करने की अनुमति देती हैं, लेकिन हम ऐसा नहीं करेंगे। इस संक्षिप्त पाठ्यक्रम में उन पर चर्चा करें, इसलिए इस बात की चिंता न करें कि यहां एक खाली घुंघराले ब्रेस क्यों है।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5018cb0a",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1?\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Andrew.\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2e892",
   "metadata": {},
   "source": [
    "#### 2.1.6 सामग्री को सीधे स्टोरेज कैश में जोड़ें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14219b70",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()  # 新建一个空的对话缓存记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a36e9905",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})  # 向缓存区添加指定对话的输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61631b1f",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)  # 查看缓存区结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2fdf9ec",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi\\nAI: What's up\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))# 再次加载记忆变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac544f2",
   "metadata": {},
   "source": [
    "नई सामग्री जोड़ना जारी रखें, और वार्तालाप इतिहास सहेजा जाएगा!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ca79256",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "890a4497",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddd91a-bf1c-4b82-b99c-c585420e4ecb",
   "metadata": {},
   "source": [
    "### 2.2 चीनी संस्करण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3e4e9-7a6a-4a09-9ac3-0096a67849c7",
   "metadata": {},
   "source": [
    "#### 2.1.1 संवाद मॉडल प्रारंभ करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3577aaff-7edb-40b0-866a-e407e63d55e0",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a77d37ab-1f75-4ae8-8d7c-5066773ead81",
   "metadata": {
    "height": 133
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你好, 我叫皮皮鲁\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)  \n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747cb539-abc4-4e47-8cb9-1ee608ab07fc",
   "metadata": {},
   "source": [
    "#### 2.1.2 संवाद का पहला दौर"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e48462-7a92-4842-bdaa-2a478ba2252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"你好, 我叫皮皮鲁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d320b-6b20-4722-99db-c48a43711d6c",
   "metadata": {},
   "source": [
    "#### 2.1.3 संवाद का दूसरा दौर"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ed6e97a-d7ea-4188-a6d7-f91d2a29d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好, 我叫皮皮鲁\n",
      "AI: 你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "Human: 1+1等于多少？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1等于2。'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"1+1等于多少？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1fd531-216e-42d8-b226-839747ad7dd3",
   "metadata": {},
   "source": [
    "#### 2.1.4 संवाद का तीसरा दौर"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dfe488-2758-42c7-9c20-e483b4c22ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好, 我叫皮皮鲁\n",
      "AI: 你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "Human: 1+1等于多少？\n",
      "AI: 1+1等于2。\n",
      "Human: What is my name?\n",
      "AI: 你的名字是皮皮鲁。\n",
      "Human: 我叫什么名字？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你叫皮皮鲁。'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我叫什么名字？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9822e-943d-4905-a1f8-a0d28c215d60",
   "metadata": {},
   "source": [
    "#### 2.1.5 स्टोरेज कैश देखें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0795580f-b6b6-47e0-8882-26fe204560bd",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好, 我叫皮皮鲁\n",
      "AI: 你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "Human: 1+1等于多少？\n",
      "AI: 1+1等于2。\n",
      "Human: What is my name?\n",
      "AI: 你的名字是皮皮鲁。\n",
      "Human: 我叫什么名字？\n",
      "AI: 你叫皮皮鲁。\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfe7824f-bd6e-4b95-92e2-1c85c62a92e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好, 我叫皮皮鲁\n",
      "AI: 你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "Human: 1+1等于多少？\n",
      "AI: 1+1等于2。\n",
      "Human: What is my name?\n",
      "AI: 你的名字是皮皮鲁。\n",
      "Human: 我叫什么名字？\n",
      "AI: 你叫皮皮鲁。\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48942759-8afb-4aed-80c5-a48952a2b0c0",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好, 我叫皮皮鲁\\nAI: 你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\\nHuman: 1+1等于多少？\\nAI: 1+1等于2。\\nHuman: What is my name?\\nAI: 你的名字是皮皮鲁。\\nHuman: 我叫什么名字？\\nAI: 你叫皮皮鲁。'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d0c4625-e928-45dc-b8da-4ab865ac5f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好, 我叫皮皮鲁\\nAI: 你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\\nHuman: 1+1等于多少？\\nAI: 1+1等于2。\\nHuman: What is my name?\\nAI: 你的名字是皮皮鲁。\\nHuman: 我叫什么名字？\\nAI: 你叫皮皮鲁。'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3778e-5fbf-43ed-9df1-d57d98ec6fb0",
   "metadata": {},
   "source": [
    "#### 2.1.6 सामग्री को सीधे स्टोरेज कैश में जोड़ें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "147b2c30-1662-4b49-aaf8-c228428e5cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b5e27f0-dad7-41b6-9326-bebf6299638f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfa7c555-06ab-4906-b3dc-906f789e08f5",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西\\nHuman: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deb33de8-37ea-4180-a73e-0fc456b14eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西\\nHuman: Not much, just hanging\\nAI: Cool\\nHuman: 很高兴和你成为朋友！\\nAI: 是的，让我们一起去冒险吧！'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10146f1a-0114-4902-8122-d19ae6f7c461",
   "metadata": {},
   "source": [
    "### 2.3 सारांश"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759b6bc-edb2-4cfe-b0f8-1bf6c4d796f9",
   "metadata": {},
   "source": [
    "जब हम चैट वार्तालाप के लिए एक बड़े भाषा मॉडल का उपयोग करते हैं, तो बड़ा भाषा मॉडल स्वयं अब तक की ऐतिहासिक बातचीत को याद नहीं रखता है। एपीआई नोड की प्रत्येक कॉल स्वतंत्र है या अब तक की बातचीत और आउटपुट उत्पन्न करने के लिए एलएलएम में इनपुट या संदर्भ संलग्न करें ऐसा लगता है कि जब यह बातचीत के अगले दौर में होता है तो इसे याद रहता है कि पहले क्या कहा गया था।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98e9ff",
   "metadata": {},
   "source": [
    "## 3. वार्तालाप कैश विंडो संग्रहण\n",
    "\n",
    "जैसे-जैसे बातचीत लंबी होती जाएगी, आवश्यक मेमोरी की मात्रा बहुत लंबी हो जाएगी, एलएलएम को बड़ी संख्या में टोकन भेजने की लागत भी अधिक महंगी हो जाएगी, यही कारण है कि एपीआई कॉल शुल्क आमतौर पर आवश्यक टोकन की संख्या के आधार पर लिया जाता है। प्रक्रिया।\n",
    "\n",
    "उपरोक्त समस्याओं के जवाब में, लैंगचेन ऐतिहासिक वार्तालापों को सहेजने के लिए कई सुविधाजनक भंडारण विधियां भी प्रदान करता है, उनमें से वार्तालाप कैश विंडो भंडारण केवल एक को बरकरार रखता हैवार्तालापों का विंडो आकार। यह केवल सबसे हाल के एन इंटरैक्शन का उपयोग करता है। इसका उपयोग हाल के इंटरैक्शन की स्लाइडिंग विंडो रखने के लिए किया जा सकता है ताकि बफर बहुत बड़ा न हो"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c9061-9916-4524-b497-93a0aa2b7d06",
   "metadata": {},
   "source": [
    "### 3.1 अंग्रेजी संस्करण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641477a4",
   "metadata": {},
   "source": [
    "#### 3.1.1 विंडो स्टोरेज में संवाद के दो दौर जोड़ें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ea6233e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# k विंडो पैरामीटर है, k=1 का अर्थ है कि केवल एक वार्तालाप मेमोरी रखी गई है\n",
    "memory = ConversationBufferWindowMemory(k=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc4553fb",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# संवाद के दो दौर स्मृति में जोड़ें\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a788403",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# और मेमोरी वेरिएबल का वर्तमान रिकॉर्ड देखें\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bda148",
   "metadata": {},
   "source": [
    "#### 3.1.2 संवाद श्रृंखला में विंडो स्टोरेज का उपयोग करना"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4087bc87",
   "metadata": {
    "height": 133
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d661e3",
   "metadata": {},
   "source": [
    "यहां ध्यान दें! चूंकि यहां मेमोरी की एक विंडो का उपयोग किया जाता है, इसलिए ऐतिहासिक संदेशों का केवल एक दौर सहेजा जा सकता है, इसलिए एआई आपके द्वारा बातचीत के पहले दौर में बताए गए नाम को नहीं जान सकता है अधिकतम पिछले दौर (दूसरे दौर) का।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4faaa952",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb20ddaa",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "489b2194",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88837e7c-cf4b-469e-b820-bbfc49ba876c",
   "metadata": {},
   "source": [
    "### 3.2 चीनी संस्करण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ec3ad-6959-4a36-b1b5-4fcafe8088ad",
   "metadata": {},
   "source": [
    "#### 3.1.1 विंडो स्टोरेज में संवाद के दो दौर जोड़ें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68a2907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 很高兴和你成为朋友！\\nAI: 是的，让我们一起去冒险吧！'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# k=1 का अर्थ है कि केवल एक वार्तालाप मेमोरी रखी गई है\n",
    "memory = ConversationBufferWindowMemory(k=1)  \n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "memory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabf017-5bfd-4904-9f06-388f994eddc9",
   "metadata": {},
   "source": [
    "#### 3.1.2 संवाद श्रृंखला में विंडो स्टोरेज का उपयोग करना"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ee854d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，皮皮鲁！很高兴认识你。我是一个AI助手，可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "1+1等于2。\n",
      "很抱歉，我无法知道您的名字。\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )\n",
    "print(conversation.predict(input=\"你好, 我叫皮皮鲁\"))\n",
    "print(conversation.predict(input=\"1+1等于多少？\"))\n",
    "print(conversation.predict(input=\"我叫什么名字？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2931b92",
   "metadata": {},
   "source": [
    "## 4. वार्तालाप टोकन कैश संग्रहण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff5b4c7",
   "metadata": {},
   "source": [
    "वार्तालाप टोकन कैश मेमोइज़ेशन के साथ, मेमोरी सहेजे गए टोकन की संख्या को सीमित कर देगी यदि टोकन की संख्या निर्दिष्ट संख्या से अधिक है, तो यह नवीनतम संचार के अनुरूप टोकन की संख्या को बनाए रखने के लिए बातचीत के पहले भाग को काट देगी, लेकिन। टोकन सीमा से अधिक नहीं."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f6d063c",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "!pip install -q tiktoken            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb9020ed",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84112",
   "metadata": {},
   "source": [
    "### 4.1 अंग्रेजी संस्करण\n",
    "टोकन कैश संग्रहण में संवाद जोड़ा गया, टोकन की संख्या सीमित की गई और परीक्षण किया गया"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43582ee6",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"}, {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"}, {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "284288e1",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62b2e1",
   "metadata": {},
   "source": [
    "आप देख सकते हैं कि सीमा पार करने वाले टोकन हटा दिए गए हैं!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6be43",
   "metadata": {},
   "source": [
    "### 4.2 चीनी संस्करण"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9191020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: 轻舟已过万重山。'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"朝辞白帝彩云间，\"}, {\"output\": \"千里江陵一日还。\"})\n",
    "memory.save_context({\"input\": \"两岸猿声啼不住，\"}, {\"output\": \"轻舟已过万重山。\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08ef4a-876f-422a-81f9-4805288e5955",
   "metadata": {},
   "source": [
    "### 4.3 अनुपूरक"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d918b",
   "metadata": {},
   "source": [
    "चैटजीपीटी टोकनाइजेशन के लिए बाइट पेयर एन्कोडिंग (बीपीई)-आधारित पद्धति का उपयोग करता है (इनपुट टेक्स्ट को टोकन में विभाजित करना बीपीई एक सामान्य टोकनाइजेशन तकनीक है जो इनपुट टेक्स्ट को छोटी सबवर्ड इकाइयों में विभाजित करती है)।\n",
    "\n",
    "OpenAI ने अपने आधिकारिक GitHub पर एक नया ओपन सोर्स Python लाइब्रेरी [tiktoken](https://github.com/openai/tiktoken) जारी किया है। इस लाइब्रेरी का उपयोग मुख्य रूप से HuggingFace के टोकनाइज़र की तुलना में किया जाता है कई गुना बढ़ गया.\n",
    "\n",
    "विशिष्ट टोकन गणना मेथ के लिएओडीएस, विशेष रूप से चीनी अक्षरों और अंग्रेजी शब्दों के बीच अंतर, कृपया विशिष्ट पाठों के लिए [ज़ीहू लेख] (https://www.zhihu.com/question/594159910) देखें।"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff55d5d",
   "metadata": {},
   "source": [
    "## 5. वार्तालाप सारांश कैश संग्रहण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39b83a",
   "metadata": {},
   "source": [
    "वार्तालाप सारांश कैश संग्रहण, **अब तक की ऐतिहासिक बातचीत का सारांश लिखने के लिए एलएलएम का उपयोग करें**, और इसे सहेजें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72dcf8b1",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b213e-ce17-46a0-8652-03658ca58dd8",
   "metadata": {},
   "source": [
    "### 5.1 अंग्रेजी संस्करण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572ef39",
   "metadata": {},
   "source": [
    "#### 5.1.1 वार्तालाप सारांश कैश का उपयोग करना\n",
    "\n",
    "किसी के शेड्यूल वाली एक लंबी स्ट्रिंग बनाएं"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a5b238f",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "#एक लंबी स्ट्रिंग बनाएं\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "# वार्तालाप सारांश कैश मेमोरी का उपयोग करना\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) \n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"What is on the schedule today?\"}, {\"output\": f\"{schedule}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15226a41-ab36-43a0-93f7-c03c6b374936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb97b6",
   "metadata": {},
   "source": [
    "#### 5.1.2 वार्तालाप सारांश कैश संग्रहण पर आधारित वार्तालाप श्रृंखला\n",
    "उपरोक्त वार्तालाप सारांश कैश संग्रहण के आधार पर, एक नई वार्तालाप श्रृंखला बनाएं"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6728edba",
   "metadata": {
    "height": 99
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a221b1d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of AI in natural language processing and how it can be applied to various industries and use cases.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb582617",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of AI in natural language processing and how it can be applied to various industries and use cases.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba827aa",
   "metadata": {
    "height": 31
   },
   "source": [
    "### 5.2 चीनी संस्करण"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64898f33-c538-4e68-b008-7123870b692b",
   "metadata": {},
   "source": [
    "#### 5.2.1 वार्तालाप सारांश कैश का उपयोग करना\n",
    "\n",
    "किसी के शेड्यूल वाली एक लंबी स्ट्रिंग बनाएं"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c07922b",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "#एक लंबी स्ट्रिंग बनाएं\n",
    "schedule = \"在八点你和你的产品团队有一个会议。 \\\n",
    "你需要做一个PPT。 \\\n",
    "上午9点到12点你需要忙于LangChain。\\\n",
    "Langchain是一个有用的工具，因此你的项目进展的非常快。\\\n",
    "中午，在意大利餐厅与一位开车来的顾客共进午餐 \\\n",
    "走了一个多小时的路程与你见面，只为了解最新的 AI。 \\\n",
    "确保你带了笔记本电脑可以展示最新的 LLM 样例.\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "memory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\n",
    "memory.save_context({\"input\": \"今天的日程安排是什么？\"}, {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "17424a12-430f-4529-9067-300978c6169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29a956-607a-4247-9eb5-01285a370991",
   "metadata": {},
   "source": [
    "#### 5.1.2 वार्तालाप सारांश कैश संग्रहण पर आधारित वार्तालाप श्रृंखला\n",
    "उपरोक्त वार्तालाप सारांश कैश संग्रहण के आधार पर, एक नई वार्तालाप श्रृंखला बनाएं"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "52696c8c",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "48690d13",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples.\n",
      "Human: 展示什么样的样例最好呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'展示一些具有多样性和创新性的样例可能是最好的选择。你可以选择展示一些基于图像识别的样例，比如人脸识别、物体识别等。另外，你也可以展示一些自然语言处理方面的样例，比如文本生成、情感分析等。最重要的是选择那些能够展示出你们团队的技术实力和创造力的样例。'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"展示什么样的样例最好呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "85bba1f8",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples. The human asks what kind of samples would be best to showcase. The AI suggests that showcasing diverse and innovative samples would be the best choice. They recommend selecting samples based on image recognition, such as face recognition and object recognition. Additionally, they suggest showcasing samples related to natural language processing, such as text generation and sentiment analysis. The AI emphasizes the importance of choosing samples that demonstrate the team's technical expertise and creativity.\"}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # 摘要记录更新了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
