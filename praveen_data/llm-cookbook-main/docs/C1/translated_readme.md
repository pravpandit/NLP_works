# Part 1 Prompt Engineering for Developers

Prompt was originally a task-specific input form or template designed by NLP researchers for downstream tasks. After ChatGPT ushered in a new era of large language models, Prompt became a synonym for interactive input with large models. That is, we generally call the input to the large model Prompt, and the output returned by the large model Completion.

With the emergence of LLMs (large language models) such as ChatGPT, the paradigm of natural language processing is evolving from Pretrain-Finetune to Prompt Engineering. For LLMs with strong natural language understanding and generation capabilities and the ability to handle a variety of tasks, a reasonable Prompt design greatly determines the upper and lower limits of its capabilities. Prompt Engineering is the skill of constructing prompts that can fully utilize the capabilities of large models for specific tasks. Prompt Engineering is an essential skill to fully and efficiently use LLMs.

LLM is gradually changing people's lives. For developers, how to quickly and conveniently develop some applications with stronger capabilities and integrated LLM based on the API provided by LLM to conveniently implement someA newer and more practical ability is an important ability that needs to be learned urgently. To efficiently develop applications that integrate LLM based on APIs, the first thing is to learn how to use LLM reasonably and efficiently, that is, how to build Prompt Engineering. The first part of the prompt engineering for developers is derived from the "ChatGPT Prompt Engineering for Developers" tutorial launched by Professor Andrew Ng and OpenAI. It is aimed at developers who are getting started with LLM. It introduces in a simple way how to construct prompts and implement various common functions including summary, inference, conversion, etc. based on the API provided by OpenAI. It is the first step to get started with LLM development. For developers who want to get started with LLM, you need to fully master the Prompt Engineering skills in this part and be able to implement personalized customization functions based on the above skills.

The main contents of this part include: principles and techniques for writing prompts; text summarization (such as summarizing user comments); text inference (such as sentiment classification, topic extraction); text conversion (such as translation, automatic error correction); extension (such as writing emails), etc.

**Table of Contents:**

1. Introduction @邹雨衡
2. Prompt Construction Guidelines @邹雨衡3. How to iterate and optimize Prompt Itrative @邹雨衡
4. Summarizing @玉琳
5. Text inference @长琴
6. Transforming @玉琳
7. Expand @邹雨衡
8. Chatbot @长琴
9. Summarizing @长琴