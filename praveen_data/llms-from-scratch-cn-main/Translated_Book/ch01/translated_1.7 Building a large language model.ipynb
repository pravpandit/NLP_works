{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 Building a large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we laid the foundation for understanding LLMs. In the remainder of this book, we will write an LLM from scratch. We will use the basic ideas behind GPT as a blueprint and solve the problem in three stages as outlined in Figure 1.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1.9 The stages of building a large language model (LLM) covered in this book include implementing the LLM architecture and data preparation process, pretraining the LLM to create a base model, and fine-tuning the base model to make it a personal assistant or text classifier. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig-1.7-1](../img/fig-1.7-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "First, we will understand the basic data preprocessing steps and write the attention mechanism at the core of each LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in the second phase, we will learn how to write and pre-train a GPT-like LLM that is capable of generating new text. We will also discuss the basic principles of evaluating LLMs, which is crucial for developing powerful natural language processing systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pre-training a large LLM from scratch is a significant undertaking, with computational costs that can range from thousands to millions of dollars for models like GPT. Therefore, the second phase focuses on implementing training with small datasets for educational purposes. In addition, the book will provide code examples for loading publicly available model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in the third stage, we will take the pre-trained LLM and fine-tune it to perform instructions such as answering queries or classifying text - the most common tasks in many real-world applications and research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope you look forward to embarking on this exciting journey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
