## प्राकृतिक भाषा प्रसंस्करण (एनएलपी)
नेचुरल लैंग्वेज प्रोसेसिंग (एनएलपी) एक महत्वपूर्ण कृत्रिम बुद्धिमत्ता (आर्टिफिशियल इंटेलिजेंस, एआई) तकनीक है। हम एनएलपी तकनीक के अनुप्रयोग को हर जगह देख सकते हैं, जैसे ऑनलाइन खोज, विज्ञापन, ईमेल, बुद्धिमान ग्राहक सेवा, मशीन अनुवाद, बुद्धिमान समाचार प्रसारण, आदि। हाल के वर्षों में, डीप लर्निंग (डीएल) पर आधारित एनएलपी तकनीक ने विभिन्न कार्यों में अच्छे परिणाम प्राप्त किए हैं। डीप लर्निंग मॉडल पर आधारित ये एनएलपी कार्य समाधान आमतौर पर पारंपरिक, कार्य-विशिष्ट फीचर इंजीनियरिंग का उपयोग नहीं करते हैं। केवल उपयोग करके अच्छे परिणाम प्राप्त किए जा सकते हैं एक एंड-टू-एंड न्यूरल नेटवर्क मॉडल। यह ट्यूटोरियल एनएलपी में कई क्लासिक कार्यों को हल करने के लिए सबसे अत्याधुनिक गहन शिक्षण मॉडल संरचनाओं (ट्रांसफॉर्मर) पर आधारित होगा। इस ट्यूटोरियल के अध्ययन के माध्यम से, हम ट्रांसफार्मर से संबंधित सिद्धांतों को समझने, एनएलपी में व्यावहारिक समस्याओं को हल करने के लिए ट्रांसफार्मर से संबंधित गहन शिक्षण मॉडल का कुशलतापूर्वक उपयोग करने और विभिन्न कार्यों में अच्छे परिणाम प्राप्त करने में सक्षम होंगे।

प्राकृतिक भाषा और गहन शिक्षण के लिए पाठ्यक्रम अनुशंसाएँ: [CS224n: De के साथ प्राकृतिक भाषा प्रसंस्करणईपी लर्निंग](http://web.stanford.edu/class/cs224n/)
प्राकृतिक भाषा प्रसंस्करण पर अनुशंसित पुस्तकें: [भाषण और भाषा प्रसंस्करण](https://web.stanford.edu/~jurafsky/slp3/)

## सामान्य एनएलपी कार्य
यह ट्यूटोरियल एनएलपी कार्यों को 4 प्रमुख श्रेणियों में विभाजित करता है: 1. पाठ वर्गीकरण, 2. अनुक्रम लेबलिंग, 3. प्रश्न और उत्तर कार्य - निष्कर्षण प्रश्न और उत्तर और बहुविकल्पीय प्रश्न और उत्तर, 4. सृजन कार्य - भाषा मॉडल, मशीन अनुवाद और सारांश पीढ़ी.

* पाठ वर्गीकरण: पाठ के एकल, दो या एकाधिक अनुच्छेदों को वर्गीकृत करें। उदाहरण के लिए: "यह ट्यूटोरियल अद्भुत है!" इस पाठ की भावनात्मक प्रवृत्ति सकारात्मक है, और दो पाठ "मैं ट्रांसफार्मर सीख रहा हूं" और "ट्रांसफार्मर कैसे सीखें" समान हैं।
* अनुक्रम एनोटेशन: पाठ अनुक्रमों में टोकन, शब्द या शब्दों को वर्गीकृत करें। उदाहरण के लिए: "मैं **राष्ट्रीय पुस्तकालय** में ट्रांसफार्मर का अध्ययन कर रहा हूं।" इस पाठ में **राष्ट्रीय पुस्तकालय** एक **स्थान** है जिसे पाठ की मशीन की समझ को सुविधाजनक बनाने के लिए चिह्नित किया जा सकता है।
* प्रश्नोत्तर कार्य - निष्कर्षात्मक प्रश्नोत्तर और बहुविकल्पीय प्रश्नोत्तर: 1. निष्कर्षात्मक प्रश्नोत्तर **प्रश्न** के आधार पर दिए गए पाठ से **उत्तर** ढूंढता है। उत्तर दिए गए पाठ का एक छोटा पैराग्राफ होना चाहिए। उदाहरण: प्रश्न "प्राथमिक स्कूली शिक्षा कितने समय तक चलती है?" और पाठ का एक पैराग्राफ "प्राथमिक शिक्षा आम तौर पर छह साल तक चलती है। ", तो उत्तर "छह वर्ष" है। 2. बहुविकल्पीय प्रश्न और उत्तर, एकाधिक विकल्पों में से सही उत्तर चुनें। उदाहरण के लिए: "प्रश्न और उत्तर में निम्नलिखित में से कौन सी मॉडल संरचना सर्वश्रेष्ठ है? "और 4 विकल्प "ए, एमएलपी, बी, सीएनएन, सी, एलएसटीएम, डी, ट्रांसफार्मर", तो उत्तर विकल्प डी है।
* पीढ़ी के कार्य - भाषा मॉडल, मशीनी अनुवाद और सारांश पीढ़ी: पाठ के मौजूदा पैराग्राफ के आधार पर एक शब्द उत्पन्न करना आमतौर पर भाषा मॉडल कहा जाता है, पाठ के बड़े पैराग्राफ के आधार पर एक छोटा सारांश पाठ तैयार करना आमतौर पर सारांश पीढ़ी कहा जाता है, और परिवर्तित करना उदाहरण के लिए, चीनी वाक्यों का अंग्रेजी जैसी लक्ष्य भाषा में अनुवाद को आमतौर पर मशीनी अनुवाद कहा जाता है।

यद्यपि विभिन्न ट्रांसफार्मर-आधारित गहन शिक्षण मॉडल ने कई कृत्रिम रूप से निर्मित एनएलपी कार्यों में अच्छा प्रदर्शन किया है, मानव भाषा की चौड़ाई और गहराई के कारण गहन शिक्षण मॉडल को अभी भी एक लंबा रास्ता तय करना है।

## ट्रांसफार्मर का उदय

2017 में, पेपर [अटेंशन इज़ ऑल यू नीड] (https://arxiv.org/pdf/1706.03762.pdf) ने पहली बार **ट्रांसफॉर्मर** मॉडल संरचना का प्रस्ताव रखा और अत्याधुनिक (SOTA) हासिल किया। सबसे अच्छा) प्रभाव. 2018 में, [बर्ट: प्री-ट्रडीप बाईडायरेक्शनल ट्रांसफार्मर की एनिंग
भाषा समझ](https://arxiv.org/pdf/1810.04805.pdf) बड़े पैमाने पर भाषा मॉडल प्री-ट्रेनिंग (प्री-ट्रेन) करने के लिए ट्रांसफार्मर मॉडल संरचना का उपयोग करता है, और फिर फाइन-ट्यूनिंग के बाद कई एनएलपी डाउनस्ट्रीम कार्य करता है (फाइनट्यून), इसने एक झटके में प्रमुख एनएलपी कार्यों की सूची में उच्चतम स्कोर स्थापित किया, जो एक सनसनी थी। 2019 से 2021 तक, शोधकर्ताओं ने ट्रांसफार्मर की मॉडल संरचना को प्री-ट्रेनिंग + फाइन-ट्यूनिंग की प्रशिक्षण पद्धति के साथ जोड़ा, और ट्रांसफार्मर मॉडल संरचना और प्रशिक्षण विधियों (जैसे ट्रांसफार्मर-एक्सएल, एक्सएलनेट, रोबर्टा) में सुधार की एक श्रृंखला का प्रस्ताव दिया। वगैरह।) । जैसा कि नीचे दिए गए चित्र में दिखाया गया है, विभिन्न ट्रांसफार्मरों में सुधार लगातार सामने आ रहे हैं।

![एक साथ रखें](./pictures/1-x-formers.png) चित्र: विभिन्न ट्रांसफार्मर सुधार, स्रोत: [ट्रांसफॉर्मर का एक सर्वेक्षण](https://arxiv.org/pdf/2106.04554.pdf)

इसके अलावा, चूंकि ट्रएन्फॉर्मर की उत्कृष्ट मॉडल संरचना अधिक जानकारी को समायोजित करने के लिए इसके मापदंडों को बहुत बड़ा करने की अनुमति देती है, इसलिए, हाल के वर्षों में कंप्यूटिंग शक्ति में सुधार के साथ, ट्रांसफार्मर मॉडल की क्षमताओं में सुधार जारी है बेहतर से बेहतर प्रभाव वाले ट्रांसफार्मर लगातार सामने आ रहे हैं, सरल आँकड़े नीचे दिए गए चित्र से देखे जा सकते हैं:

![मॉडल पैरामीटर बड़े होते जा रहे हैं](./pictures/2-model_parameters.png) चित्र: प्री-ट्रेनिंग मॉडल पैरामीटर बड़े होते जा रहे हैं, स्रोत [हगिंगफेस](https://huggingface.co/course/chapter1/4?fw = पीटी)


हालाँकि विभिन्न ट्रांसफॉर्मर पर कई अध्ययन हैं, सामान्य तौर पर, क्लासिक और लोकप्रिय ट्रांसफॉर्मर मॉडल शुरुआती लोगों के लिए [हगिंगफेस/ट्रांसफॉर्मर्स, 48.9k स्टार] (https://github.com/huggingface/transformers) के माध्यम से मुफ्त में प्राप्त और उपयोग किए जा सकते हैं। शोधकर्ताओं ने जबरदस्त मदद प्रदान की।

यह ट्यूटोरियल भी [हगिंगफेस/ट्रांसफॉर्मर्स, 48.9k स्टार](https://github.com/huggingface/trans) पर आधारित होगाफॉर्मर्स) विशिष्ट प्रोग्रामिंग और कार्य समाधान कार्यान्वयन के लिए।

एनएलपी में पूर्व-प्रशिक्षण + फाइन-ट्यूनिंग प्रशिक्षण विधियों के लिए अनुशंसित पढ़ना:
[2021 में प्री-ट्रेनिंग मॉडल को वैज्ञानिक रूप से "फाइन-ट्यून" कैसे करें?
](https://zhuanlan.zhihu.com/p/363802308) और [वर्ड एंबेडिंग से बर्ट मॉडल तक-प्राकृतिक भाषा प्रसंस्करण में पूर्व-प्रशिक्षण प्रौद्योगिकी का विकास इतिहास](https://zhuanlan.zhihu.com/p /49271699 )