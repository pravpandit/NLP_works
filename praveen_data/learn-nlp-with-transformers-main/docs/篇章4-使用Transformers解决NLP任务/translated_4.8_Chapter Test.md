## Chapter Quiz
* Question 1: Which pre-trained model is better for NLP generation tasks, BERT, Roberta, GPT, T5?
* Question 2: How to construct input for multiple-choice question answering?
* Question 3: How does extractive question answering solve the problem of very long text context?
* Question 4: How to choose tokenizer and pre-trained model?