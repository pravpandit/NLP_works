{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 पर्यावरण विन्यास\n",
    "\n",
    "सबसे पहले, हम पिछले अध्यायों की तरह समान मिनिस्ट डेटासेट और लेनेट नेटवर्क का उपयोग करके आवश्यक वातावरण, डेटासेट और मॉडल आयात करते हैं।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f14fe352af0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.quantization\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from utils import LeNet,train,evaluate,get_model_size,get_model_flops,MiB\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 मॉडल और डेटासेट का निर्माण"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "    \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "        \n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# डिवाइस = टॉर्च.डिवाइस (\"क्यूडा\" यदि टॉर्च.क्यूडा.इस_उपलब्ध है() अन्यथा \"सीपीयू\")\n",
    "model = LeNet()#.to(device=device)\n",
    "print(model)\n",
    "# मॉडल का राज्य शब्दकोश लोड करें\n",
    "# चेकपॉइंट = टॉर्च.लोड('../ch02/model.pt')\n",
    "checkpoint = torch.load('./model.pt')\n",
    "\n",
    "# राज्य शब्दकोश को मॉडल में लोड करें\n",
    "model.load_state_dict(checkpoint)\n",
    "fp32_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# सामान्यीकरण सेट करें\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# डेटासेट प्राप्त करें\n",
    "# ट्रेन_डेटासेट = डेटासेट.MNIST(root='../ch02/data/mnist', ट्रेन=सही, डाउनलोड=सही, ट्रांसफॉर्म=ट्रांसफॉर्म)\n",
    "# test_dataset = datasets.MNIST(root='../ch02/data/mnist', ट्रेन=गलत, डाउनलोड=सही, परिवर्तन=परिवर्तन) # ट्रेन=सही प्रशिक्षण सेट, =गलत परीक्षण सेट\n",
    "train_dataset = datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='./data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "# डेटा लोडर की स्थापना\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 एफपी32 मॉडल की सटीकता और आकार सत्यापित करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8597c81c4547a3b32f0ac0e461e5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 model has accuracy=97.99000%\n",
      "fp32 model has size=0.17 MiB\n"
     ]
    }
   ],
   "source": [
    "fp32_model_accuracy = evaluate(fp32_model, test_loader)\n",
    "fp32_model_size = get_model_size(fp32_model)\n",
    "print(f\"fp32 model has accuracy={fp32_model_accuracy:.5f}%\")\n",
    "print(f\"fp32 model has size={fp32_model_size/MiB:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 मॉडल को मात्रात्मक मॉडल में बदलें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qnnpack', 'none', 'fbgemm']\n"
     ]
    }
   ],
   "source": [
    "backend = torch.backends.quantized.supported_engines #运行时可以使用这句命令检查自己支持的后端\n",
    "print(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(\n",
       "    1, 6, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(\n",
       "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=256, out_features=120, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(\n",
       "    in_features=120, out_features=84, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu4): ReLU()\n",
       "  (fc3): Linear(\n",
       "    in_features=84, out_features=10, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# मॉडल को QAT मॉडल में परिमाणित करें\n",
    "quant_model = copy.deepcopy(model)\n",
    "quant_model.qconfig = torch.quantization.get_default_qat_qconfig(backend[-1])\n",
    "torch.quantization.prepare_qat(quant_model, inplace=True)\n",
    "print(quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आप देख सकते हैं कि उपरोक्त मॉडल में FakeQuantize फ़ंक्शन जोड़ा गया है। इस फ़ंक्शन का उपयोग सिमुलेशन परिमाणीकरण के लिए किया जाता है।"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 परिमाणीकरण मॉडल की सटीकता सत्यापित करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039dee0dd4844709ba10d959df84d789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant model has accuracy=98.37000%\n"
     ]
    }
   ],
   "source": [
    "quant_model_accuracy = evaluate(quant_model, test_loader)\n",
    "print(f\"quant model has accuracy={quant_model_accuracy:.5f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 परिमाणित मॉडल का प्रशिक्षण"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b9a9a831f84fdbbc6a865a5851d421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=938.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e01505b2bd4caa91d7a783158315ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 98.34% / Best Accuracy: 98.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2187b48d4b4175b437535acd4b25b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=938.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65a122e87a749f6bea93dac4b4251ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 1 Accuracy 98.32% / Best Accuracy: 98.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6538b5e345a4449c8122eb2a9b558899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=938.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef10de5f3e384cee9dd1f24c200ddf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 2 Accuracy 98.28% / Best Accuracy: 98.34%\n"
     ]
    }
   ],
   "source": [
    "num_finetune_epochs = 3 #   这里一般微调5～10个epoch\n",
    "optimizer = torch.optim.SGD(quant_model.parameters(), lr=0.001, momentum=0.9) #学习率调低一些\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_accuracy = 0\n",
    "epoch = num_finetune_epochs\n",
    "while epoch > 0:\n",
    "    train(quant_model, train_loader, criterion, optimizer, scheduler)\n",
    "    model_accuracy = evaluate(quant_model, test_loader)\n",
    "    is_best = model_accuracy > best_accuracy\n",
    "    best_accuracy = max(model_accuracy, best_accuracy)\n",
    "    print(f'        Epoch {num_finetune_epochs-epoch} Accuracy {model_accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "    epoch -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 परिमाणित मॉडल को परिमाणित परिनियोजन मॉडल में परिवर्तित करें और इसकी सटीकता को सत्यापित करें"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "यहां हम एक सत्यापन फ़ंक्शन को फिर से परिभाषित करते हैं क्योंकि मॉडल को परिमाणित करने के बाद, इनपुट और आउटपुट को भी परिमाणित करने की आवश्यकता होती है:\n",
    "आउटपुट = डीक्वेंट (आउटपुट)\n",
    "इनपुट = मात्रा (इनपुट)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "quant = torch.quantization.QuantStub() \n",
    "dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "def evaluate_quant(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "  \n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "# डेटा को सीपीयू से जीपीयू में ले जाएं\n",
    "# इनपुट = इनपुट.टू('एमपीएस')\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = quant(inputs)\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "# लक्ष्य = लक्ष्य.से('एमपीएस')\n",
    "\n",
    "#अनुमान\n",
    "    outputs = model(inputs)\n",
    "# प्रिंट (आउटपुट)\n",
    "    outputs = dequant(outputs)\n",
    "# लॉग को क्लास इंडेक्स में बदलें\n",
    "# प्रिंट (आउटपुट)\n",
    "    outputs = outputs.to(\"cpu\")\n",
    "# आउटपुट = आउटपुट.argmax(dim=1)\n",
    "    outputs=torch.max(outputs,1)[1]\n",
    "\n",
    "# मेट्रिक्स अपडेट करें\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "वास्तविक int8 मॉडल प्राप्त करने के लिए क्वांटाइज्ड प्रशिक्षित मॉडल में नकली नोड्स को हटा दें। निम्नलिखित मॉडल में सभी नोड ऑपरेटर क्वांटाइज्ड ऑपरेटर बन गए हैं।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): QuantizedConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.16204923391342163, zero_point=36)\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.3756241202354431, zero_point=54)\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): QuantizedLinear(in_features=256, out_features=120, scale=0.28476396203041077, zero_point=53, qscheme=torch.per_channel_affine)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=0.2204333394765854, zero_point=55, qscheme=torch.per_channel_affine)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=0.28054389357566833, zero_point=60, qscheme=torch.per_channel_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.quantization.convert(quant_model, inplace=True)\n",
    "print(quant_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## पूर्ण int8 मॉडल की सटीकता सत्यापित करें"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "यह देखा जा सकता है कि पूर्ण int8 मॉडल की सटीकता परिमाणीकरण प्रशिक्षण के दौरान पिछले युग की सटीकता के लगभग समान है।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e19869e7b64fb38e9a23c24d25cc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_quant model has accuracy=98.37000%\n"
     ]
    }
   ],
   "source": [
    "final_quant_model_accuracy = evaluate_quant(quant_model, test_loader)\n",
    "print(f\"final_quant model has accuracy={final_quant_model_accuracy:.5f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
