{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## संबंधित पुस्तकालयों और नेटवर्कों को आयात करें\n",
    "\n",
    "`res8x4` को डिस्टिल करने के लिए `res32x4` का उपयोग करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# शिक्षक नेटवर्क और छात्र नेटवर्क\n",
    "from nets.resnet import resnet32x4, resnet8x4\n",
    "#ज्ञान आसवन का हानि कार्य केडी\n",
    "from loss.kd import loss\n",
    "\n",
    "#टेन्सरबोर्ड\n",
    "Train_Info = \"KD : Res32x4 To Res8x4\"\n",
    "writer = SummaryWriter(comment=Train_Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# यादृच्छिक संख्या बीज सेट करें ताकि इसे पुन: प्रस्तुत किया जा सके\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU, अपने डिवाइस पर '1' के नंबर को gpu नंबर में बदलें\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## हाइपरपैरामीटर को परिभाषित करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4               # temperature : 知识蒸馏中的温度\n",
    "ALPHA = 0.1         # alpha : hard_loss(硬损失交叉熵)的loss weight \n",
    "BETA = 0.9          # beta : soft_loss(软损失KL散度)的loss weight\n",
    "N = 100             # num_classes : 类别数\n",
    "EPOCH = 20          # epoch : 训练轮数\n",
    "BATCH_SIZE = 128    # batch_size : 批处理大小 \n",
    "LR = 0.05           # learning_rate : 初试学习率\n",
    "\n",
    "# ऑप्टिमाइज़र में अन्य हाइपरपैरामीटर, जैसे गति, भार-क्षय, मील के पत्थर, गामा, आदि आमतौर पर शायद ही कभी बदले जाते हैं।\n",
    "# जब EPOCH बदलता है, तो मील के पत्थर भी उसी के अनुसार बदलने चाहिए।"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## शिक्षक मॉडल लोड करें और छात्र नेटवर्क को परिभाषित करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res32x4 = resnet32x4(num_classes=N)\n",
    "ckpt = torch.load(\"checkpoints/teacher/ckpt_epoch_240.pth\", map_location='cpu')\n",
    "res32x4.load_state_dict(ckpt[\"model\"])\n",
    "res32x4 = nn.DataParallel(res32x4).cuda()\n",
    "res32x4.eval()\n",
    "\n",
    "res8x4 = resnet8x4(num_classes=N)\n",
    "res8x4 = torch.nn.DataParallel(res8x4).cuda()\n",
    "\n",
    "teacher_net = res32x4\n",
    "student_net = res8x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## डेटासेट लोड करें\n",
    "जब आप पहली बार इसका उपयोग करेंगे, तो यह पहले डाउनलोड होगा यदि डाउनलोड धीमा है, तो आप डेटासेट को मैन्युअल रूप से डाउनलोड कर सकते हैं और इसे डेटा फ़ोल्डर में खींच सकते हैं"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# डेटासेट तैयार करें और उसे प्रीप्रोसेस करें\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # 先四周填充0，在把图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),     # 图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "# प्रशिक्षण डेटासेट\n",
    "# num_workers आम तौर पर सीपीयू के प्रदर्शन पर निर्भर करता है\n",
    "trainset = torchvision.datasets.CIFAR100(root=DATA_PATH, train=True, download=True, transform=transform_train) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)   \n",
    "# डेटासेट का परीक्षण करें\n",
    "testset = torchvision.datasets.CIFAR100(root=DATA_PATH, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## अनुकूलक\n",
    "\n",
    "आम तौर पर, विभिन्न पेपरों में, cifar-100 डेटासेट पर `युग` को `240` पर सेट किया जाता है\n",
    "\n",
    "संबंधित `मील के पत्थर` का मान `[150, 180, 210]` है\n",
    "\n",
    "यहां, केवल प्रदर्शन के लिए, सभी `युग` को `40` पर सेट किया गया है, और `मील के पत्थर` का मान `[15, 25, 35]` है"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(student_net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25, 35], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ट्रेन फ़ंक्शन और परीक्षण फ़ंक्शन"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# प्रशिक्षण सेट और परीक्षण सेट पर क्रमशः सर्वश्रेष्ठ एसीसी को परिभाषित करें, इसे वैश्विक चर के रूप में संशोधित करने के लिए ग्लोबल का उपयोग करें, और फिर प्रशिक्षण के दौरान इसे अपडेट करें\n",
    "best_train_acc = 0\n",
    "best_test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(epoch):\n",
    "    global best_train_acc\n",
    "\n",
    "# छात्र मॉडल को प्रशिक्षण मोड पर सेट करें\n",
    "    student_net.train()\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "# प्रगति पट्टी प्रदर्शित करने के लिए ट्रेनलोडर को tqdm से लपेटें\n",
    "    with tqdm(trainloader, desc=f\"Training Epoch {epoch}\", total=len(trainloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_student, _ = student_net(inputs)\n",
    "            with torch.no_grad():\n",
    "                logits_teacher, _ = teacher_net(inputs)\n",
    "\n",
    "#कठिन हानि\n",
    "            ce_loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "#सॉफ्टलॉस\n",
    "            kd_loss = loss(logits_student, logits_teacher, temperature=T)\n",
    "            total_loss = ALPHA * ce_loss + BETA * kd_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            _, predicted = logits_student.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#अपडेटटेन्सरबोर्ड\n",
    "            writer.add_scalar('Train/Accuracy', 100. * correct / total, batch_idx + (epoch - 1) * 782)\n",
    "            writer.add_scalar('Train/Loss', total_loss.item(), batch_idx + (epoch - 1) * 782)\n",
    "\n",
    "# प्रगति पट्टी के प्रत्यय को अद्यतन करने के लिए set_postfix का उपयोग करें\n",
    "            pbar.set_postfix(loss=train_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "# यदि वर्तमान प्रशिक्षण सेट की सटीकता best_test_acc से अधिक है, तो best_test_acc को अपडेट करें\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_train_acc:\n",
    "        best_train_acc = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch):\n",
    "    global best_test_acc\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "# प्रगति पट्टी प्रदर्शित करने के लिए टेस्टलोडर को लपेटने के लिए tqdm का उपयोग करें\n",
    "        with tqdm(testloader, desc=f\"Testing Epoch {epoch}\", total=len(testloader)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                logits_student, _ = net(inputs)\n",
    "\n",
    "                loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = logits_student.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "# tqdm प्रगति पट्टी के प्रत्यय में वर्तमान हानि और सटीकता प्रदर्शित करें\n",
    "                pbar.set_postfix(loss=test_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "#अपडेटटेन्सरबोर्ड\n",
    "                writer.add_scalar('Test/Accuracy', 100. * correct / total, batch_idx + (epoch - 1) * 157)\n",
    "                writer.add_scalar('Test/Loss', loss.item(), batch_idx + (epoch - 1) * 157)\n",
    "\n",
    "# वर्तमान परीक्षण सेट पर सटीकता की गणना करें\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "# यदि वर्तमान परीक्षण सेट पर सटीकता best_test_acc से अधिक है, तो best_test_acc अपडेट करें\n",
    "# और छात्र मॉडल को सेव करें\n",
    "        if acc > best_test_acc:\n",
    "            print('Saving..')\n",
    "            torch.save(student_net, 'checkpoints/student/kd_res8x4.pth')\n",
    "            best_test_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##रेलगाड़ी"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 391/391 [01:05<00:00,  5.99it/s, acc=10.1%, loss=8.75]\n",
      "Testing Epoch 1: 100%|██████████| 79/79 [00:06<00:00, 13.00it/s, acc=14.0%, loss=3.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s, acc=19.9%, loss=7.69]\n",
      "Testing Epoch 2: 100%|██████████| 79/79 [00:06<00:00, 12.45it/s, acc=18.0%, loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 391/391 [00:51<00:00,  7.58it/s, acc=28.5%, loss=6.84]\n",
      "Testing Epoch 3: 100%|██████████| 79/79 [00:06<00:00, 12.30it/s, acc=26.4%, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 391/391 [00:52<00:00,  7.48it/s, acc=36.2%, loss=6.18]\n",
      "Testing Epoch 4: 100%|██████████| 79/79 [00:06<00:00, 11.85it/s, acc=34.3%, loss=2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 391/391 [00:52<00:00,  7.40it/s, acc=41.6%, loss=5.71]\n",
      "Testing Epoch 5: 100%|██████████| 79/79 [00:06<00:00, 12.99it/s, acc=37.0%, loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 391/391 [00:51<00:00,  7.59it/s, acc=45.8%, loss=5.36]\n",
      "Testing Epoch 6: 100%|██████████| 79/79 [00:06<00:00, 11.31it/s, acc=34.7%, loss=3.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 391/391 [00:53<00:00,  7.30it/s, acc=49.4%, loss=5.05]\n",
      "Testing Epoch 7: 100%|██████████| 79/79 [00:06<00:00, 12.15it/s, acc=44.5%, loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 391/391 [00:54<00:00,  7.15it/s, acc=52.2%, loss=4.82]\n",
      "Testing Epoch 8: 100%|██████████| 79/79 [00:06<00:00, 12.31it/s, acc=47.3%, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 391/391 [00:51<00:00,  7.66it/s, acc=54.5%, loss=4.64]\n",
      "Testing Epoch 9: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s, acc=37.1%, loss=3.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 391/391 [00:52<00:00,  7.44it/s, acc=56.7%, loss=4.47]\n",
      "Testing Epoch 10: 100%|██████████| 79/79 [00:06<00:00, 12.72it/s, acc=46.0%, loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 391/391 [00:51<00:00,  7.66it/s, acc=58.2%, loss=4.33]\n",
      "Testing Epoch 11: 100%|██████████| 79/79 [00:05<00:00, 13.35it/s, acc=50.8%, loss=2.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 391/391 [00:50<00:00,  7.69it/s, acc=59.6%, loss=4.22]\n",
      "Testing Epoch 12: 100%|██████████| 79/79 [00:06<00:00, 12.33it/s, acc=51.1%, loss=2.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 391/391 [00:51<00:00,  7.66it/s, acc=60.6%, loss=4.13]\n",
      "Testing Epoch 13: 100%|██████████| 79/79 [00:06<00:00, 11.76it/s, acc=52.1%, loss=2.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 391/391 [00:50<00:00,  7.82it/s, acc=61.3%, loss=4.07]\n",
      "Testing Epoch 14: 100%|██████████| 79/79 [00:06<00:00, 12.75it/s, acc=53.1%, loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 391/391 [00:51<00:00,  7.64it/s, acc=62.1%, loss=3.98]\n",
      "Testing Epoch 15: 100%|██████████| 79/79 [00:06<00:00, 13.16it/s, acc=51.2%, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 391/391 [00:49<00:00,  7.95it/s, acc=69.5%, loss=3.35]\n",
      "Testing Epoch 16: 100%|██████████| 79/79 [00:06<00:00, 12.28it/s, acc=65.2%, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 391/391 [00:52<00:00,  7.45it/s, acc=71.6%, loss=3.17]\n",
      "Testing Epoch 17: 100%|██████████| 79/79 [00:06<00:00, 12.60it/s, acc=65.2%, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 391/391 [00:51<00:00,  7.61it/s, acc=72.3%, loss=3.1] \n",
      "Testing Epoch 18: 100%|██████████| 79/79 [00:06<00:00, 13.09it/s, acc=65.8%, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 391/391 [00:50<00:00,  7.67it/s, acc=72.6%, loss=3.06]\n",
      "Testing Epoch 19: 100%|██████████| 79/79 [00:06<00:00, 12.95it/s, acc=66.2%, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 391/391 [00:52<00:00,  7.47it/s, acc=73.4%, loss=3.01]\n",
      "Testing Epoch 20: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s, acc=66.3%, loss=1.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCH + 1) :\n",
    "    train(epoch)\n",
    "    test(student_net, epoch)\n",
    "\n",
    "# सीखने की दर अद्यतन करें\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KD : Res32x4 To Res8x4\n",
      "best_Train_Acc =  73.41\n",
      "best_Test_Acc =  66.31\n"
     ]
    }
   ],
   "source": [
    "print(Train_Info)\n",
    "print('best_Train_Acc = ', best_train_acc)\n",
    "print('best_Test_Acc = ', best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.29' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.28' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# टेंसरबोर्ड प्रारंभ करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
