{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络架构搜索(NAS)实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务：做一个简单的NAS算法\n",
    "\n",
    "网格搜索(grid search):算法思路，将所有可能的组合进行网格搜索，选择最合适的那个即可\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载python函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集和定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "train_dataset = datasets.MNIST(root='../ch02/data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='../ch02/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  # scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    # inputs = inputs.to('mps')\n",
    "    # targets = targets.to('mps')\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs.cuda()).cpu()\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    # inputs = inputs.to('mps')\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "    # targets = targets.to('mps')\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs.cuda()).cpu()\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_flops(model, inputs):\n",
    "    num_macs = profile_macs(model, inputs)\n",
    "    return num_macs\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32):\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    \"\"\"\n",
    "    num_elements = 0\n",
    "    for param in model.parameters():\n",
    "        num_elements += param.numel()\n",
    "    return num_elements * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络架构搜索\n",
    "\n",
    "## 任务，在给定约束的模型大小下，找到最好的结果\n",
    "\n",
    "搜索方法：Grid search\n",
    "\n",
    "搜索空间：在LeNet上，定义不同的遍历情况，进行组合，然后依次训练并验证模型大小\n",
    "\n",
    "输出：最终输出合适的神经网络结构，并保存\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个LeNet网络\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, conv1_channel=6, conv1_kernel=5, conv2_channel=16, conv2_kernel=5, fc1_size=128, fc2_size=84, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=conv1_channel, kernel_size=conv1_kernel) \n",
    "        # 1 x 28 x 28 -> conv1_channel x (28-conv1_kernel+1) x (28-conv1_kernel+1)\n",
    "        # conv1_channel x (28-conv1_kernel+1) x (28-conv1_kernel+1) -> conv1_channel x (28-conv1_kernel+1)//2 x (28-conv1_kernel+1)//2\n",
    "        self.conv2 = nn.Conv2d(in_channels=conv1_channel, out_channels=conv2_channel, kernel_size=conv2_kernel) \n",
    "        # conv1_channel x (28-conv1_kernel+1)//2 x (28-conv1_kernel+1)//2 -> conv2_channel x ((28-conv1_kernel+1)//2- conv2_kernel + 1) x ((28-conv1_kernel+1)//2- conv2_kernel + 1)\n",
    "        # conv2_channel x ((28-conv1_kernel+1)//2- conv2_kernel + 1) x ((28-conv1_kernel+1)//2- conv2_kernel + 1) -> conv2_channel x ((28-conv1_kernel+1)//2- conv2_kernel + 1)//2 x ((28-conv1_kernel+1)//2- conv2_kernel + 1)//2\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        linear_input_dim = conv2_channel * (((28-conv1_kernel+1)//2-conv2_kernel+1)//2)**2 \n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=linear_input_dim, out_features=fc1_size)\n",
    "        self.fc2 = nn.Linear(in_features=fc1_size, out_features=fc2_size)\n",
    "        self.fc3 = nn.Linear(in_features=fc2_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义搜索空间\n",
    "conv1_channel_list = [3, 6, 9]\n",
    "conv1_kernel_list = [3, 5, 7]\n",
    "conv2_channel_list = [12, 16, 20]\n",
    "conv2_kernel_list = [3, 5, 7]\n",
    "fc1_size_list = [64, 128, 256]\n",
    "fc2_size_list = [32, 84, 120]\n",
    "\n",
    "# 模型训练参数配置\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "num_epoch = 5\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "limitation_model_size = 0.05 # 限制模型大小\n",
    "\n",
    "# 记录全局最好\n",
    "best_model = None\n",
    "best_model_info = \"\"\n",
    "overall_best_accuracy = 0\n",
    "\n",
    "## 开始进行搜索\n",
    "print(\"Searning\")\n",
    "for conv1_channel in conv1_channel_list:\n",
    "    for conv1_kernel in conv1_kernel_list:\n",
    "        for conv2_channel in conv2_channel_list:\n",
    "            for conv2_kernel in conv2_kernel_list:\n",
    "                for fc1_size in fc1_size_list:\n",
    "                    for fc2_size in fc2_size_list:\n",
    "                        model = LeNet(conv1_channel, conv1_kernel, conv2_channel, conv2_kernel, fc1_size, fc2_size).to(device=device)\n",
    "                        fp32_model_size = get_model_size(model)\n",
    "                        if fp32_model_size/MiB < limitation_model_size:\n",
    "                            print(f\"conv1_channel:{conv1_channel}, conv1_kenle:{conv1_kernel}, conv2_channel:{conv2_channel}, conv2_kenle:{conv2_kernel}, \"\\\n",
    "                              f\"fc1_size:{fc1_size}, fc2_size:{fc2_size}\")\n",
    "                            print(f\"model has size={fp32_model_size/MiB:.2f} MiB\")\n",
    "                            optimizer = torch.optim.SGD(model.parameters(),  lr=lr, momentum=momentum)  # lr学习率，momentum冲量\n",
    "                            best_accuracy = 0 \n",
    "                            best_checkpoint = dict()\n",
    "                            for epoch in range(num_epoch):\n",
    "                                train(model, train_loader, criterion, optimizer)\n",
    "                                accuracy = evaluate(model, test_loader)\n",
    "                                is_best = accuracy > best_accuracy\n",
    "                                if is_best:\n",
    "                                    best_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n",
    "                                    best_accuracy = accuracy\n",
    "                                print(f'Epoch{epoch+1:>2d} Accuracy {accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "                            model.load_state_dict(best_checkpoint['state_dict'])\n",
    "                            model_accuracy = evaluate(model, test_loader)\n",
    "                            print(f\"Model has accuracy={model_accuracy:.2f}%\")\n",
    "                            # 全局记录\n",
    "                            if model_accuracy > overall_best_accuracy:\n",
    "                                overall_best_accuracy = model_accuracy\n",
    "                                best_model = model\n",
    "                                best_model_info = f\"conv1_channel:{conv1_channel}, conv1_kenle:{conv1_kernel}, conv2_channel:{conv2_channel}, conv2_kenle:{conv2_kernel}, \"\\\n",
    "                              f\"fc1_size:{fc1_size}, fc2_size:{fc2_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出全局最好的结果\n",
    "print(\"the result of searching is \"+ best_model_info)\n",
    "print(f\"the accumulate of best model is:{overall_best_accuracy:.2f}%\")\n",
    "# print(best_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
