{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# न्यूरल नेटवर्क आर्किटेक्चर सर्च (एनएएस) अभ्यास"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कार्य: एक सरल NAS एल्गोरिदम बनाएं\n",
    "\n",
    "ग्रिड खोज: एल्गोरिथम विचार, सभी संभावित संयोजनों पर ग्रिड खोज करें और सबसे उपयुक्त संयोजन का चयन करें"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "पायथन फ़ंक्शन लाइब्रेरी लोड करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# डेटा सेट लोड करें और प्रशिक्षण प्रक्रिया को परिभाषित करें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# सामान्यीकरण सेट करें\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# डेटा सेट प्राप्त करें\n",
    "train_dataset = datasets.MNIST(root='../ch02/data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='../ch02/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# डेटालोडर सेट करें\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "# अनुसूचक: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "# डेटा को सीपीयू से जीपीयू में ले जाएं\n",
    "# इनपुट = इनपुट.टू('एमपीएस')\n",
    "# लक्ष्य = लक्ष्य.से('एमपीएस')\n",
    "\n",
    "# ग्रेडिएंट्स को रीसेट करें (अंतिम पुनरावृत्ति से)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "#आगे का अनुमान\n",
    "    outputs = model(inputs.cuda()).cpu()\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "#पिछड़ा प्रचार\n",
    "    loss.backward()\n",
    "\n",
    "# ऑप्टिमाइज़र और एलआर शेड्यूलर को अपडेट करें\n",
    "    optimizer.step()\n",
    "# शेड्यूलर.स्टेप()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "# डेटा को सीपीयू से जीपीयू में ले जाएं\n",
    "# इनपुट = इनपुट.टू('एमपीएस')\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "# लक्ष्य = लक्ष्य.से('एमपीएस')\n",
    "\n",
    "#अनुमान\n",
    "    outputs = model(inputs.cuda()).cpu()\n",
    "\n",
    "# लॉग को क्लास इंडेक्स में बदलें\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "# मेट्रिक्स अपडेट करें\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_flops(model, inputs):\n",
    "    num_macs = profile_macs(model, inputs)\n",
    "    return num_macs\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32):\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    \"\"\"\n",
    "    num_elements = 0\n",
    "    for param in model.parameters():\n",
    "        num_elements += param.numel()\n",
    "    return num_elements * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# तंत्रिका नेटवर्क वास्तुकला खोज\n",
    "\n",
    "## कार्य, दिए गए सीमित मॉडल आकार के तहत सर्वोत्तम परिणाम ढूंढें\n",
    "\n",
    "खोज विधि: ग्रिड खोज\n",
    "\n",
    "स्थान खोजें: LeNet पर, विभिन्न ट्रैवर्सल स्थितियों को परिभाषित करें, उन्हें संयोजित करें, और फिर क्रम में मॉडल आकार को प्रशिक्षित और सत्यापित करें\n",
    "\n",
    "आउटपुट: अंत में उपयुक्त तंत्रिका नेटवर्क संरचना को आउटपुट करें और इसे सहेजें"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet नेटवर्क को परिभाषित करें\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, conv1_channel=6, conv1_kernel=5, conv2_channel=16, conv2_kernel=5, fc1_size=128, fc2_size=84, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=conv1_channel, kernel_size=conv1_kernel) \n",
    "# 1 x 28 x 28 -> conv1_channel x (28-conv1_kernel+1) x (28-conv1_kernel+1)\n",
    "# conv1_channel x (28-conv1_kernel+1) x (28-conv1_kernel+1) -> conv1_channel x (28-conv1_kernel+1)//2 x (28-conv1_kernel+1)//2\n",
    "        self.conv2 = nn.Conv2d(in_channels=conv1_channel, out_channels=conv2_channel, kernel_size=conv2_kernel) \n",
    "# conv1_channel x (28-conv1_kernel+1)//2 x (28-conv1_kernel+1)//2 -> conv2_channel x ((28-conv1_kernel+1)//2- conv2_kernel + 1) x ((28-conv1_kernel +1)//2- conv2_कर्नेल + 1)\n",
    "# conv2_channel x ((28-conv1_kernel+1)//2- conv2_kernel + 1) x ((28-conv1_kernel+1)//2- conv2_kernel + 1) -> conv2_channel x ((28-conv1_kernel+1)// 2- conv2_kernel + 1)//2 x ((28-conv1_kernel+1)//2- conv2_kernel + 1)//2\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        linear_input_dim = conv2_channel * (((28-conv1_kernel+1)//2-conv2_kernel+1)//2)**2 \n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=linear_input_dim, out_features=fc1_size)\n",
    "        self.fc2 = nn.Linear(in_features=fc1_size, out_features=fc2_size)\n",
    "        self.fc3 = nn.Linear(in_features=fc2_size, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# मॉडल = LeNet().to(डिवाइस=डिवाइस)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# खोज स्थान को परिभाषित करें\n",
    "conv1_channel_list = [3, 6, 9]\n",
    "conv1_kernel_list = [3, 5, 7]\n",
    "conv2_channel_list = [12, 16, 20]\n",
    "conv2_kernel_list = [3, 5, 7]\n",
    "fc1_size_list = [64, 128, 256]\n",
    "fc2_size_list = [32, 84, 120]\n",
    "\n",
    "# मॉडल प्रशिक्षण पैरामीटर कॉन्फ़िगरेशन\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "num_epoch = 5\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "limitation_model_size = 0.05 # 限制模型大小\n",
    "\n",
    "# सर्वश्रेष्ठ वैश्विक रिकॉर्ड दर्ज करें\n",
    "best_model = None\n",
    "best_model_info = \"\"\n",
    "overall_best_accuracy = 0\n",
    "\n",
    "## खोजना शुरू करें\n",
    "print(\"Searning\")\n",
    "for conv1_channel in conv1_channel_list:\n",
    "    for conv1_kernel in conv1_kernel_list:\n",
    "        for conv2_channel in conv2_channel_list:\n",
    "            for conv2_kernel in conv2_kernel_list:\n",
    "                for fc1_size in fc1_size_list:\n",
    "                    for fc2_size in fc2_size_list:\n",
    "                        model = LeNet(conv1_channel, conv1_kernel, conv2_channel, conv2_kernel, fc1_size, fc2_size).to(device=device)\n",
    "                        fp32_model_size = get_model_size(model)\n",
    "                        if fp32_model_size/MiB < limitation_model_size:\n",
    "                            print(f\"conv1_channel:{conv1_channel}, conv1_kenle:{conv1_kernel}, conv2_channel:{conv2_channel}, conv2_kenle:{conv2_kernel}, \"\\\n",
    "                              f\"fc1_size:{fc1_size}, fc2_size:{fc2_size}\")\n",
    "                            print(f\"model has size={fp32_model_size/MiB:.2f} MiB\")\n",
    "                            optimizer = torch.optim.SGD(model.parameters(),  lr=lr, momentum=momentum)  # lr学习率，momentum冲量\n",
    "                            best_accuracy = 0 \n",
    "                            best_checkpoint = dict()\n",
    "                            for epoch in range(num_epoch):\n",
    "                                train(model, train_loader, criterion, optimizer)\n",
    "                                accuracy = evaluate(model, test_loader)\n",
    "                                is_best = accuracy > best_accuracy\n",
    "                                if is_best:\n",
    "                                    best_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n",
    "                                    best_accuracy = accuracy\n",
    "                                print(f'Epoch{epoch+1:>2d} Accuracy {accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "                            model.load_state_dict(best_checkpoint['state_dict'])\n",
    "                            model_accuracy = evaluate(model, test_loader)\n",
    "                            print(f\"Model has accuracy={model_accuracy:.2f}%\")\n",
    "# वैश्विक रिकॉर्ड\n",
    "                            if model_accuracy > overall_best_accuracy:\n",
    "                                overall_best_accuracy = model_accuracy\n",
    "                                best_model = model\n",
    "                                best_model_info = f\"conv1_channel:{conv1_channel}, conv1_kenle:{conv1_kernel}, conv2_channel:{conv2_channel}, conv2_kenle:{conv2_kernel}, \"\\\n",
    "                              f\"fc1_size:{fc1_size}, fc2_size:{fc2_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# सर्वोत्तम वैश्विक परिणाम आउटपुट करें\n",
    "print(\"the result of searching is \"+ best_model_info)\n",
    "print(f\"the accumulate of best model is:{overall_best_accuracy:.2f}%\")\n",
    "# प्रिंट(best_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
