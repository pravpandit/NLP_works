# अध्याय 2 सीएनएन मूल बातें

>यह ट्यूटोरियल आपको मॉडल संपीड़न के आकर्षण की सराहना करने के लिए सीएनएन नेटवर्क को मूल बिंदु के रूप में ले जाएगा। जिन छात्रों के पास कुछ बुनियादी बातें हैं, उन्हें सीएनएन के बारे में पता होना चाहिए, तो क्या आप चैनल, कनवल्शन कर्नेल, फ़िल्टर जैसे शब्दों के बीच अंतर को अलग कर सकते हैं। फ़ीचर मानचित्र, परत, आदि? यदि आप अंतर नहीं कर सकते, तो कृपया इस ट्यूटोरियल को संदेह के साथ पढ़ें।

## 2.1 सीएनएन का परिचय

&emsp;&emsp;सीएनएन नेटवर्क, अर्थात् कन्वोल्यूशनल न्यूरल नेटवर्क, एक प्रकार का गहन अध्ययन हैछवियों (2डी ग्रिड) और ध्वनि संकेतों (1डी ग्रिड) जैसे ग्रिड जैसी संरचना वाले डेटा को संसाधित करने के लिए विशेष रूप से डिज़ाइन किए गए नेटवर्क ने छवि और वीडियो पहचान, छवि वर्गीकरण, चिकित्सा छवि विश्लेषण और अन्य क्षेत्रों में उल्लेखनीय सफलता हासिल की है।

### 2.1.1 कोर रचना
&emsp;&emsp;सीएनएन का मुख्य विचार मैनुअल फीचर निष्कर्षण के बिना इनपुट डेटा की सुविधाओं को स्वचालित रूप से और प्रभावी ढंग से निकालने के लिए कनवल्शनल परतों का उपयोग करना हैवर्गीकरण, पता लगाने या विभाजन जैसे कार्यों को करने के लिए नेटवर्क की कई परतों के माध्यम से संयुक्त सीएनएन में आमतौर पर निम्नलिखित प्रकार की परतें होती हैं:

1. **संवादात्मक परतें**:
ये परतें कन्वोल्यूशन ऑपरेशंस के माध्यम से इनपुट डेटा की स्थानीय विशेषताओं को निकालती हैं। प्रत्येक कन्वोल्यूशनल परत में मल्टीपल कन्वोल्यूशन कर्नेल अलग-अलग फीचर मैप उत्पन्न कर सकते हैं।

2. **सक्रियण परतें**:
आम तौर पर कनवल्शन परत का पालन करें, गैर-रैखिकता का परिचय दें, ताकि नेटवर्क सीख सकेअधिक जटिल विशेषताएं। सबसे अधिक इस्तेमाल किया जाने वाला सक्रियण फ़ंक्शन ReLU (रेक्टिफाइड लीनियर यूनिट) है।

3. **पूलिंग परतें**:
इन परतों का उपयोग फ़ीचर मानचित्र के स्थानिक आकार को कम करने, बाद की परतों के मापदंडों और गणनाओं की संख्या को कम करने और फ़ीचर पहचान को अधिक स्थिर बनाने के लिए किया जाता है।

4. **पूरी तरह से जुड़ी हुई परतें**:
आमतौर पर सीएनएन के अंत में स्थित, यह उच्च-आयामी फीचर वेक्टर आउटपुट को कनवल्शन लेयर या पूलिंग लेयर द्वारा अंतिम आउटपुट में परिवर्तित करता है, जैसे कि वेंई वर्गीकरण लेबल।

### 2.1.2 लाभ
&emsp;&emsp;सीएनएन पारंपरिक मशीन सीखने के तरीकों में मैन्युअल फीचर निष्कर्षण की कठिन प्रक्रिया से बचते हुए, परतों के सुपरपोजिशन और संयोजन के माध्यम से कच्चे डेटा से उपयोगी फीचर प्रतिनिधित्व को स्वचालित रूप से और प्रभावी ढंग से सीख सकता है। इसके निम्नलिखित फायदे हैं:
1. पैरामीटर शेयरिंग: कन्वेन्शनल परत में कन्वेन्शनल कर्नेल में पैरामीटर के समान सेट का पुन: उपयोग करके, सीएनएन कम पी के साथ बड़े पैमाने पर इनपुट डेटा को संसाधित कर सकता हैपैरामीटर.
2. स्थानीय कनेक्शन: कनवल्शनल परत में न्यूरॉन्स केवल इनपुट डेटा के स्थानीय क्षेत्र से जुड़े होते हैं, जो नेटवर्क को स्थानीय सुविधाओं पर ध्यान केंद्रित करने और मॉडल के स्थानिक उपयोग को बढ़ाने की अनुमति देता है।
3. अनुवाद अपरिवर्तनीयता: पूलिंग परत के माध्यम से, सीएनएन इनपुट डेटा के छोटे पैमाने पर अनुवाद के लिए अपरिवर्तनीय रह सकता है, जो छवियों में वस्तुओं की पहचान करने के लिए विशेष रूप से महत्वपूर्ण है।

&emsp;&emsp;नीचे दिया गया चित्र एक दृश्य उदाहरण है, कृपया देखें [सीएनएन-स्पष्ट करेंएर](https://poloclub.github.io/cnn-explainer)

![](images/convlayer_overview_demo.gif)

## 2.2 संबंधित शब्दों की व्याख्या

- चैनल: आमतौर पर डेटा की गहराई के आयाम को संदर्भित करता है। उदाहरण के लिए, एक रंगीन छवि में तीन रंग चैनल होते हैं: लाल, हरा और नीला (आरजीबी)। सीएनएन में, इनपुट परत में चैनलों की संख्या रंग की संख्या से मेल खाती है छवि के चैनल, जबकि छिपी हुई परत में चैनलों की संख्या परत में फिल्टर की संख्या से मेल खाती है, अर्थात, fe की संख्याप्रत्येक फ़िल्टर द्वारा उत्पन्न प्रकृति मानचित्र।
- कनवल्शन कर्नेल: कनवल्शन परत में फीचर निष्कर्षण के लिए उपयोग किया जाने वाला एक छोटा मैट्रिक्स, कनवल्शन ऑपरेशन करते समय, कनवल्शन कर्नेल इनपुट डेटा के प्रत्येक क्षेत्र पर स्लाइड करता है, संबंधित स्थानीय क्षेत्र के साथ तत्व-वार गुणन करता है। फिर उन्हें कनवल्शन आउटपुट का एक तत्व बनाने के लिए सारांशित किया जाता है, कनवल्शन कर्नेल डेटा की स्थानीय विशेषताओं, जैसे किनारों, बनावट आदि को कैप्चर कर सकता है।
- फ़िल्टर: इसमें मल्टीपल शामिल हैई कन्वोल्यूशन कर्नेल, जिसकी संख्या इनपुट डेटा के चैनलों की संख्या के बराबर है, उदाहरण के लिए, तीन रंगीन चैनलों के साथ एक रंगीन छवि के लिए, आरजीबी, एक फिल्टर में तीन कनवल्शन कर्नेल होंगे, प्रत्येक रंग चैनल के लिए एक संपूर्ण फ़िल्टर इनपुट डेटा पर कार्य करता है, एक द्वि-आयामी फ़ीचर मानचित्र तैयार किया जाएगा, फ़िल्टर विशिष्ट प्रकार की सुविधाओं का पता लगा सकते हैं, और विभिन्न फ़िल्टर विभिन्न सुविधाओं को कैप्चर कर सकते हैं।
- फ़ीचर मानचित्र: निकाले गए फ़ीचर प्रतिनिधित्व को संदर्भित करता हैइनपुट डेटा (जैसे एक छवि) से एक विशिष्ट कनवल्शन फ़िल्टर के माध्यम से जब इनपुट डेटा एक कनवल्शन परत से गुजरता है, तो इस परत के प्रत्येक फ़िल्टर को एक नया द्वि-आयामी सरणी उत्पन्न करने के लिए इनपुट डेटा पर स्वतंत्र रूप से लागू किया जाता है। फ़ीचर मानचित्र.
- परत: सीएनएन में कई परतें होती हैं, जिनमें से प्रत्येक एक कनवल्शन परत, एक पूलिंग परत, एक पूरी तरह से जुड़ी हुई परत आदि हो सकती है। प्रत्येक कनवल्शन परत में कई फिल्टर होते हैं, प्रत्येक फ़िल्टर एक फीचर मैप उत्पन्न करता हैकनवल्शन ऑपरेशन, और परत के आउटपुट को बनाने के लिए सभी फ़ीचर मानचित्रों को एक साथ स्टैक किया जाता है।

**कनेक्शन और अंतर:**

- कर्नेल मूल इकाई है जो फ़िल्टर का निर्माण करती है। मल्टी-चैनल इनपुट को संयोजित करते समय, प्रत्येक चैनल का अपना संबंधित कर्नेल होता है, और उनका संग्रह एक फ़िल्टर का निर्माण करता है।
- फ़िल्टर कर्नेल का एक सेट है, जिसका उपयोग इनपुट डेटा से एक विशिष्ट फीचर सेट को निकालने के लिए किया जाता है।
- चैनल डेटा के गहराई आयाम को संदर्भित करता है, जहां चैनल आमतौर पर मेल खाता हैएक प्राकृतिक छवि के रंग चैनल के लिए, और कनवल्शन परत द्वारा आउटपुट चैनलों की संख्या परत में फिल्टर की संख्या से निर्धारित होती है।
- लेयर सीएनएन में एक घटक इकाई है, और उनके कार्यों के अनुसार विभिन्न प्रकार की परतें हैं, कन्वोल्यूशन लेयर उनमें से एक है, जो फीचर निष्कर्षण के लिए फिल्टर का उपयोग करती है।
- कर्नेल/फ़िल्टर स्थानीय सुविधाओं के निष्कर्षण पर केंद्रित है, चैनल सुविधाओं की विविधता और प्रतिनिधित्व पर केंद्रित है, और लेयर नेटवर्क संरचना का एक घटक हैture.

निम्नलिखित चित्र 3-चैनल छवि पर एक कनवल्शन ऑपरेशन दिखाता है:

![](images/multi_channel.gif)

&emsp;&emsp;3 × 3 × 3` के आयाम वाले तीन कनवल्शन कर्नेल (फ़िल्टर भी कहा जाता है) चैनल हैं, जो कनवल्शन कर्नेल की ऊंचाई, चौड़ाई और गहराई का प्रतिनिधित्व करते हैं। कनवल्शन ऑपरेशन पहले तीन इनपुट चैनलों पर कनवल्शन ऑपरेशन करता है , फिर कनवल्शन परिणाम जोड़ता है, और अंत में एक फीचर मैप आउटपुट करता है।

&emsp;&emsp;नीचे 3डी डेटा का एक उदाहरण हैकल्पना करना कठिन है, सभी डेटा (इनपुट डेटा वॉल्यूम नीला है, वेट डेटा वॉल्यूम लाल है, और आउटपुट डेटा वॉल्यूम हरा है) कॉलम में गहराई के स्लाइस को व्यवस्थित करके प्रदर्शित किया जाता है।

![](images/conv_demo.gif)

कनवल्शन ऑपरेशन अनिवार्य रूप से फ़िल्टर और इनपुट डेटा के स्थानीय क्षेत्र के बीच एक डॉट उत्पाद है। कनवल्शनल परतों का सामान्य कार्यान्वयन। वर्तमान विधि इसका लाभ उठाना और कनवल्शनल परत के आगे के प्रसार को चालू करना है। एक विशाल मेंमैट्रिक्स गुणन.

## 2.3 मॉडल संपीड़न के लिए सामान्य मूल्यांकन संकेतक

&emsp;&emsp;मॉडल संपीड़न गहन शिक्षण मॉडल के आकार और गणना को कम करने की एक तकनीक है। इसका उद्देश्य मॉडल के प्रदर्शन को बनाए रखते हुए संसाधन खपत को कम करना है, जिससे मॉडल को संसाधन-बाधित उपकरणों पर तैनाती के लिए अधिक उपयुक्त बनाया जा सके संपीड़न में शामिल हैं:

### 2.3.1 सटीकता

&emsp;&emsp;सटीकता से तात्पर्य किसी विशिष्ट पर मॉडल की सटीकता से हैसंपीड़न से पहले और बाद के कार्य, जैसे वर्गीकरण सटीकता, पता लगाने की सटीकता, आदि। हालांकि संपीड़न सटीकता की एक निश्चित डिग्री का त्याग कर सकता है, लक्ष्य स्वीकार्य सटीकता बनाए रखते हुए संपीड़ित करना है।

### 2.3.2 पैरामीटर्स

&emsp;&emsp;पैरामीटर एक मॉडल में प्रशिक्षित करने योग्य मापदंडों की कुल संख्या को संदर्भित करते हैं, आमतौर पर सभी भार और पूर्वाग्रहों की कुल संख्या जो एक गहन शिक्षण मॉडल बनाते हैं। संपीड़न के बाद मॉडल मापदंडों की संख्या आमतौर पर काफी कम हो जाती है।### 2.3.3 मॉडल आकार

&emsp;&emsp;मॉडल आकार संपीड़न प्रभाव को मापने के लिए सबसे सहज संकेतक है, जिसे आमतौर पर मॉडल फ़ाइल के भंडारण आकार (जैसे एमबी) द्वारा मापा जाता है: `आकार = पैरामीटर * बैंडविड्थ`

उदाहरण के लिए, एक मॉडल का पैरामीटर आकार 61एम है, यह मानते हुए कि 32-बिट फ्लोटिंग पॉइंट नंबर स्टोरेजस्टोरेज के लिए उपयोग किए जाते हैं, तो मॉडल का आकार है:
$$ 61एम * 4बाइट्स(32बिट्स) = 224एमबी(224 * 10^6 बाइट्स) $$

### 2.3.4 एमएसी

&emsp;&emsp;MACs (की संख्या)मल्टीप्ली-एक्युमुलेट ऑपरेशंस) गुणन-संचय ऑपरेशंस की संख्या का प्रतिनिधित्व करता है। यह कंप्यूटर के लिए फ़्लोटिंग-पॉइंट ऑपरेशंस करने के लिए मूल इकाई है, जिसमें गुणन ऑपरेशन और संचय (अतिरिक्त) ऑपरेशन शामिल हैं, इसका वर्णन करने के लिए एमएसी का उपयोग किया जाता है कनवल्शनल न्यूरल नेटवर्क (सीएनएन) में कनवल्शन ऑपरेशन की कम्प्यूटेशनल मात्रा, विशेष रूप से, जब हम कनवल्शन परत में आगे प्रसार करते हैं, तो प्रत्येक कनवल्शन कर्नेल एक डॉट निष्पादित करता हैइनपुट फीचर मैप के स्थानीय क्षेत्र के साथ उत्पाद (तत्व-वार गुणन), और फिर आउटपुट फीचर मैप पर एक मूल्य प्राप्त करने के लिए सभी डॉट उत्पादों के परिणामों को जमा करता है। इस प्रक्रिया में प्रत्येक गुणन और उसके बाद के संचय ऑपरेशन का गठन होता है एक मैक.

### 2.3.5 फ्लॉप

&emsp;&emsp;FLOPs (फ़्लोटिंग पॉइंट ऑपरेशंस की संख्या, FLOPs) एक मॉडल के लिए आवश्यक फ़्लोटिंग पॉइंट ऑपरेशंस की संख्या को संदर्भित करता है जो FLOPs कंप्यूटिंग के लिए आनुपातिक हैमॉडल के लिए आवश्यक संसाधन.

### 2.3.6 संपीड़न अनुपात

&emsp;&emsp;संपीड़न अनुपात मूल मॉडल आकार और संपीड़ित मॉडल आकार का अनुपात है। उच्च संपीड़न अनुपात का मतलब छोटा मॉडल आकार है, लेकिन इसके साथ प्रदर्शन हानि भी हो सकती है।

### 2.3.7 अनुमान गति

&emsp;&emsp;अनुमान गति मॉडल को आगे प्रसार करने के लिए आवश्यक समय को संदर्भित करती है। मॉडल संपीड़न आमतौर पर अनुमान गति में सुधार करता है क्योंकि यह गणना की मात्रा को कम करता हैदूसरा मॉडल आकार.

## संदर्भ लिंक

- <https://blog.csdn.net/weixin_38481963/article/details/109906338>
- <https://cs231n.github.io/convolutional-networks/>
- <https://poloclub.github.io/cnn-explainer/>