# अध्याय 1 परिचय

कंप्यूटिंग प्रदर्शन और भंडारण स्थान के विकास के साथ, डिवाइस बड़े गहन शिक्षण मॉडल का समर्थन कर सकते हैं, जिनमें से कुछ में लाखों (या यहां तक ​​कि अरबों) पैरामीटर हैं।

&emsp;&emsp;तंत्रिका नेटवर्क पर हाल के सैद्धांतिक शोध में, यह पाया गया है कि गहन शिक्षण तंत्रिका नेटवर्क की अनुकूलन प्रक्रिया में, न्यूरॉन्स में दो अनावश्यक स्थितियाँ होंगी, एक यह है कि विभिन्न न्यूरॉन्स एक ही भूमिका निभाने के लिए एक साथ काम करते हैं; वे मो नहीं करतेअनुकूलन प्रक्रिया के दौरान वे निरर्थक नोड बन गए।

समतुल्य नेटवर्क के विचार का उपयोग करते हुए, एक ओर, समान न्यूरॉन्स को एक ही न्यूरॉन में एकत्रित किया जा सकता है, और केवल संख्यात्मक परिवर्तन की आवश्यकता होती है, ताकि एक न्यूरॉन संख्यात्मक परिवर्तन को सहन कर सके; दूसरी ओर, नेटवर्क के समग्र प्रदर्शन को बदले बिना अनावश्यक न्यूरॉन्स को हटाया जा सकता है, जो प्रदर्शन को बदले बिना समग्र नेटवर्क गणना को कम कर देता है और यहां तक ​​कि प्रभावित भी कर सकता है।इसे आज़माएं। यह विचार मॉडल के प्रदर्शन को बदले बिना मॉडल न्यूरॉन्स को ट्रिम करना संभव बनाता है, इसलिए मॉडल प्रूनिंग की तकनीक को **मॉडल प्रूनिंग** कहा जाता है।

&emsp;&emsp;इसी प्रकार, कंप्यूटर में मॉडलों का संख्यात्मक भंडारण आम तौर पर फ्लोटिंग पॉइंट स्टोरेज होता है। विशिष्ट गणनाओं में, गणना सटीकता को उचित रूप से कम करने से अंतिम परिणाम प्रभावित नहीं होता है, लेकिन यह मॉडल संचालन के आकार और गणना की गति को कम कर सकता है। इस तकनीक को **मॉडल क्वांटिज़ा कहा जाता हैटियोन**.

&emsp;&emsp;ऐसी अन्य प्रौद्योगिकियाँ हैं जैसे आसवन सीखना, तंत्रिका नेटवर्क वास्तुकला खोज, आदि, जो मूल रूप से मॉडल मापदंडों और संख्यात्मक भंडारण के दृष्टिकोण से मॉडल के प्रदर्शन को बनाए रखते हुए मॉडल को छोटा बनाने के लक्ष्य को प्राप्त कर सकती हैं सामूहिक रूप से **मॉडल संपीड़न प्रौद्योगिकियों** के रूप में जाना जाता है। ये मॉडल संपीड़न प्रौद्योगिकियां बढ़ती जटिलता और संसाधन आवश्यकताओं से उत्पन्न चुनौतियों का समाधान करने में मदद करती हैंआधुनिक तंत्रिका नेटवर्क के मॉडल के आकार को कम करके और परिचालन दक्षता में सुधार करके, मॉडल विभिन्न उपकरणों पर गहन शिक्षण मॉडल तैनात कर सकता है, जो विभिन्न क्षेत्रों में व्यावहारिक अनुप्रयोगों के लिए संभावनाएं प्रदान करता है।

## 1.1 मॉडल प्रूनिंग

&emsp;&emsp;प्रूनिंग मुख्य रूप से गहन शिक्षण मॉडल से अनावश्यक कनेक्शन, वजन और यहां तक ​​कि पूरे न्यूरॉन्स को पहचानने और हटाने के बारे में है, इन अनावश्यक घटकों को हटाकर, मॉडल अधिक कॉम्पैक्ट बन सकता है, तेजी से चल सकता है, और अधिक एम हो सकता हैउच्च सटीकता बनाए रखते हुए एमोरी-कुशल। आम तौर पर प्रूनिंग वेट के साथ प्रूनिंग शुरू करने की सिफारिश की जाती है, क्योंकि यह प्रूनिंग न्यूरॉन्स की तरह मॉडल की वास्तुकला को नहीं बदलता है। प्रूनिंग वेट का सार चयनित एकल मापदंडों के वजन को निर्धारित करना है नेटवर्क शून्य पर। ये पैरामीटर मॉडल के तर्क को प्रभावित करने में सक्षम नहीं होंगे।

## 1.2 मॉडल परिमाणीकरण

&emsp;&emsp;क्वांटिज़ेशन एक और तकनीक है जो तंत्रिका नेटवर्क को छोटा, तेज़ और एम बनाती हैवजन और पूर्वाग्रहों की सटीकता को कम करके अयस्क कुशल पारंपरिक गहन शिक्षण मॉडल में, वजन और पूर्वाग्रहों जैसे मापदंडों को अक्सर 32-बिट फ्लोटिंग पॉइंट नंबरों (एकल परिशुद्धता) का उपयोग करके संग्रहीत और संसाधित किया जाता है, जो उच्च सटीकता प्रदान करता है लेकिन बहुत अधिक मेमोरी की आवश्यकता होती है। और कंप्यूटिंग संसाधन कम बिट्स (उदाहरण के लिए 8 बिट्स या उससे भी कम) का उपयोग करके इन मानों का प्रतिनिधित्व करके इस समस्या को हल करते हैं। यह मॉडल की मेमोरी फ़ुटप्रिंट को कम करता है और लीवर द्वारा गणना को गति देता है।पूर्णांक संचालन के लिए पुराने हार्डवेयर अनुकूलन।

## 1.3 ज्ञान आसवन

&emsp;&emsp;ज्ञान आसवन एक बड़े, जटिल मॉडल (अक्सर शिक्षक मॉडल कहा जाता है) से एक छोटे, सरलीकृत मॉडल (छात्र मॉडल कहा जाता है) में ज्ञान को स्थानांतरित करने की एक तकनीक है। शिक्षक मॉडल में बड़ी मात्रा में सीखी गई जानकारी शामिल होती है एक बड़े डेटासेट के प्रशिक्षण का उद्देश्य इस ज्ञान को अधिक संक्षिप्त और कुशल रूप में परिष्कृत करना है जिसे आसानी से रेसो पर तैनात किया जा सकता हैआग्रह-बाधित उपकरणों या सीमित कंप्यूटिंग शक्ति वाले परिदृश्यों में।

## 1.4 न्यूरल नेटवर्क आर्किटेक्चर खोज

&emsp;&emsp;न्यूरल नेटवर्क आर्किटेक्चर सर्च एक ऐसी तकनीक है जो किसी दिए गए मॉडल आर्किटेक्चर, रेंज और लंबाई जैसे खोज स्थान देकर, बहुत अधिक जनशक्ति की आवश्यकता के बिना स्वचालित रूप से इष्टतम नेटवर्क आर्किटेक्चर की खोज करने के लिए मशीन लर्निंग का उपयोग करती है नेटवर्क डिज़ाइन को एक खोज समस्या में परिवर्तित किया जाता है, और एक खोज रणनीति और एक स्वचालित मोड को डिज़ाइन करकेएल मूल्यांकन पद्धति, एक तंत्रिका नेटवर्क वास्तुकला जो दिए गए खोज स्थान में लक्ष्य को पूरा करती है, स्वचालित रूप से और जल्दी से खोजी जाती है।

## 1.5 सारांश

मॉडल संपीड़न विधियाँ जैसे कि प्रूनिंग, परिमाणीकरण, आसवन और तंत्रिका वास्तुकला खोज नेटवर्क अतिरेक को हटाने के लिए प्रभावी समाधान प्रदान करती हैं। विभिन्न मॉडल संपीड़न विधियों की विशेषताएं इस प्रकार हैं:

|. विधि |. लागू स्तर |. क्या पूर्व-प्रशिक्षित मॉडल की आवश्यकता है |उम्र |
|----------------|-------|-------|--- ---------------|--|------|
|. मॉडल प्रूनिंग | पैरामीटर्स, चैनल, फिल्टर और कनवल्शनल परतों और महत्वहीन भागों के महत्व को निर्धारित करें | कनवल्शनल लेयर, पूरी तरह से कनेक्टेड लेयर | हां | हार्डवेयर पर त्वरण को सुविधाजनक बनाने के लिए पैरामीटर की संख्या को काफी कम कर सकता है; नेटवर्क संकरा, भंडारण स्थान और कंप्यूटिंग गति में तेजी लाने की सुविधा |एनजी अनियमित नेटवर्क संरचना का कारण बनेगा, जिससे प्रभावी ढंग से तेजी लाना मुश्किल हो जाएगा; संरचित प्रूनिंग हार्डवेयर प्लेटफार्मों के साथ असंगति और खराब लचीलेपन का कारण बन सकती है
|. मॉडल परिमाणीकरण | वजन साझाकरण और मैट्रिक्स सन्निकटन के आधार पर, पैरामीटर और सक्रियण मूल्यों के लिए भंडारण बिट्स की संख्या कम करें, और मेमोरी ओवरहेड को कम करें, पूरी तरह से कनेक्टेड परत | हां | इसमें अच्छा संपीड़न और नेटवर्क प्रदर्शन है, और कम प्रशिक्षण समय है एक छोटा जाल प्राप्त कर सकते हैंछोटे भंडारण, कम गणना और अच्छे नेटवर्क प्रदर्शन के साथ काम करें | परिमाणित भार और सक्रियण नेटवर्क की क्षमता और फीचर मानचित्रों की गुणवत्ता को कम करते हैं, इसके अलावा, भविष्यवाणी सटीकता में कमी करना आसान होता है ग्रेडिएंट जानकारी में शोर उत्पन्न करेगा, जिससे ग्रेडिएंट डिसेंट विधि के आधार पर प्रशिक्षण प्रक्रिया को अभिसरण करना अधिक कठिन हो जाएगा |
|. ज्ञान आसवन | सॉफ्टमैक्स क्लासिफायर आउटपुट का उपयोग सॉफ्ट के रूप में करेंज्ञान, छात्र नेटवर्क को प्रशिक्षित करने के लिए पूर्व ज्ञान के रूप में | संवादात्मक परत, संपूर्ण नेटवर्क |। प्रशिक्षित करने में आसान, मापदंडों की संख्या को काफी कम कर सकता है, अधिक संपीड़न प्राप्त करने के लिए अन्य संपीड़न विधियों के साथ संयोजन करना आसान है शिक्षक और छात्र मॉडल को प्रशिक्षित करें, कनवल्शन कर्नेल और छोटी दिशाओं वाले नेटवर्क के साथ विशेष संरचनाओं का उपयोग करना मुश्किल है, और सामान्यीकरण खराब है |
|. न्यूरल नेटवर्क आर्किटेक्चर खोज |इष्टतम मॉडल कॉन्फ़िगरेशन खोजने के लिए खोज एल्गोरिदम के माध्यम से विभिन्न नेटवर्क संरचनाएं |। नहीं, स्वचालित रूप से उच्च-प्रदर्शन, संसाधन-कुशल गहन शिक्षण मॉडल आर्किटेक्चर की खोज करने में सक्षम। और परिणाम खोज स्थान की परिभाषा और खोज एल्गोरिदम की पसंद से सीमित हो सकते हैं |