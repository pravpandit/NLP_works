# Awesome Compression

## Project Introduction

&emsp;&emsp;With the popularity of ChatGPT, large language models have emerged one after another and have shown extraordinary capabilities to effectively solve various problems. However, these models usually require a lot of computing resources and memory, resulting in high runtime resource consumption, which limits their application in certain scenarios and discourages many researchers. This project uses easy-to-understand language to introduce model compression methods such as pruning, quantization, and knowledge distillation, so that more novices can learn about model compression technology faster.

## Project Significance

&emsp;&emsp;Currently, the relevant information on model compression on the Internet is relatively complicated, and it is difficult for beginners to find a simple and high-quality Chinese introductory tutorial to learn. This project draws on [MIT 6.5940 TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2023-fall-65940) to provide an introductory tutorial on model compression and lower the learning threshold of model compression. In the tutorial, you will learn about different compression methods, and through practice and examples, learn how to apply these methods to compress deep learning models to meet practical application needs.

## Project Audience

&emsp;&emsp;This project is suitable for the following learners:

- DeepLearning researchers;
- Embedded system and mobile application developers;
- Developers interested in AI hardware acceleration and deployment;
- Students interested in model compression technology.

## Project highlights

- Provide easy-to-understand theoretical content to popularize model compression technology;
- Provide practical code to help learners better understand theoretical content in combination with actual scenarios.

### Table of Contents

- Chapter 1 Introduction
- Chapter 2 CNN Basics
- Chapter 3 Model Pruning
- Chapter 4 Model Quantization
- Chapter 5 Neural Network Architecture Search
- Chapter 6 Knowledge Distillation
- Chapter 7 Project Practice

## Course Knowledge Mind Map

## Roadmap

- Step 1: Build the content framework and confirm the person in charge of each chapter (1 month);
- Step 2: Write the chapter content (3 months);
- Step 3: Revise and improve the overall content (1 month).

## Contribute

- If you want to participate in the project, please check the [Issue]() of the project to view the unassigned tasks.
- If you find some problems, please give feedback in [Issue]()üêõ.
- If you are interested in this project and want to participate, you can communicate through [Discussion]()üí¨.

If you are interested in Datawhale and want to start a new project, you are welcome toWelcome to [Datawhale Contribution Guide](https://github.com/datawhalechina/DOPMC#%E4%B8%BA-datawhale-%E5%81%9A%E5%87%BA%E8%B4%A1%E7%8C%AE).

## List of Contributors

| Name | Responsibilities | Introduction |
| :----| :---- | :---- |
| [Chen Yuli](https://github.com/ironartisan) | Project Leader | Datawhale Member - Graduate Student at Beijing University of Posts and Telecommunications |
| [Jiang Weiwei](https://jwwthu.github.io) | Contributor to Chapters 1 and 2 | Assistant Professor at Beijing University of Posts and Telecommunications |
| [Sun Hanyu](https://github.com/sunhanyu714) | Contributor to Chapter 4 | Model Deployment Engineer |
| [Zhang Yijie](https://github.com/Wings236) | Contributor to Chapter 5 | Graduate Student at Jinan University |
| [Wei Yukang](https://github.com/JinYu1998) | Contributor to Chapter 6 | Graduate Student at Hebei University of Science and Technology |

## Environment Installation
### Node.js version

Node v16

### Install docsify
```shell
npm i docsify-cli -g
```

### Start docsify
```shell
docsify serve ./docs
```

## Follow us

<div align=center>
<p>Scan the QR code below to follow the official account: Datawhale</p>
<img src="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg" width = "180" height = "180">
</div>

## LICENSE

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /></a><br />This work is licensed under a Creative Commons Attribution-NonCommercial-Share Alike 4.0 International License.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=datawhalechina/awesome-compression&type=Date)](https://star-history.com/#datawhalechina/awesome-compression)