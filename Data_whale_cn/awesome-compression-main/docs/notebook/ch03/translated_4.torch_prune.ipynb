{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pruning Torch Practice\n",
    "Pytorch has added pruning operations since version 1.4.0. In the `torch.nn.utils.prune` module, this tutorial divides the pruning range into the following pruning methods:\n",
    "- Local Pruning\n",
    "- Structured Pruning\n",
    "- Random Structured Pruning (random_structured)\n",
    "- Norm Structured Pruning (ln_structured)\n",
    "- Unstructured Pruning\n",
    "- Random Unstructured Pruning (random_unstructured)\n",
    "- Norm Unstructured Pruning (l1_unstructured)\n",
    "- Global Pruning\n",
    "- Unstructured Pruning (global_unstructured)\n",
    "- Custom Pruning (Custom Pruning)\n",
    "\n",
    "**Note:** Global pruning only has unstructured pruning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Local Pruning\n",
    "First, we will introduce the local pruning method, which refers to pruning a single layer or a local range of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Structured pruning\n",
    "According to the pruning method, it can be divided into structured pruning and unstructured pruning. Unstructured pruning will randomly change some weight parameters to 0, while structured pruning will change some channels of a certain dimension to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Random structured pruning (random_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a classic LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LeNet network\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print model structure\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 0.0220,  0.1789, -0.0544, -0.0713,  0.0478],\n",
      "          [ 0.1995, -0.0415,  0.0288, -0.1431,  0.1057],\n",
      "          [ 0.1600,  0.0248, -0.1903, -0.0242, -0.1961],\n",
      "          [-0.0211,  0.0257, -0.1116, -0.1678,  0.0611],\n",
      "          [ 0.0012,  0.0420, -0.1725, -0.1265, -0.1075]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540, -0.1928, -0.0355, -0.0075, -0.1481],\n",
      "          [ 0.0135,  0.0192,  0.0082, -0.0120, -0.0164],\n",
      "          [-0.0435, -0.1488,  0.1092, -0.0041,  0.1960],\n",
      "          [-0.1045, -0.0136,  0.0398, -0.1286,  0.0617],\n",
      "          [-0.0091,  0.0466,  0.1827,  0.1655,  0.0727]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1976,  0.0123,  0.1523, -0.1207,  0.1493],\n",
      "          [-0.1799,  0.0580,  0.1490,  0.1647, -0.0572],\n",
      "          [-0.0908,  0.1094, -0.0676, -0.0023,  0.0624],\n",
      "          [-0.0320, -0.1794,  0.1706, -0.0486,  0.0557],\n",
      "          [ 0.1482, -0.1306,  0.1213, -0.1090, -0.1267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1278,  0.1037, -0.0323, -0.1504,  0.1080],\n",
      "          [ 0.0266, -0.0996,  0.1499, -0.0845,  0.0609],\n",
      "          [-0.0662, -0.1405, -0.0586, -0.0615, -0.0462],\n",
      "          [-0.1118, -0.0961, -0.1325, -0.0417, -0.0741],\n",
      "          [ 0.1842, -0.1040, -0.1786, -0.0593,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]], requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0893, -0.1464, -0.1101, -0.0076,  0.1493, -0.0418],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# Print the parameters of the first convolutional layer\n",
    "module = model.conv1\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print the attribute tensor named_buffers in the module, which is initially an empty list\n",
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Print the model's state dictionary, which contains all the parameters\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first parameter: module, represents the specific module to be pruned, here it refers to module=model.conv1,\n",
    "# Indicates that pruning is to be performed on the first convolutional layer.\n",
    "# The second parameter: name, represents which parameters in the selected module to be pruned.\n",
    "# Here name=\"weight\" is set, which means to prune the weight in the network instead of bias.\n",
    "# The third parameter: amount, represents the pruning of a specific proportion or absolute number of parameters in the model.\n",
    "# amount is a float value between 0.0-1.0, representing the ratio, or a positive integer representing how many parameters to clip.\n",
    "# The fourth parameter: dim, represents the dimension index of the channel to be pruned.\n",
    "#            \n",
    "\n",
    "prune.random_structured(module, name=\"weight\", amount=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Print the model's state dictionary again and observe the conv1 layer\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-0.0893, -0.1464, -0.1101, -0.0076,  0.1493, -0.0418],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.0220,  0.1789, -0.0544, -0.0713,  0.0478],\n",
      "          [ 0.1995, -0.0415,  0.0288, -0.1431,  0.1057],\n",
      "          [ 0.1600,  0.0248, -0.1903, -0.0242, -0.1961],\n",
      "          [-0.0211,  0.0257, -0.1116, -0.1678,  0.0611],\n",
      "          [ 0.0012,  0.0420, -0.1725, -0.1265, -0.1075]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540, -0.1928, -0.0355, -0.0075, -0.1481],\n",
      "          [ 0.0135,  0.0192,  0.0082, -0.0120, -0.0164],\n",
      "          [-0.0435, -0.1488,  0.1092, -0.0041,  0.1960],\n",
      "          [-0.1045, -0.0136,  0.0398, -0.1286,  0.0617],\n",
      "          [-0.0091,  0.0466,  0.1827,  0.1655,  0.0727]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1976,  0.0123,  0.1523, -0.1207,  0.1493],\n",
      "          [-0.1799,  0.0580,  0.1490,  0.1647, -0.0572],\n",
      "          [-0.0908,  0.1094, -0.0676, -0.0023,  0.0624],\n",
      "          [-0.0320, -0.1794,  0.1706, -0.0486,  0.0557],\n",
      "          [ 0.1482, -0.1306,  0.1213, -0.1090, -0.1267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1278,  0.1037, -0.0323, -0.1504,  0.1080],\n",
      "          [ 0.0266, -0.0996,  0.1499, -0.0845,  0.0609],\n",
      "          [-0.0662, -0.1405, -0.0586, -0.0615, -0.0462],\n",
      "          [-0.1118, -0.0961, -0.1325, -0.0417, -0.0741],\n",
      "          [ 0.1842, -0.1040, -0.1786, -0.0593,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# Print the attribute tensor named_buffers in the module again\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]]]))]\n"
     ]
    }
   ],
   "source": [
    "# Print the attribute tensor named_buffers in the module again\n",
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: After pruning, the original weight matrix weight becomes weight_orig. And module.named_buffers(), which was printed as an empty list before pruning, now has an additional weight_mask parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540, -0.1928, -0.0355, -0.0075, -0.1481],\n",
      "          [ 0.0135,  0.0192,  0.0082, -0.0120, -0.0164],\n",
      "          [-0.0435, -0.1488,  0.1092, -0.0041,  0.1960],\n",
      "          [-0.1045, -0.0136,  0.0398, -0.1286,  0.0617],\n",
      "          [-0.0091,  0.0466,  0.1827,  0.1655,  0.0727]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1278,  0.1037, -0.0323, -0.1504,  0.1080],\n",
      "          [ 0.0266, -0.0996,  0.1499, -0.0845,  0.0609],\n",
      "          [-0.0662, -0.1405, -0.0586, -0.0615, -0.0462],\n",
      "          [-0.1118, -0.0961, -0.1325, -0.0417, -0.0741],\n",
      "          [ 0.1842, -0.1040, -0.1786, -0.0593,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print module.weight and see what we find?\n",
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: After pruning, the original weight becomes weight_orig and is stored in named_parameters. The corresponding pruning matrix is ​​stored in weight_mask. The weight_mask is regarded as a mask tensor, and the result of multiplying it with weight_orig is stored in weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** After pruning, the weight is no longer a parameter of the module, but only an attribute of the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pruning operation, the model will correspond to a specific _forward_pre_hooks function for pruning, which stores the executed pruning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(327, <torch.nn.utils.prune.RandomStructured object at 0x00000235D8EFF1C0>)])\n"
     ]
    }
   ],
   "source": [
    "# print_forward_pre_hooks\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Norm structured pruning (ln_structured)\n",
    "The parameters of a model can be pruned multiple times, which is called iterative pruning. The above steps have performed random structured pruning on conv1. Next, perform norm structured pruning on it again. Let's see what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model state_dict keys:\n",
      "odict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "**************************************************\n",
      " module named_parameters:\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0893, -0.1464, -0.1101, -0.0076,  0.1493, -0.0418],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.0220,  0.1789, -0.0544, -0.0713,  0.0478],\n",
      "          [ 0.1995, -0.0415,  0.0288, -0.1431,  0.1057],\n",
      "          [ 0.1600,  0.0248, -0.1903, -0.0242, -0.1961],\n",
      "          [-0.0211,  0.0257, -0.1116, -0.1678,  0.0611],\n",
      "          [ 0.0012,  0.0420, -0.1725, -0.1265, -0.1075]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540, -0.1928, -0.0355, -0.0075, -0.1481],\n",
      "          [ 0.0135,  0.0192,  0.0082, -0.0120, -0.0164],\n",
      "          [-0.0435, -0.1488,  0.1092, -0.0041,  0.1960],\n",
      "          [-0.1045, -0.0136,  0.0398, -0.1286,  0.0617],\n",
      "          [-0.0091,  0.0466,  0.1827,  0.1655,  0.0727]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1976,  0.0123,  0.1523, -0.1207,  0.1493],\n",
      "          [-0.1799,  0.0580,  0.1490,  0.1647, -0.0572],\n",
      "          [-0.0908,  0.1094, -0.0676, -0.0023,  0.0624],\n",
      "          [-0.0320, -0.1794,  0.1706, -0.0486,  0.0557],\n",
      "          [ 0.1482, -0.1306,  0.1213, -0.1090, -0.1267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1278,  0.1037, -0.0323, -0.1504,  0.1080],\n",
      "          [ 0.0266, -0.0996,  0.1499, -0.0845,  0.0609],\n",
      "          [-0.0662, -0.1405, -0.0586, -0.0615, -0.0462],\n",
      "          [-0.1118, -0.0961, -0.1325, -0.0417, -0.0741],\n",
      "          [ 0.1842, -0.1040, -0.1786, -0.0593,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]], requires_grad=True))]\n",
      "**************************************************\n",
      " module named_buffers:\n",
      "[('weight_mask', tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]]]))]\n",
      "**************************************************\n",
      " module weight:\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "**************************************************\n",
      " module _forward_pre_hooks:\n",
      "OrderedDict([(328, <torch.nn.utils.prune.PruningContainer object at 0x00000235D919EE50>)])\n"
     ]
    }
   ],
   "source": [
    "# The first parameter: module, represents the specific module to be pruned, here it refers to module=model.conv1,\n",
    "# Indicates that pruning is to be performed on the first convolutional layer.\n",
    "# The second parameter: name, represents which parameters in the selected module to be pruned.\n",
    "# Here name=\"weight\" is set, which means to prune the weight in the network instead of bias.\n",
    "# The third parameter: amount, represents the pruning of a specific proportion or absolute number of parameters in the model.\n",
    "# amount is a float value between 0.0-1.0, representing the ratio, or a positive integer representing how many parameters to clip.\n",
    "# The fourth parameter: n, represents the norm type, here n=2 represents the L2 norm.\n",
    "# The fifth parameter: dim, represents the dimension index of the channel to be pruned.\n",
    "\n",
    "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "\n",
    "# Print model parameters again\n",
    "print(\" model state_dict keys:\")\n",
    "print(model.state_dict().keys())\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module named_parameters:\")\n",
    "print(list(module.named_parameters()))\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module named_buffers:\")\n",
    "print(list(module.named_buffers()))\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module weight:\")\n",
    "print(module.weight)\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module _forward_pre_hooks:\")\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Iterative pruning is equivalent to serializing multiple pruning cores into one pruning core. The new mask matrix is ​​combined with the old mask matrix using the compute_mask method in PruningContainer. Finally, there is only one weight_orig and weight_mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can I see all the pruning history? module._forward_pre_hooks is a mechanism for executing custom operations before the forward propagation of the model. The executed pruning methods are recorded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.nn.utils.prune.RandomStructured object at 0x00000235D8EFF1C0>, <torch.nn.utils.prune.LnStructured object at 0x00000235D9381F10>]\n"
     ]
    }
   ],
   "source": [
    "# Print pruning history\n",
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == \"weight\":  \n",
    "        break\n",
    "\n",
    "print(list(hook))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Random unstructured pruning (random_unstructured)\n",
    "You can prune any substructure of the model. In addition to pruning weights, you can also prune bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model state_dict keys:\n",
      "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "**************************************************\n",
      " module named_parameters:\n",
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.0220,  0.1789, -0.0544, -0.0713,  0.0478],\n",
      "          [ 0.1995, -0.0415,  0.0288, -0.1431,  0.1057],\n",
      "          [ 0.1600,  0.0248, -0.1903, -0.0242, -0.1961],\n",
      "          [-0.0211,  0.0257, -0.1116, -0.1678,  0.0611],\n",
      "          [ 0.0012,  0.0420, -0.1725, -0.1265, -0.1075]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540, -0.1928, -0.0355, -0.0075, -0.1481],\n",
      "          [ 0.0135,  0.0192,  0.0082, -0.0120, -0.0164],\n",
      "          [-0.0435, -0.1488,  0.1092, -0.0041,  0.1960],\n",
      "          [-0.1045, -0.0136,  0.0398, -0.1286,  0.0617],\n",
      "          [-0.0091,  0.0466,  0.1827,  0.1655,  0.0727]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1976,  0.0123,  0.1523, -0.1207,  0.1493],\n",
      "          [-0.1799,  0.0580,  0.1490,  0.1647, -0.0572],\n",
      "          [-0.0908,  0.1094, -0.0676, -0.0023,  0.0624],\n",
      "          [-0.0320, -0.1794,  0.1706, -0.0486,  0.0557],\n",
      "          [ 0.1482, -0.1306,  0.1213, -0.1090, -0.1267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1278,  0.1037, -0.0323, -0.1504,  0.1080],\n",
      "          [ 0.0266, -0.0996,  0.1499, -0.0845,  0.0609],\n",
      "          [-0.0662, -0.1405, -0.0586, -0.0615, -0.0462],\n",
      "          [-0.1118, -0.0961, -0.1325, -0.0417, -0.0741],\n",
      "          [ 0.1842, -0.1040, -0.1786, -0.0593,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([-0.0893, -0.1464, -0.1101, -0.0076,  0.1493, -0.0418],\n",
      "       requires_grad=True))]\n",
      "**************************************************\n",
      " module named_buffers:\n",
      "[('weight_mask', tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]]])), ('bias_mask', tensor([1., 1., 0., 1., 1., 1.]))]\n",
      "**************************************************\n",
      " module bias:\n",
      "tensor([-0.0893, -0.1464, -0.0000, -0.0076,  0.1493, -0.0418],\n",
      "       grad_fn=<MulBackward0>)\n",
      "**************************************************\n",
      " module _forward_pre_hooks:\n",
      "OrderedDict([(328, <torch.nn.utils.prune.PruningContainer object at 0x00000235D919EE50>), (329, <torch.nn.utils.prune.RandomUnstructured object at 0x00000235D8F4C310>)])\n"
     ]
    }
   ],
   "source": [
    "# The first parameter: module, represents the specific module to be pruned, here it refers to module=model.conv1,\n",
    "# Indicates that pruning is to be performed on the first convolutional layer.\n",
    "# The second parameter: name, represents which parameters in the selected module to be pruned.\n",
    "# Here name=\"weight\" is set, which means to prune the weight in the network instead of bias.\n",
    "# The third parameter: amount, represents the pruning of a specific proportion or absolute number of parameters in the model.\n",
    "# amount is a float value between 0.0-1.0, representing the ratio, or a positive integer representing how many parameters to clip.\n",
    "\n",
    "prune.random_unstructured(module, name=\"bias\", amount=1)\n",
    "\n",
    "# Print model parameters again\n",
    "print(\" model state_dict keys:\")\n",
    "print(model.state_dict().keys())\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module named_parameters:\")\n",
    "print(list(module.named_parameters()))\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module named_buffers:\")\n",
    "print(list(module.named_buffers()))\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module bias:\")\n",
    "print(module.bias)\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module _forward_pre_hooks:\")\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Applying different pruning strategies on different parameter sets of the module, we can find that in the model parameters state_dict and named_parameters, there are not only weight_orig but also bias_orig. In the parameter named_buffers, weight_mask and bias_mask also appear at the same time. \n",
    "Finally, because we apply two different pruning functions on two types of parameters, _forward_pre_hooks also prints out two different function results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Norm unstructured pruning (l1_unstructured)\n",
    "Previously, we introduced different methods for pruning the weight and bias of the specified conv1 layer. So, is it possible to support pruning specific parameters of multi-layer networks at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model state_dict keys:\n",
      "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias_orig', 'conv2.bias_mask', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "**************************************************\n",
      " module named_parameters:\n",
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.0220,  0.1789, -0.0544, -0.0713,  0.0478],\n",
      "          [ 0.1995, -0.0415,  0.0288, -0.1431,  0.1057],\n",
      "          [ 0.1600,  0.0248, -0.1903, -0.0242, -0.1961],\n",
      "          [-0.0211,  0.0257, -0.1116, -0.1678,  0.0611],\n",
      "          [ 0.0012,  0.0420, -0.1725, -0.1265, -0.1075]]],\n",
      "\n",
      "\n",
      "        [[[-0.0540, -0.1928, -0.0355, -0.0075, -0.1481],\n",
      "          [ 0.0135,  0.0192,  0.0082, -0.0120, -0.0164],\n",
      "          [-0.0435, -0.1488,  0.1092, -0.0041,  0.1960],\n",
      "          [-0.1045, -0.0136,  0.0398, -0.1286,  0.0617],\n",
      "          [-0.0091,  0.0466,  0.1827,  0.1655,  0.0727]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1976,  0.0123,  0.1523, -0.1207,  0.1493],\n",
      "          [-0.1799,  0.0580,  0.1490,  0.1647, -0.0572],\n",
      "          [-0.0908,  0.1094, -0.0676, -0.0023,  0.0624],\n",
      "          [-0.0320, -0.1794,  0.1706, -0.0486,  0.0557],\n",
      "          [ 0.1482, -0.1306,  0.1213, -0.1090, -0.1267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1278,  0.1037, -0.0323, -0.1504,  0.1080],\n",
      "          [ 0.0266, -0.0996,  0.1499, -0.0845,  0.0609],\n",
      "          [-0.0662, -0.1405, -0.0586, -0.0615, -0.0462],\n",
      "          [-0.1118, -0.0961, -0.1325, -0.0417, -0.0741],\n",
      "          [ 0.1842, -0.1040, -0.1786, -0.0593,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([-0.0893, -0.1464, -0.1101, -0.0076,  0.1493, -0.0418],\n",
      "       requires_grad=True))]\n",
      "**************************************************\n",
      " module named_buffers:\n",
      "[('weight_mask', tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]]])), ('bias_mask', tensor([1., 1., 0., 0., 1., 1.]))]\n",
      "**************************************************\n",
      " module weight:\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "**************************************************\n",
      " module bias:\n",
      "tensor([-0.0893, -0.1464, -0.0000, -0.0000,  0.1493, -0.0418],\n",
      "       grad_fn=<MulBackward0>)\n",
      "**************************************************\n",
      " module _forward_pre_hooks:\n",
      "OrderedDict([(328, <torch.nn.utils.prune.PruningContainer object at 0x00000235D919EE50>), (330, <torch.nn.utils.prune.PruningContainer object at 0x00000235DA526AF0>)])\n"
     ]
    }
   ],
   "source": [
    "# Prune the model's module parameters\n",
    "for n, m in model.named_modules():\n",
    "# Perform l1_unstructured pruning on all convolutional layers in the model, and select 20% of the parameters for pruning\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(m, name=\"bias\", amount=0.2)\n",
    "# Perform ln_structured pruning on all fully connected layers in the model, and select 40% of the parameters for pruning\n",
    "# elif isinstance(module, torch.nn.Linear):\n",
    "# prune.random_structured(module, name=\"weight\", amount=0.4, dim=0)\n",
    "\n",
    "# Print model parameters again\n",
    "print(\" model state_dict keys:\")\n",
    "print(model.state_dict().keys())\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module named_parameters:\")\n",
    "print(list(module.named_parameters()))\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module named_buffers:\")\n",
    "print(list(module.named_buffers()))\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module weight:\")\n",
    "print(module.weight)\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module bias:\")\n",
    "print(module.bias)\n",
    "print('*'*50)\n",
    "\n",
    "print(\" module _forward_pre_hooks:\")\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prune and permanently remove the model's weight. After the previous pruning steps, the original weight has become 'weight_orig', and weight is the result of multiplying 'weight_orig' and the mask matrix, becoming an attribute. Please observe what changes have occurred after remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      " model state_dict keys:\n",
      "odict_keys(['conv1.bias', 'conv1.weight', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "**************************************************\n",
      " model named_parameters:\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0893, -0.1464, -0.0000, -0.0000,  0.1493, -0.0418],\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0833, -0.1491, -0.1143,  0.0113],\n",
      "          [ 0.0452,  0.1662, -0.0425, -0.0904, -0.1235],\n",
      "          [ 0.0565,  0.0933, -0.0721,  0.0909,  0.1837],\n",
      "          [-0.1739,  0.0263,  0.1339,  0.0648, -0.0382],\n",
      "          [-0.1667,  0.1478,  0.0448, -0.0892,  0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0889, -0.0737, -0.1655, -0.1708, -0.0988],\n",
      "          [-0.1787,  0.1127,  0.0706, -0.0352,  0.1238],\n",
      "          [-0.0985, -0.1929, -0.0062,  0.0488, -0.1152],\n",
      "          [-0.1659, -0.0448,  0.0821, -0.0956, -0.0262],\n",
      "          [ 0.1928,  0.1767, -0.1792, -0.1364,  0.0507]]]], requires_grad=True))]\n",
      "**************************************************\n",
      " model named_buffers:\n",
      "[]\n",
      "**************************************************\n",
      " model forward_pre_hooks:\n",
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "# Perform pruning and permanent operation on the module weight remove\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        prune.remove(m, 'bias')\n",
    "\n",
    "# Perform pruning and permanent operation on conv1 weight remove\n",
    "prune.remove(module, 'weight')\n",
    "print('*'*50)\n",
    "\n",
    "# Print out the state dictionary of the pruned model\n",
    "print(\" model state_dict keys:\")\n",
    "print(model.state_dict().keys())\n",
    "print('*'*50)\n",
    "\n",
    "# Print model parameters again\n",
    "print(\" model named_parameters:\")\n",
    "print(list(module.named_parameters()))\n",
    "print('*'*50)\n",
    "\n",
    "# Print the model mask buffers parameters again\n",
    "print(\" model named_buffers:\")\n",
    "print(list(module.named_buffers()))\n",
    "print('*'*50)\n",
    "\n",
    "# Print the model's _forward_pre_hooks again\n",
    "print(\" model forward_pre_hooks:\")\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: After performing the remove operation on the model's weight and bias, weight_orig and bias_orig in the model parameter set disappear and become weight and bias, indicating that pruning has become permanent. For the named_buffers tensor printing, it can be seen that only [] is left, because weight_mask and bias-mask, which are masks for weight and bias, have taken effect and no longer need to be retained. \n",
    "Similarly, only an empty dictionary is left in _forward_pre_hooks. Weight and bias have become parameters again, and pruning has become permanent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four local pruning methods have been introduced above, but to a large extent, you need to decide to prune a certain layer of the network based on your own experience.\n",
    "A more general pruning strategy is to use global pruning, which prunes from the perspective of the entire network. After global pruning, the percentage of pruning on different layers may be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "**************************************************\n",
      "odict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.bias', 'conv2.weight_orig', 'conv2.weight_mask', 'fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.bias', 'fc2.weight_orig', 'fc2.weight_mask', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "model = LeNet().to(device=device)\n",
    "\n",
    "# First print the state dictionary of the initialized model\n",
    "print(model.state_dict().keys())\n",
    "print('*'*50)\n",
    "\n",
    "# Build parameter sets to determine which layers and parameter sets participate in pruning\n",
    "parameters_to_prune = (\n",
    "            (model.conv1, 'weight'),\n",
    "            (model.conv2, 'weight'),\n",
    "            (model.fc1, 'weight'),\n",
    "            (model.fc2, 'weight'))\n",
    "\n",
    "# Call the global pruning function global_unstructured in prune to perform the pruning operation\n",
    "prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n",
    "\n",
    "# Print the state dictionary of the pruned model\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pruning the model, different layers will have different proportions of weight parameters pruned off. Use the code to print it out and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 5.33%\n",
      "Sparsity in conv2.weight: 17.25%\n",
      "Sparsity in fc1.weight: 22.03%\n",
      "Sparsity in fc2.weight: 14.67%\n",
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "    100. * float(torch.sum(model.conv1.weight == 0))\n",
    "    / float(model.conv1.weight.nelement())\n",
    "    ))\n",
    "\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "    100. * float(torch.sum(model.conv2.weight == 0))\n",
    "    / float(model.conv2.weight.nelement())\n",
    "    ))\n",
    "\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "    100. * float(torch.sum(model.fc1.weight == 0))\n",
    "    / float(model.fc1.weight.nelement())\n",
    "    ))\n",
    "\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "    100. * float(torch.sum(model.fc2.weight == 0))\n",
    "    / float(model.fc2.weight.nelement())\n",
    "    ))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "    100. * float(torch.sum(model.conv1.weight == 0)\n",
    "               + torch.sum(model.conv2.weight == 0)\n",
    "               + torch.sum(model.fc1.weight == 0)\n",
    "               + torch.sum(model.fc2.weight == 0))\n",
    "         / float(model.conv1.weight.nelement()\n",
    "               + model.conv2.weight.nelement()\n",
    "               + model.fc1.weight.nelement()\n",
    "               + model.fc2.weight.nelement())\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: When the global pruning strategy is adopted (assuming that 20% of the parameters are involved in pruning), only 20% of the total parameters of the model are pruned, and the specific situation of each layer is determined by the specific parameter distribution of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pruning model inherits the class BasePruningMethod() to perform pruning. There are several methods inside: call, apply_mask, apply, prune, remove, etc. The __init__ (constructor) and compute_mask functions must be implemented to complete the custom pruning rule setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class of custom pruning method must inherit prune.BasePruningMethod\n",
    "class custom_prune(prune.BasePruningMethod):\n",
    "#Specify the type of pruning implemented by this technique (supported options are global, structured, and unstructured)\n",
    "    PRUNING_TYPE = \"unstructured\"\n",
    "\n",
    "# Internally implement the compute_mask function and define the pruning rules, which is essentially how to mask the weight parameters\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "# The rule defined here is to mask out every other parameter, and finally 50% of the parameters involved in pruning are masked out\n",
    "        mask.view(-1)[::2] = 0\n",
    "        return mask\n",
    "\n",
    "# Customize the pruning method function, and directly call the pruning class method apply internally\n",
    "def custome_unstructured_pruning(module, name):\n",
    "    custom_prune.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "2.996683120727539 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Instantiate the model class\n",
    "model = LeNet().to(device=device)\n",
    "\n",
    "start = time.time()\n",
    "# Call the function of the custom pruning method to perform custom pruning on the bias in the first fully connected layer fc1 in the model\n",
    "custome_unstructured_pruning(model.fc1, name=\"bias\")\n",
    "\n",
    "# The biggest sign of successful pruning is having the bias_mask parameter\n",
    "print(model.fc1.bias_mask)\n",
    "\n",
    "# Print the time taken for custom pruning\n",
    "duration = time.time() - start\n",
    "print(duration * 1000, 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The bias_mask tensor printed out completely masks every other bit in a predefined way, with 0 and 1 appearing alternately. When the remove operation is performed later, the weights in the original bias_orig will also be pruned every other bit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
