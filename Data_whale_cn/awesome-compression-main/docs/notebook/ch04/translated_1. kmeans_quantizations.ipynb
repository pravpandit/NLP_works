{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans Quantitative Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster quantization uses the K-means method to obtain the weighted cluster centers and labels. At the same time, the weights can be deduced from the cluster centers and labels, but there are losses in the process.\n",
    "<div align=\"center\"> <img src=\"../../ch04/images/k-means.jpg\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "First, we install the necessary environment. The dataset and model use the same minist dataset and LeNet network as in the previous chapters. (PS: It is best to create a separate conda environment first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing torchprofile...\n",
      "Installing fast-pytorch-kmeans...\n",
      "All required packages have been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "print('Installing torchprofile...')\n",
    "# !pip install torchprofile -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "print('Installing fast-pytorch-kmeans...')\n",
    "# ! pip install fast-pytorch-kmeans -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# ! pip install matplotlib -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# ! pip install tqdm -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# !conda install pytorch::pytorch torchvision torchaudio -c pytorch\n",
    "# It is best to go to the official website to find the version command that suits you to install pytorch\n",
    "print('All required packages have been successfully installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the python library used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/learning/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1077cab70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model and dataset\n",
    "\n",
    "The links to the dataset and model are as follows:\n",
    "\n",
    "- Model weights: https://github.com/datawhalechina/awesome-compression/blob/main/docs/notebook/ch02/model.pt\n",
    "- Dataset: https://github.com/datawhalechina/awesome-compression/tree/main/docs/notebook/ch02/data/mnist/MNIST/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LeNet network\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set normalization\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Get the dataset\n",
    "train_dataset = datasets.MNIST(root='../ch02/data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='../ch02/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# Setting up DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model's state dictionary\n",
    "checkpoint = torch.load('../ch02/model.pt')\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "fp32_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "# Move the data from CPU to GPU\n",
    "# inputs = inputs.to('mps')\n",
    "# targets = targets.to('mps')\n",
    "\n",
    "# Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "# Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "# Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "# Move the data from CPU to GPU\n",
    "# inputs = inputs.to('mps')\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "# targets = targets.to('mps')\n",
    "\n",
    "# Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "# Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "# Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create two functions: Calculate Flops and Model Size\n",
    "\n",
    "- Parameters (params):\n",
    "The number of parameters, usually in M.\n",
    "params = Kh × Kw × Cin × Cout\n",
    "- Model size (model size):\n",
    "In general deep learning frameworks (such as PyTorch), 32-bit storage is generally used, that is, one parameter is stored in 32 bits. Therefore, a model with 1M (M here is a unit of one million) parameters requires a storage space of: 1M * 32bit = 32Mb = 4MB.\n",
    "- Calculation (Flops):\n",
    "\n",
    "That is, the number of floating-point operations, which is used to measure the complexity of the algorithm/model. Graphs usually only consider the number of multiplication and addition operations, and only consider the calculation of parameter layers such as Conv and FC, ignoring BN and PReLU. In general, Conv and FC layers also ignore the calculation of pure addition operations, such as bias addition and shortcut residual addition. Currently, only BN and CNN can be used without bias.\n",
    "FLOPs = Kh * Kw * Cin * Cout * H * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_flops(model, inputs):\n",
    "    num_macs = profile_macs(model, inputs)\n",
    "    return num_macs\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32):\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    \"\"\"\n",
    "    num_elements = 0\n",
    "    for param in model.parameters():\n",
    "        num_elements += param.numel()\n",
    "    return num_elements * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the accuracy and size of the FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 model has accuracy=97.99%\n",
      "fp32 model has size=0.17 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "fp32_model_accuracy = evaluate(fp32_model, test_loader)\n",
    "fp32_model_size = get_model_size(fp32_model)\n",
    "print(f\"fp32 model has accuracy={fp32_model_accuracy:.2f}%\")\n",
    "print(f\"fp32 model has size={fp32_model_size/MiB:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build K-means quantization function\n",
    "\n",
    "$n$-bit k-means quantization will divide the data into $2^n$ clusters, and the data in the same cluster will share the same weight value.\n",
    "\n",
    "k-means quantization will create a codebook, which includes:\n",
    "\n",
    "- centroids: $2^n$ FP32 cluster centroids.\n",
    "- labels: an $n$-bit integer tensor with the same number of elements as the original FP32 weight tensor. Each integer indicates which cluster it belongs to.\n",
    "\n",
    "During inference, generate an FP32 tensor based on the codebook for inference:\n",
    "> ***quantized_weight* = *codebook.centroids*\\[*codebook.labels*\\].view_as(weight)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target bitwidth: 2 bits\n",
      "        num unique values before k-means quantization: 15\n",
      "        num unique values after  k-means quantization: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fast_pytorch_kmeans import KMeans\n",
    "from collections import namedtuple\n",
    "import pdb\n",
    "Codebook = namedtuple('Codebook', ['centroids', 'labels'])\n",
    "def k_means_quantize(fp32_tensor: torch.Tensor, bitwidth=4, codebook=None):\n",
    "    \"\"\"\n",
    "    quantize tensor using k-means clustering\n",
    "    :param fp32_tensor:\n",
    "    :param bitwidth: [int] quantization bit width, default=4\n",
    "    :param codebook: [Codebook] (the cluster centroids, the cluster label tensor)\n",
    "    :return:\n",
    "        [Codebook = (centroids, labels)]\n",
    "            centroids: [torch.(cuda.)FloatTensor] the cluster centroids\n",
    "            labels: [torch.(cuda.)LongTensor] cluster label tensor\n",
    "    \"\"\"\n",
    "    if codebook is None:\n",
    "# First calculate the number of cluster center points\n",
    "# get number of clusters based on the quantization precision\n",
    "        n_clusters = 2**bitwidth\n",
    "# print(n_clusters)\n",
    "# Use kmeans algorithm to get the center of the cluster\n",
    "# use k-means to get the quantization centroids\n",
    "        kmeans = KMeans(n_clusters=n_clusters, mode='euclidean', verbose=0)\n",
    "        labels = kmeans.fit_predict(fp32_tensor.view(-1, 1)).to(torch.long)\n",
    "        centroids = kmeans.centroids.to(torch.float).view(-1)\n",
    "        codebook = Codebook(centroids, labels)\n",
    "    \n",
    "# decode the codebook into k-means quantized tensor for inference\n",
    "# Decode the codebook to get the k-means quantized tensor\n",
    "    quantized_tensor = codebook.centroids[codebook.labels]\n",
    "    \n",
    "    fp32_tensor.set_(quantized_tensor.view_as(fp32_tensor))\n",
    "    return codebook\n",
    "\n",
    "def plot_matrix(tensor, ax, title, cmap=ListedColormap(['white'])):\n",
    "    ax.imshow(tensor.cpu().numpy(), vmin=-0.5, vmax=0.5, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    for i in range(0,tensor.shape[0]):\n",
    "        for j in range(0,tensor.shape[1]):\n",
    "            \n",
    "            text = ax.text(j, i, f'{tensor[i, j].item():.2f}',ha=\"center\", va=\"center\", color=\"k\") \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    bitwidth = 2\n",
    "    test_tensor = torch.tensor([\n",
    "        [-0.3747,  0.0874,  0.3200, -0.4868,  0.4404],\n",
    "        [-0.0402,  0.2322, -0.2024, -0.4986,  0.1814],\n",
    "        [ 0.3102, -0.3942, -0.2030,  0.0883, -0.4741]])\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(8, 12))\n",
    "    ax_left, ax_right = axes.ravel()\n",
    "    \n",
    "    plot_matrix(test_tensor, ax_left, 'original tensor')\n",
    "    \n",
    "    num_unique_values_before_quantization = test_tensor.unique().numel()\n",
    "\n",
    "    codebook_test = k_means_quantize(fp32_tensor=test_tensor, bitwidth=bitwidth)\n",
    "# pdb.set_trace()\n",
    "    num_unique_values_after_quantization = test_tensor.unique().numel()\n",
    "    \n",
    "    print(f'    target bitwidth: {bitwidth} bits')\n",
    "    print(f'        num unique values before k-means quantization: {num_unique_values_before_quantization}')\n",
    "    print(f'        num unique values after  k-means quantization: {num_unique_values_after_quantization}')\n",
    "    assert num_unique_values_after_quantization == min((1 << bitwidth), num_unique_values_before_quantization)\n",
    "    \n",
    "    plot_matrix(test_tensor, ax_right, f'{bitwidth}-bit k-means quantized tensor', \\\n",
    "                    cmap='tab20c')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means quantization on FP32 model\n",
    "\n",
    "In the class `KMeansQuantizer` constructed in the code below, we must record `centroids` and `labels` so that `codebooks` can be applied or updated when the model weights change.\n",
    "\n",
    "``````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import parameter\n",
    "class KMeansQuantizer:\n",
    "    def __init__(self, model : nn.Module, bitwidth=4):\n",
    "        self.codebook = self.quantize(model, bitwidth)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply(self, model, update_centroids):\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in self.codebook:\n",
    "                if update_centroids:\n",
    "                    self.update_codebook(param, codebook=self.codebook[name])\n",
    "                self.codebook[name] = k_means_quantize(\n",
    "                    param, codebook=self.codebook[name])\n",
    "                \n",
    "    def update_codebook(self,fp32_tensor: torch.Tensor, codebook: Codebook):\n",
    "        \"\"\"\n",
    "        update the centroids in the codebook using updated fp32_tensor\n",
    "        :param fp32_tensor: [torch.(cuda.)Tensor]\n",
    "        :param codebook: [Codebook] (the cluster centroids, the cluster label tensor)\n",
    "        \"\"\"\n",
    "        n_clusters = codebook.centroids.numel()\n",
    "        fp32_tensor = fp32_tensor.view(-1)\n",
    "        for k in range(n_clusters):\n",
    "            cluster_points = fp32_tensor[codebook.labels == k]\n",
    "            if cluster_points.numel() > 0:\n",
    "                codebook.centroids[k] = cluster_points.mean()\n",
    "                \n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def quantize(model: nn.Module, bitwidth=4):\n",
    "        codebook = dict()\n",
    "        if isinstance(bitwidth, dict):\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in bitwidth:\n",
    "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth[name])\n",
    "        else:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.dim() > 1:\n",
    "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth)\n",
    "        return codebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at the accuracy and size of the quantized model under different bitwidths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that the storage for codebooks is ignored when calculating the model size.\n",
      "k-means quantizing model into 8 bits\n",
      "    8-bit k-means quantized model has size=0.04 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8-bit k-means quantized model has accuracy=92.54%\n",
      "k-means quantizing model into 4 bits\n",
      "    4-bit k-means quantized model has size=0.02 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4-bit k-means quantized model has accuracy=87.95%\n",
      "k-means quantizing model into 2 bits\n",
      "    2-bit k-means quantized model has size=0.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2-bit k-means quantized model has accuracy=75.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print('Note that the storage for codebooks is ignored when calculating the model size.')\n",
    "quantizers = dict()\n",
    "for bitwidth in [8, 4, 2]:\n",
    "    print(f'k-means quantizing model into {bitwidth} bits')\n",
    "    quantizer = KMeansQuantizer(model, bitwidth)\n",
    "    quantized_model_size = get_model_size(model, bitwidth)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
    "    quantized_model_accuracy = evaluate(model, test_loader)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
    "    quantizers[bitwidth] = quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train kmeans quantized model\n",
    "You can see that the accuracy of the quantized model in the previous step has dropped significantly, so we must perform quantization-aware training to restore the accuracy.\n",
    "\n",
    "The gradient update formula for centroids is as follows:\n",
    "\n",
    "> $\\frac{\\partial \\mathcal{L} }{\\partial C_k} = \\sum_{j} \\frac{\\partial \\mathcal{L} }{\\partial W_{j}} \\frac{\\partial W_{j} }{\\partial C_k} = \\sum_{j} \\frac{\\partial \\mathcal{L} }{\\partial W_{j}} \\mathbf{1}(I_{j}=k)$\n",
    "\n",
    "$\\mathcal{L}$ is the loss, $C_k$ is the *k*th centroids, and $I_{j}$ is the label of the weight $W_{j}$. $\\mathbf{1}()$ is a function to find the corresponding label, i.e., $I_{j}==k$.\n",
    "\n",
    "We update centroids using the following formula:\n",
    "\n",
    "> $C_k = \\frac{\\sum_{j}W_{j}\\mathbf{1}(I_{j}=k)}{\\sum_{j}\\mathbf{1}(I_{j}=k)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means quantizing model into 8 bits\n",
      "    8-bit k-means quantized model has size=0.04 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8-bit k-means quantized model has accuracy=96.13% before quantization-aware training \n",
      "        Quantization-aware training due to accuracy drop=1.86% is larger than threshold=0.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 97.77% / Best Accuracy: 97.77%\n",
      "k-means quantizing model into 4 bits\n",
      "    4-bit k-means quantized model has size=0.02 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4-bit k-means quantized model has accuracy=96.70% before quantization-aware training \n",
      "        Quantization-aware training due to accuracy drop=1.29% is larger than threshold=0.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 97.14% / Best Accuracy: 97.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 1 Accuracy 97.28% / Best Accuracy: 97.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 2 Accuracy 97.35% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 3 Accuracy 97.28% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 4 Accuracy 97.28% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 5 Accuracy 97.30% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 6 Accuracy 97.17% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 7 Accuracy 97.01% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 8 Accuracy 97.34% / Best Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 9 Accuracy 97.26% / Best Accuracy: 97.35%\n",
      "k-means quantizing model into 2 bits\n",
      "    2-bit k-means quantized model has size=0.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2-bit k-means quantized model has accuracy=94.89% before quantization-aware training \n",
      "        Quantization-aware training due to accuracy drop=3.10% is larger than threshold=0.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 95.85% / Best Accuracy: 95.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 1 Accuracy 95.84% / Best Accuracy: 95.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 2 Accuracy 96.13% / Best Accuracy: 96.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 3 Accuracy 96.26% / Best Accuracy: 96.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 4 Accuracy 96.25% / Best Accuracy: 96.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 5 Accuracy 96.13% / Best Accuracy: 96.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 6 Accuracy 96.35% / Best Accuracy: 96.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 7 Accuracy 96.29% / Best Accuracy: 96.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 8 Accuracy 96.37% / Best Accuracy: 96.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 9 Accuracy 96.39% / Best Accuracy: 96.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "accuracy_drop_threshold = 0.5\n",
    "quantizers_before_finetune = copy.deepcopy(quantizers)\n",
    "quantizers_after_finetune = quantizers\n",
    "\n",
    "for bitwidth in [8, 4, 2]:\n",
    "    quantizer = quantizers[bitwidth]\n",
    "    print(f'k-means quantizing model into {bitwidth} bits')\n",
    "    quantizer.apply(model, update_centroids=False)\n",
    "    quantized_model_size = get_model_size(model, bitwidth)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
    "    quantized_model_accuracy = evaluate(model, test_loader)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}% before quantization-aware training \")\n",
    "    accuracy_drop = fp32_model_accuracy - quantized_model_accuracy\n",
    "    if accuracy_drop > accuracy_drop_threshold:\n",
    "        print(f\"        Quantization-aware training due to accuracy drop={accuracy_drop:.2f}% is larger than threshold={accuracy_drop_threshold:.2f}%\")\n",
    "        num_finetune_epochs = 10\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        best_accuracy = 0\n",
    "        epoch = num_finetune_epochs\n",
    "        while accuracy_drop > accuracy_drop_threshold and epoch > 0:\n",
    "            train(model, train_loader, criterion, optimizer, scheduler,\n",
    "                  callbacks=[lambda: quantizer.apply(model, update_centroids=True)])\n",
    "            model_accuracy = evaluate(model, test_loader)\n",
    "            is_best = model_accuracy > best_accuracy\n",
    "            best_accuracy = max(model_accuracy, best_accuracy)\n",
    "            print(f'        Epoch {num_finetune_epochs-epoch} Accuracy {model_accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "            accuracy_drop = fp32_model_accuracy - best_accuracy\n",
    "            epoch -= 1\n",
    "    else:\n",
    "        print(f\"        No need for quantization-aware training since accuracy drop={accuracy_drop:.2f}% is smaller than threshold={accuracy_drop_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
