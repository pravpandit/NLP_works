# Chapter 1 Introduction

Welcome to the **Prompt Engineering for Developers** section, which is based on **Andrew Ng's "Prompt Engineering for Developer" course**. The "Prompt Engineering for Developer" course is taught by **Andrew Ng** and **Isa Fulford**, a member of the OpenAI technical team. Isa has developed the popular ChatGPT retrieval plugin and has made great contributions to teaching the application of LLM (Large Language Model) technology in products. She also participated in writing the OpenAI cookbook that teaches people to use prompts. Through the study of this module, we hope to share with you the best practices and techniques for developing LLM applications using prompts.

There are many materials on the Internet about prompt design (we will keep this term in this tutorial), such as articles like "30 prompts everyone has to know", which mainly focus on **ChatGPT's web interface**, which many people use to perform specific, usually one-time tasks. But we think that for developers, **Large Language Model (LLM) is the ability to quickly build software applications through API calls. In fact, we learned that the team at AI Fund, DeepLearning.AI's sister company, has been working with many startups to apply these technologies to many applications. It is exciting to see that the LLM API allows developers to build applications very quickly.

In this module, we will share with readers various tips and best practices to improve the application of large language models. The book covers a wide range of typical application scenarios of language models, including software development prompt word design, text summarization, reasoning, transformation, expansion, and building chatbots. We sincerely hope that this course will inspire readers' imagination and develop better language model applications.

As LLM develops, it can be roughly divided into two types, which will be called **Basic LLM** and **Instruction Tuned LLM**. **Basic LLM** is a model that is trained to predict the next word based on text training data. It is usually trained on a large amount of data from the Internet and other sources to determine the most likely word that will appear next. For example, if you use "Once upon a time, there was a unicorn" as the prompt, the base LLM may continue to predict "She lived with her unicorn friend in a magical forest." However, if you use "What is the capital of France?" as the prompt, the base LLM may continue to predict "She lived with her unicorn friend in a magical forest."mpt, the basic LLM may predict the answer as "What is the largest city in France? What is the population of France?" based on an article on the Internet, because the article on the Internet is likely to be a list of question-and-answer questions about the country of France.

Unlike basic language models, **instruction fine-tuning LLM** can better understand and follow instructions through special training. For example, when asked "What is the capital of France?", this type of model is likely to directly answer "The capital of France is Paris". The training of instruction fine-tuning LLM is usually based on pre-trained language models. First, **pre-training** is performed on large-scale text data to master the basic laws of language. On this basis, further training and **fine-tuning** are carried out, with the input being instructions and the output being the correct response to these instructions. Sometimes **RLHF (reinforcement learning from human feedback)** technology is also used to further enhance the model's ability to follow instructions based on human feedback on the model output. Through this controlled training process. Instruction fine-tuning LLM can generate outputs that are highly sensitive to instructions, safer and more reliable, and less irrelevant and damaging content. Therefore. Many real-world applications have already moved to using these large language models.

Therefore, this course will focus on best practices for fine-tuning LLMs for instructions, and we recommend that you use them for most use cases.When fine-tuning your LLM with instructions, you can think of it as giving instructions to another person (assuming they are smart but don't know the specific details of your task). So when an LLM doesn't work properly, it's sometimes because the instructions aren't clear enough. For example, if you want to ask "Please write something about Alan Turing for me," it might be helpful to make it clear that you want the text to focus on his scientific work, his personal life, his historical role, or something else. You can also specify the tone of the answer to better suit your needs, with options such as *writing like a professional journalist* or *writing an essay to a friend*.

If you think of the LLM as a new college graduate asking them to complete the task, you can even specify in advance which text fragments they should read to write about Alan Turing, which can help the new graduate complete the task better. The next chapter of this book will elaborate on two key principles of prompt design: **clarity** and **giving enough time to think**.