{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e778b7",
   "metadata": {},
   "source": [
    "# Chapter 3 Embeddings\n",
    "\n",
    "In this chapter, we will learn about Embeddings. Embeddings can be understood as a vector representation of text that is easier for computers to process, and are usually used to convert discrete, high-dimensional data representations (such as words, sentences, or documents) into continuous, low-dimensional vector representations.\n",
    "\n",
    "The purpose of Embeddings is to capture the semantic and grammatical relationships between data so that similar data is closer in the embedding space. For example, in natural language processing, Word Embeddings can be used to map words to a continuous vector space so that words with similar meanings are closer in the embedding space. This feature also makes them one of the most important components in LLM (Large Language Model).\n",
    "\n",
    "In this chapter, we need to use Cohere's API key.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [I. Environment Configuration](#I.)\n",
    "\n",
    "- [II. Word Embeddings](#II.)\n",
    "\n",
    "- [2.1 Understanding the Concept of Embeddings](#2.1)\n",
    "\n",
    "- [2.2 Implementing Word Embeddings](#2.2)\n",
    "\n",
    "- [III. Sentence Embeddings](#III.)\n",
    "\n",
    "- [3.1 Understanding the Concept of Sentence Embeddings](#3.1)\n",
    "\n",
    "- [3.2Implementing sentence embeddings](#3.2)\n",
    "\n",
    "- [IV. Articles Embeddings](#IV.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30b4c0",
   "metadata": {},
   "source": [
    "## 1. Environment Configuration <a id=\"1.\"></a>\n",
    "\n",
    "Let's first prepare some Python libraries and APIs that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cohere umap-learn altair datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68949b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code can help us load the API we need\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # 读取本地 .env 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bf0c1",
   "metadata": {},
   "source": [
    "We need to import the Cohere library and create a Cohere client using the API key.\n",
    "\n",
    "The Cohere library is a library that contains functions for calling large language models, which can be called through API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(os.environ['COHERE_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c18f5",
   "metadata": {},
   "source": [
    "In addition, we also need to import the Pandas library, which can be used for data analysis and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0e8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da3e10",
   "metadata": {},
   "source": [
    "## 2. Word Embeddings\n",
    "\n",
    "### 2.1 Understanding the concept of embeddings\n",
    "\n",
    "Let's first learn what Embeddings are.\n",
    "\n",
    "Here, we have a grid with horizontal and vertical axes and coordinate values, and we can see that a bunch of words are located in this grid.\n",
    "If you want to put the words in the right place, where would you put the word \"apple\" (translated as \"apple\")?\n",
    "\n",
    "![Alt ​​text](images/3-1.png)\n",
    "\n",
    "As you can see in this grid, similar words are grouped together.\n",
    "So in the upper left, there are footballs, basketballs, and table tennis balls, in the lower left, there are houses, buildings, and castles, in the lower right, there are vehicles such as bicycles and cars, and in the upper right, there are fruits.\n",
    "Therefore, apple will be classified as the fruit in the upper right.\n",
    "Then, we associate each word in the table with the coordinate axis. Here, the coordinate of apple is (5, 5).\n",
    "\n",
    "This is a kind of Embeddings, which maps each word to a vector consisting of two values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646832bd",
   "metadata": {},
   "source": [
    "Generally speaking, Embeddings will map words to more values. We will have as many words as possible, and in order to represent each word, the Embeddings actually used can map a word to hundreds or even thousands of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3859edc",
   "metadata": {},
   "source": [
    "### 2.2 Implementing word embedding <a id=\"2.2\"></a>\n",
    "\n",
    "We will use a very small data table. It contains three words: joy, happiness, and potato. We create it with Pandas as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6ddfdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "0        joy\n",
       "1  happiness\n",
       "2     potato"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_words = pd.DataFrame({'text':\n",
    "  [\n",
    "      'joy',\n",
    "      'happiness',\n",
    "      'potato'\n",
    "  ]})\n",
    "\n",
    "three_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf3135d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>欢乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>快乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>马铃薯</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text\n",
       "0   欢乐\n",
       "1   快乐\n",
       "2  马铃薯"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chinese version\n",
    "three_words = pd.DataFrame({'text':\n",
    "  [\n",
    "      '欢乐',\n",
    "      '快乐',\n",
    "      '马铃薯'\n",
    "  ]})\n",
    "\n",
    "three_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063208e1",
   "metadata": {},
   "source": [
    "Next, we create embeddings for these three words.\n",
    "We use the embed function from the Cohere library to create these embeddings.\n",
    "The embed function takes a few inputs. The first input is the dataset \"three_words\" that we want to embed, and we also need to specify the column to be used as \"text\", and the model to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd461b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_words_emb = co.embed(texts=list(three_words['text']),\n",
    "                           model='embed-english-v2.0').embeddings  # 英文版本用英文嵌入模型 embed-english-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ada8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese version\n",
    "three_words_emb = co.embed(texts=list(three_words['text']),\n",
    "                           model='embed-multilingual-v2.0').embeddings  # 中文版本用多语言嵌入模型 embed-multilingual-v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c14fc",
   "metadata": {},
   "source": [
    "Now let's look at the embeddings associated with each word. We call the embedding associated with the word \"joy\" \"word_1\", which can be obtained by looking at the first row of \"three_words_emb\". We do the same for \"word_2\" and \"word_3\". They are the embeddings corresponding to the words \"happiness\" and \"potato\".\n",
    "\n",
    "We can print the first 10 values ​​of the embedding associated with the word \"joy\", that is, the first ten values ​​in \"word_1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074dc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1 = three_words_emb[0]\n",
    "word_2 = three_words_emb[1]\n",
    "word_3 = three_words_emb[2]\n",
    "\n",
    "print(word_1[:10])\n",
    "# Note: The output results below are for the English version. If it is the Chinese version, it will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf4586",
   "metadata": {},
   "source": [
    "[2.3203125,\n",
    "-0.18334961,\n",
    "-0.578125,\n",
    "-0.7314453,\n",
    "-2.2050781,\n",
    "-2.59375,\n",
    "0.35205078,\n",
    "-1.6220703,\n",
    "0.27954102,\n",
    "0.3083496]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45febbc8",
   "metadata": {},
   "source": [
    "## 3. Sentence Embeddings <a id=\"三、\"></a>\n",
    "\n",
    "### 3.1 Understand the concept of sentence embeddings <a id=\"3.1\"></a>\n",
    "\n",
    "Embeddings can be used not only for words, but also for longer text snippets. In fact, it can be a very long text snippet.\n",
    "\n",
    "![Alt ​​text](images/3-2.png)\n",
    "\n",
    "In this example, we have some sentence embeddings.\n",
    "\n",
    "Now these sentences are converted into a vector or a list of values.\n",
    "\n",
    "Notice that the first sentence is \"hello, how are you?\" and the last sentence is \"Hi, how's it going?\".\n",
    "\n",
    "They don't have the same words, but their meanings are very similar, so Embeddings will map them to some very close values.\n",
    "\n",
    "### 3.2 Implement sentence embeddings <a id=\"3.2\"></a>\n",
    "\n",
    "Prepare a small dataset with multiple sentences. As you can see, this dataset has eight sentences, and they appear in pairs. Each sentence is the answer to the previous one. For example, the answer to \"What color is the sky?\" is \"The sky is blue\" and the answer to \"What is an apple?\" is \"An appleis a fruit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eddd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing eight sentences\n",
    "sentences = pd.DataFrame({'text':\n",
    "  [\n",
    "   'Where is the world cup?',  # 句子1: 世界杯在哪里？\n",
    "   'The world cup is in Qatar',  # 句子2: 世界杯在卡塔尔。\n",
    "   'What color is the sky?',  # 句子3: 天空是什么颜色的？\n",
    "   'The sky is blue',  # 句子4: 天空是蓝色的。\n",
    "   'Where does the bear live?',  # 句子5: 熊住在哪里？\n",
    "   'The bear lives in the woods',  # 句子6: 熊住在森林里。\n",
    "   'What is an apple?',  # 句子7: 苹果是什么？\n",
    "   'An apple is a fruit',  # 句子8: 苹果是一种水果。\n",
    "  ]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese version\n",
    "sentences = pd.DataFrame({'text':\n",
    "  [\n",
    "   '世界杯在哪里？',\n",
    "   '世界杯在卡塔尔', \n",
    "   '天空是什么颜色的?', \n",
    "   '天空是蓝色的', \n",
    "   '熊住在哪里？',  \n",
    "   '熊住在森林里', \n",
    "   '苹果是什么?',  \n",
    "   '苹果是一种水果',  \n",
    "  ]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e094fe5f",
   "metadata": {},
   "source": [
    "Now, still using the embed function from the Cohere library, we convert all these sentences into Embeddings and observe which sentences are close or far from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ece326",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = co.embed(texts=list(sentences['text']),\n",
    "               model='embed-english-v2.0').embeddings  # 英文版本用英文嵌入模型 embed-english-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26903d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese version\n",
    "emb = co.embed(texts=list(sentences['text']),\n",
    "               model='embed-multilingual-v2.0').embeddings  # 中文版本用多语言嵌入模型 embed-multilingual-v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f712d9",
   "metadata": {},
   "source": [
    "Let's look at the first 3 values ​​of the embedding for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in emb:\n",
    "    print(e[:3])\n",
    "# Note: The output results below are for the English version. If it is the Chinese version, it will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abc3d2",
   "metadata": {},
   "source": [
    "[0.27319336, -0.37768555, -1.0273438]\n",
    "\n",
    "[0.49804688, 1.2236328, 0.4074707]\n",
    "\n",
    "[-0.23571777, -0.9375, 0.9614258]\n",
    "\n",
    "[0.08300781, -0.32080078, 0.9272461]\n",
    "\n",
    "[0.49780273, -0.35058594, -1.6171875]\n",
    "\n",
    "[1.2294922, -1.3779297, -1.8378906]\n",
    "\n",
    "[0.15686035, -0.92041016, 1.5996094]\n",
    "\n",
    "[1.0761719, -0.7211914, 0.9296875]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45033130",
   "metadata": {},
   "source": [
    "Let’s take a look at how many values ​​each sentence’s Embeddings has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(emb[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb1ec2",
   "metadata": {},
   "source": [
    "In this particular case, the answer is 4096, but different embeddings will have different lengths.\n",
    "\n",
    "Let’s visualize the embeddings for this dataset.\n",
    "We call the utils library function called umap_plot, which calls the umap and altair packages and generates the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import umap_plot\n",
    "# Generate a chart using the umap_plot function\n",
    "chart = umap_plot(sentences, emb)\n",
    "# Call the interactive method to display an interactive chart\n",
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2cdd3",
   "metadata": {},
   "source": [
    "![Alt ​​text](images/3-3.png)\n",
    "\n",
    "This figure shows eight points, each of which represents a sentence in our dataset. Placing the mouse on a point will show which sentence the point represents.\n",
    "\n",
    "We observed that two sentences with similar meanings are very close to each other, such as 'Where does the bear live?' and 'The bear lives in the the woods'.\n",
    "\n",
    "So we can conclude that Embeddings will place points with similar meanings close to each other and points with large differences in meanings far away from each other.\n",
    "Usually, the sentence that is most similar to a question is its specific answer.\n",
    "Therefore, we can find the answer to the question by searching for the sentence closest to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c8b01",
   "metadata": {},
   "source": [
    "## IV. Document Embeddings <a id=\"IV. \"></a>\n",
    "\n",
    "Now that you know how to embed a small dataset of eight sentences, let's work on a large dataset.\n",
    "\n",
    "We will use a large dataset of Wikipedia articles.\n",
    "It has 2000 articles with titles, text of the first paragraph, and embeddings of the first paragraph.\n",
    "Let's load the following dataset with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90769a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wiki_articles = pd.read_pickle('wikipedia.pkl')\n",
    "wiki_articles[['title','text','emb']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29abd4a",
   "metadata": {},
   "source": [
    "![Alt ​​text](images/3-4.png)\n",
    "\n",
    "We will import the Numpy library and a function that will help us visualize this graph, which is very similar to the previous graph.\n",
    "We will reduce it to two dimensions so that we can see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cde2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import umap_plot_big\n",
    "\n",
    "# Get data for the 'title' and 'text' columns from wiki_articles\n",
    "articles = wiki_articles[['title', 'text']]\n",
    "\n",
    "# Get the data of the 'emb' column from wiki_articles and convert it to a numpy array\n",
    "embeds = np.array([d for d in wiki_articles['emb']])\n",
    "\n",
    "# Generate a chart using the umap_plot_big function\n",
    "chart = umap_plot_big(articles, embeds)\n",
    "\n",
    "# Call the interactive method to display an interactive chart\n",
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e3514",
   "metadata": {},
   "source": [
    "Put the mouse on a point in the graph to display the content of the article. You can see that similar articles are located in similar locations.\n",
    "\n",
    "![Alt ​​text](images/3-5.png)\n",
    "\n",
    "That’s all about Embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
