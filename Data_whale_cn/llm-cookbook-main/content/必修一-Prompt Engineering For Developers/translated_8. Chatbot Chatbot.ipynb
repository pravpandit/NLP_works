{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9183228-0ba6-4af9-8430-649e28868253",
   "metadata": {
    "id": "JMXGlIvAwn30"
   },
   "source": [
    "# Chapter 8 Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164d820",
   "metadata": {},
   "source": [
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#一引言\" data-toc-modified-id=\"一、引言\">一、引言</a></span></li>\n",
    "<li>\n",
    "<span><a href=\"#二性的与理解背景建\" data-toc-modified-id=\"二、认同內建\">二、认同內建</a></span></li><li>\n",
    "<span><a href=\"#三訂餐机器人\" data-toc-modified-id=\"三、訂餐机器人\">三、訂餐机器人</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#31-创建json摘要\" data-toc-modified-id=\"3.1创建json摘要\">3.1创建json摘要</a></span></li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdc2c9",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "One of the exciting things about using a large language model is that we can use it to build a customized chatbot with very little effort. In this section, we will explore how to leverage chat to have extended conversations with a personalized (or specialized for a specific task or behavior) chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa0d9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "# Import third-party libraries\n",
    "\n",
    "openai.api_key = \"sk-...\"\n",
    "# Set API_KEY, please replace it with your own API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fae355",
   "metadata": {},
   "source": [
    "Chat models like ChatGPT are actually assembled to take a series of messages as input and return a model-generated message as output. This chat format was originally designed to facilitate multi-turn conversations, but we know from previous studies that it is also useful for **single-turn tasks** that do not involve any conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78344a7e",
   "metadata": {},
   "source": [
    "## 2. Identity and context building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b885b",
   "metadata": {},
   "source": [
    "Next, we'll define two helper functions.\n",
    "\n",
    "The first method has been with you for the entire tutorial, ```get_completion``` , and it works for a single turn. We put the prompt into some sort of user message dialog. The other is called ```get_completion_from_messages``` , and it takes a list of messages. These messages can come from a number of different roles, which we'll describe.\n",
    "\n",
    "In the first message, we send a system message as the system, which provides an overall indication. System messages help set up the assistant's behavior and role, and serve as high-level indications for the conversation. You can think of it as whispering in the assistant's ear, guiding its response, and the user won't notice the system message. So as a user, if you've ever used ChatGPT, you may have never known what ChatGPT's system messages were, and that's intentional. The benefit of system messages is that they provide a way for developers to guide the assistant and direct its response without making the request itself part of the conversation.\n",
    "\n",
    "In the ChatGPT web interface, your messages are called user messages, and ChatGPT's messages are called assistant messages. But when building a chatbot, after sending a system message, your role can be used only as a user.user; it can also alternate between user and assistant, providing conversation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5308d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # 控制模型输出的随机程度\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # 控制模型输出的随机程度\n",
    "    )\n",
    "# print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caaa5b",
   "metadata": {},
   "source": [
    "Now let's try using these messages in a conversation. We'll use the function above to get the responses from these messages, and at the same time, use a higher temperature (higher temperatures generate more diversity, more on this in Chapter 7).\n",
    "\n",
    "The system message says, You are an assistant that speaks like Shakespeare. This is how we describe to the assistant **how it should behave**. Then, the first user message is *Tell me a joke*. The next response given as the assistant is *Why did the chicken cross the road? * The last user message sent is *I don't know*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee681b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da45ea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get to the other side, fair sir.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b0e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese\n",
    "messages =  [  \n",
    "{'role':'system', 'content':'你是一个像莎士比亚一样说话的助手。'},    \n",
    "{'role':'user', 'content':'给我讲个笑话'},   \n",
    "{'role':'assistant', 'content':'鸡为什么过马路'},   \n",
    "{'role':'user', 'content':'我不知道'}  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f80283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因为它要去找“母鸡”。哈哈哈！（注：此为英文双关语，\"chicken\"是鸡的意思，也是胆小的意思；\"cross the road\"是过马路的意思，也是“破坏规则”的意思。）\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e5b83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f51a7e0",
   "metadata": {},
   "source": [
    "(Note: In the above example, due to the selection of temperature = 1, the model's answers will be more random and different (some of them are very creative). Here is another answer:\n",
    "\n",
    "Let me answer your question with a Shakespearean poem:\n",
    "\n",
    "When the chicken's heart wants to move forward,\n",
    "the road is its choice.\n",
    "Driving slowly and the sky is clear,\n",
    "the horn blows and the crisscrosses.\n",
    "\n",
    "Ask it where to go?\n",
    "Because there is no sign on the road,\n",
    "but the chicken leaps forward,\n",
    "and its decision does not need to hesitate.\n",
    "\n",
    "The chicken's wisdom is indescribable,\n",
    "the road is lonely like black lacquer.\n",
    "But its courage is admirable,\n",
    "bravely moving forward without retreat.\n",
    "\n",
    "So why does the chicken cross the road?\n",
    "It endures the distress of the noisy traffic.\n",
    "Because of its roar, it leaps boldly,\n",
    "and creates a boastful mural.\n",
    "\n",
    "So the beauty of the joke,\n",
    "accompanied by the chicken's courage overflowing.\n",
    "Laughing about life without fear of the road,\n",
    "with wisdom and courage, it shows its beauty.\n",
    "\n",
    "I hope this Shakespearean answer will bring you some joy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fd298",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f76bedb",
   "metadata": {},
   "source": [
    "Let's look at another example. The assistant's message is *You are a friendly chatbot* and the first user message is *Hi, my name is Isa*. We want to get the first user message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca733f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Isa! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Hi, my name is Isa'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca517ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨，Isa，很高兴见到你！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "messages =  [  \n",
    "{'role':'system', 'content':'你是个友好的聊天机器人。'},    \n",
    "{'role':'user', 'content':'Hi, 我是Isa。'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2010b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e9f96ba",
   "metadata": {},
   "source": [
    "Let's try another example. The system message is, You are a friendly chatbot, and the first user message is, Yes, can you remind me what my name is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae595bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but since we don't have any personal information about you, I don't know your name. Can you please tell me your name?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a606d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱歉，我不知道您的名字，因为我们是虚拟的聊天机器人和现实生活中的人类在不同的世界中。\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "messages =  [  \n",
    "{'role':'system', 'content':'你是个友好的聊天机器人。'},    \n",
    "{'role':'user', 'content':'好，你能提醒我，我的名字是什么吗？'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e4df5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c65d16",
   "metadata": {},
   "source": [
    "As you can see above, the model doesn’t actually know my name.\n",
    "\n",
    "Therefore, each interaction with the language model is independent of the others, which means we must provide all relevant messages for the model to refer to in the current conversation. If we want the model to refer to or “remember” earlier parts of the conversation, we must provide the earlier exchanges in the model’s input. We call this context. Try the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cbb817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Isa.\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},\n",
    "{'role':'user', 'content':'Hi, my name is Isa'},\n",
    "{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n",
    "Is there anything I can help you with today?\"},\n",
    "{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b40fb0",
   "metadata": {},
   "source": [
    "Here is another answer:\n",
    "\n",
    "*Your name is Isa! How could I forget?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6019b1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！您的名字是Isa。\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "messages =  [  \n",
    "{'role':'system', 'content':'你是个友好的聊天机器人。'},\n",
    "{'role':'user', 'content':'Hi, 我是Isa'},\n",
    "{'role':'assistant', 'content': \"Hi Isa! 很高兴认识你。今天有什么可以帮到你的吗?\"},\n",
    "{'role':'user', 'content':'是的，你可以提醒我, 我的名字是什么?'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed90a6",
   "metadata": {},
   "source": [
    "Now that we have given the model context, which is my name mentioned in the previous conversation, we can then ask the same question, which is what is my name. Because the model has all the context it needs, it is able to respond as we saw in the list of messages that were entered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedba66a-58b0-40d4-b9ae-47e79ae22328",
   "metadata": {
    "id": "bBg_MpXeYnTq"
   },
   "source": [
    "## 3. Ordering Robot\n",
    "\n",
    "Now, we build a \"ordering robot\" that automatically collects user information and accepts orders from pizza shops.\n",
    "\n",
    "The following function will collect our user messages so that we can avoid manual input like we just did. This function will collect the Prompt from the user interface we build below, then append it to a list called context (```context```), and use that context every time the model is called. The model's response is also added to the context, so both the user message and the model message are added to the context, and the context gradually becomes longer. In this way, the model has the information it needs to determine what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76749ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b003e",
   "metadata": {},
   "source": [
    "Now we will set up and run this UI to display the order bot. The initial context contains the system message containing the menu and is used on each invocation. The context will continue to grow as the conversation progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f97fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e746f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"} ] # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fff07d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "327b15b7",
   "metadata": {},
   "source": [
    "The running results are interactive, please see the Chinese version below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ea96d",
   "metadata": {},
   "source": [
    "### 3.1 Creating a JSON digest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c9822",
   "metadata": {},
   "source": [
    "Here we also ask the model to create a JSON summary that we can send to the ordering system.\n",
    "\n",
    "So we need to append another system message to the context as another instruction. We say *create a JSON summary of the order just ordered, listing the price of each item, with fields for 1) pizza, including size, 2) list of toppings, 3) list of drinks, 4) list of sides, including size, and finally the total price*. This could also be defined as a user message, not necessarily a system message.\n",
    "\n",
    "Note that we use a lower temperature here because for these types of tasks, we want the output to be relatively predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c840ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a JSON summary of the previous food order:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"pizza\": {\n",
      "    \"type\": \"cheese\",\n",
      "    \"size\": \"large\",\n",
      "    \"toppings\": [\n",
      "      \"mushrooms\"\n",
      "    ],\n",
      "    \"price\": 12.45\n",
      "  },\n",
      "  \"drinks\": [\n",
      "    {\n",
      "      \"type\": \"sprite\",\n",
      "      \"size\": \"medium\",\n",
      "      \"price\": 3.00\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"sprite\",\n",
      "      \"size\": \"medium\",\n",
      "      \"price\": 3.00\n",
      "    }\n",
      "  ],\n",
      "  \"sides\": [],\n",
      "  \"total_price\": 18.45\n",
      "}\n",
      "``` \n",
      "\n",
      "Note: I assumed that the price of the large cheese pizza with mushrooms is $12.45 instead of $12.95, since the customer only ordered one topping.\n"
     ]
    }
   ],
   "source": [
    "messages =  context.copy()\n",
    "messages.append(\n",
    "{'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\\n",
    " The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},    \n",
    ")\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ef90a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 2;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n",
       "    },    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chinese\n",
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [{'role':'system', 'content':\"\"\"\n",
    "你是订餐机器人，为披萨餐厅自动收集订单信息。\n",
    "你要首先问候顾客。然后等待用户回复收集订单信息。收集完信息需确认顾客是否还需要添加其他内容。\n",
    "最后需要询问是否自取或外送，如果是外送，你要询问地址。\n",
    "最后告诉顾客订单总金额，并送上祝福。\n",
    "\n",
    "请确保明确所有选项、附加项和尺寸，以便从菜单中识别出该项唯一的内容。\n",
    "你的回应应该以简短、非常随意和友好的风格呈现。\n",
    "\n",
    "菜单包括：\n",
    "\n",
    "菜品：\n",
    "意式辣香肠披萨（大、中、小） 12.95、10.00、7.00\n",
    "芝士披萨（大、中、小） 10.95、9.25、6.50\n",
    "茄子披萨（大、中、小） 11.95、9.75、6.75\n",
    "薯条（大、小） 4.50、3.50\n",
    "希腊沙拉 7.25\n",
    "\n",
    "配料：\n",
    "奶酪 2.00\n",
    "蘑菇 1.50\n",
    "香肠 3.00\n",
    "加拿大熏肉 3.50\n",
    "AI酱 1.50\n",
    "辣椒 1.00\n",
    "\n",
    "饮料：\n",
    "可乐（大、中、小） 3.00、2.00、1.00\n",
    "雪碧（大、中、小） 3.00、2.00、1.00\n",
    "瓶装水 5.00\n",
    "\"\"\"} ] # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9a8ef58",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1717'>\n",
       "  <div class=\"bk-root\" id=\"e321dfc5-ed71-4c7e-9054-ad25bb0996c1\" data-root-id=\"1717\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"ba214626-f150-41f7-88bd-59aed92ab8b3\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"GridStack1\",\"overrides\":[],\"properties\":[{\"default\":\"warn\",\"kind\":null,\"name\":\"mode\"},{\"default\":null,\"kind\":null,\"name\":\"ncols\"},{\"default\":null,\"kind\":null,\"name\":\"nrows\"},{\"default\":true,\"kind\":null,\"name\":\"allow_resize\"},{\"default\":true,\"kind\":null,\"name\":\"allow_drag\"},{\"default\":[],\"kind\":null,\"name\":\"state\"}]},{\"extends\":null,\"module\":null,\"name\":\"click1\",\"overrides\":[],\"properties\":[{\"default\":\"\",\"kind\":null,\"name\":\"terminal_output\"},{\"default\":\"\",\"kind\":null,\"name\":\"debug_name\"},{\"default\":0,\"kind\":null,\"name\":\"clears\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationAreaBase1\",\"overrides\":[],\"properties\":[{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationArea1\",\"overrides\":[],\"properties\":[{\"default\":[],\"kind\":null,\"name\":\"notifications\"},{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"},{\"default\":[{\"background\":\"#ffc107\",\"icon\":{\"className\":\"fas fa-exclamation-triangle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"warning\"},{\"background\":\"#007bff\",\"icon\":{\"className\":\"fas fa-info-circle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"info\"}],\"kind\":null,\"name\":\"types\"}]},{\"extends\":null,\"module\":null,\"name\":\"Notification\",\"overrides\":[],\"properties\":[{\"default\":null,\"kind\":null,\"name\":\"background\"},{\"default\":3000,\"kind\":null,\"name\":\"duration\"},{\"default\":null,\"kind\":null,\"name\":\"icon\"},{\"default\":\"\",\"kind\":null,\"name\":\"message\"},{\"default\":null,\"kind\":null,\"name\":\"notification_type\"},{\"default\":false,\"kind\":null,\"name\":\"_destroyed\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1720\"}],\"margin\":[0,0,0,0],\"name\":\"Row01094\"},\"id\":\"1719\",\"type\":\"Row\"},{\"attributes\":{\"args\":{\"bidirectional\":false,\"properties\":{\"event:button_click\":\"loading\"},\"source\":{\"id\":\"1720\"},\"target\":{\"id\":\"1721\"}},\"code\":\"\\n    if ('event:button_click'.startsWith('event:')) {\\n      var value = true\\n    } else {\\n      var value = source['event:button_click'];\\n      value = value;\\n    }\\n    if (typeof value !== 'boolean' || source.labels !== ['Loading']) {\\n      value = true\\n    }\\n    var css_classes = target.css_classes.slice()\\n    var loading_css = ['pn-loading', 'arc']\\n    if (value) {\\n      for (var css of loading_css) {\\n        if (!(css in css_classes)) {\\n          css_classes.push(css)\\n        }\\n      }\\n    } else {\\n     for (var css of loading_css) {\\n        var index = css_classes.indexOf(css)\\n        if (index > -1) {\\n          css_classes.splice(index, 1)\\n        }\\n      }\\n    }\\n    target['css_classes'] = css_classes\\n    \",\"tags\":[[5239341456,[null,\"event:button_click\"],[null,\"loading\"]]]},\"id\":\"1729\",\"type\":\"CustomJS\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01103\",\"text\":\"&lt;p&gt;User:&lt;/p&gt;\"},\"id\":\"1724\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"client_comm_id\":\"df72227b43a2413185c677536f738a1c\",\"comm_id\":\"bf7b0dfe31d54807a147c04852dfa441\",\"plot_id\":\"1717\"},\"id\":\"1730\",\"type\":\"panel.models.comm_manager.CommManager\"},{\"attributes\":{\"children\":[{\"id\":\"1722\"}],\"height\":300,\"margin\":[0,0,0,0],\"min_height\":300,\"name\":\"Row01099\"},\"id\":\"1721\",\"type\":\"Row\"},{\"attributes\":{\"icon\":null,\"js_event_callbacks\":{\"button_click\":[{\"id\":\"1729\"}]},\"label\":\"Chat!\",\"margin\":[5,10,5,10],\"subscribed_events\":[\"button_click\"]},\"id\":\"1720\",\"type\":\"Button\"},{\"attributes\":{\"children\":[{\"id\":\"1724\"},{\"id\":\"1725\"}],\"margin\":[0,0,0,0],\"name\":\"Row01105\"},\"id\":\"1723\",\"type\":\"Row\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01106\",\"style\":{\"background-color\":\"#F6F6F6\"},\"text\":\"&lt;p&gt;\\u4f60\\u597d\\uff01\\u6b22\\u8fce\\u6765\\u5230\\u62ab\\u8428\\u9910\\u5385\\uff01\\u8bf7\\u95ee\\u60a8\\u60f3\\u70b9\\u4ec0\\u4e48\\uff1f&lt;/p&gt;\",\"width\":600},\"id\":\"1728\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"children\":[{\"id\":\"1723\"},{\"id\":\"1726\"}],\"margin\":[0,0,0,0],\"name\":\"Column01111\"},\"id\":\"1722\",\"type\":\"Column\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01108\",\"text\":\"&lt;p&gt;Assistant:&lt;/p&gt;\"},\"id\":\"1727\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown01101\",\"width\":600},\"id\":\"1725\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"margin\":[5,10,5,10],\"max_length\":5000,\"placeholder\":\"Enter text here\\u2026\"},\"id\":\"1718\",\"type\":\"TextInput\"},{\"attributes\":{\"children\":[{\"id\":\"1718\"},{\"id\":\"1719\"},{\"id\":\"1721\"}],\"margin\":[0,0,0,0],\"name\":\"Column01113\"},\"id\":\"1717\",\"type\":\"Column\"},{\"attributes\":{\"children\":[{\"id\":\"1727\"},{\"id\":\"1728\"}],\"margin\":[0,0,0,0],\"name\":\"Row01110\"},\"id\":\"1726\",\"type\":\"Row\"}],\"root_ids\":[\"1717\",\"1730\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "    var render_items = [{\"docid\":\"ba214626-f150-41f7-88bd-59aed92ab8b3\",\"root_ids\":[\"1717\"],\"roots\":{\"1717\":\"e321dfc5-ed71-4c7e-9054-ad25bb0996c1\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Column\n",
       "    [0] TextInput(placeholder='Enter text here…')\n",
       "    [1] Row\n",
       "        [0] Button(name='Chat!')\n",
       "    [2] ParamFunction(function, _pane=Column, height=300, loading_indicator=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1717"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96b2a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是上一个食品订单的 JSON 摘要：\n",
      "\n",
      "```\n",
      "{\n",
      "  \"order\": {\n",
      "    \"pizza\": {\n",
      "      \"type\": \"芝士披萨\",\n",
      "      \"size\": \"大\",\n",
      "      \"price\": 10.95\n",
      "    },\n",
      "    \"toppings\": [\n",
      "      {\n",
      "        \"name\": \"蘑菇\",\n",
      "        \"price\": 1.5\n",
      "      }\n",
      "    ],\n",
      "    \"drinks\": [\n",
      "      {\n",
      "        \"name\": \"雪碧\",\n",
      "        \"size\": \"大\",\n",
      "        \"price\": 3\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"雪碧\",\n",
      "        \"size\": \"大\",\n",
      "        \"price\": 3\n",
      "      }\n",
      "    ],\n",
      "    \"sides\": [],\n",
      "    \"total_price\": 18.45\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages =  context.copy()\n",
    "messages.append(\n",
    "{'role':'system', 'content':'创建上一个食品订单的 json 摘要。\\\n",
    "逐项列出每件商品的价格，字段应该是 1) 披萨，包括大小 2) 配料列表 3) 饮料列表，包括大小 4) 配菜列表包括大小 5) 总价'},    \n",
    ")\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018de2cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef17c2b2",
   "metadata": {},
   "source": [
    "Now that we have built our own food ordering chatbot, feel free to customize and modify the system messages to change the chatbot's behavior and make it play different roles and have different knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f688397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f43e62",
   "metadata": {},
   "source": [
    "Appendix: The following figure shows a complete conversation process of the ordering robot:\n",
    "![image.png](../../figures/Chatbot-pizza-cn.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
