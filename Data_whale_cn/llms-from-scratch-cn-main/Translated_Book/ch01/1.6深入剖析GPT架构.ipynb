{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 深入剖析GPT架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本章的前文中，我们提及了GPT类模型、GPT-3和ChatGPT等术语。现在，让我们更详细地探讨一下GPT的一般架构。首先，GPT代表生成式预训练变换器，最初在以下论文中被介绍："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 通过生成式预训练改善语言理解（2018年），作者Radford等人，来自OpenAI, http://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3是这个模型的扩展版本，它拥有更多的参数，并且在更大的数据集上进行了训练。而最初提供在ChatGPT中的模型是通过使用OpenAI的InstructGPT论文中的方法，在大型指令数据集上对GPT-3进行微调创建的，我们将在第7章“通过人类反馈进行微调以遵循指令”中更详细地介绍这一点。正如我们在图1.6中早些时候看到的，这些模型是能胜任文本完成任务的，并且还可以执行其他任务，如拼写纠正、分类或语言翻译。这实际上是非常了不起的，因为GPT模型是在相对简单的下一个词预测任务上进行预训练的，如图1.7所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图1.7 在GPT模型的下一个词预训练任务中，系统通过观察前面的词来学习预测句子中即将出现的词。这种方法帮助模型理解词语和短语在语言中通常是如何组合在一起的，形成了一个可以应用于各种其他任务的基础。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig-1-7](../img/fig-1-7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一个词预测任务是一种自监督学习形式，属于自我标记的一种。这意味着我们不需要为训练数据显式地收集标签，而是可以利用数据本身的结构：我们可以使用句子或文档中的下一个词作为模型应该预测的标签。由于这个下一个词预测任务允许我们“即时”创建标签，就有可能利用大量未标记的文本数据集来训练大型语言模型，正如之前在1.5节“利用大数据集”中所讨论的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与我们在1.4节中介绍的原始变换器架构相比，使用大型语言模型（LLMs）执行不同任务，通用的GPT架构相对简单。本质上，它只是解码器部分而没有编码器，如图1.8所示。由于像GPT这样的解码器风格模型通过一次预测一个词来生成文本，它们被认为是一种自回归模型。自回归模型将其之前的输出作为未来预测的输入。因此，在GPT中，每一个新词都是基于它之前的序列来选择的，这提高了生成文本的连贯性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "像GPT-3这样的架构也比原始的变换器模型要大得多。例如，原始的变换器模型重复了编码器和解码器块六次。GPT-3有96个变换器层，总共有1750亿个参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图1.8 GPT架构仅采用了原始变换器的解码器部分。它被设计为单向的、从左到右的处理方式，这使得它非常适合于文本生成和下一个词预测任务，可以迭代地一次生成一个词。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig-1-8](../img/fig-1-8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3是在2020年推出的，按照深度学习和大型语言模型（LLM）发展的标准，这已经被认为是很久以前的事情了。然而，最近的一些架构，比如Meta的Llama模型，仍然基于相同的基础概念，只是引入了一些小的修改。因此，理解GPT仍然非常重要，本书专注于实现GPT背后的主要架构，同时提供了一些由其他LLM采用的特定调整的指引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，有趣的是，虽然原始的变换器模型是明确为语言翻译设计的，但GPT模型——尽管它们有更大而且更简单的架构，主要目标是下一个词的预测——也能够执行翻译任务。这一能力最初让研究人员感到意外，因为它出现在一个主要针对下一个词预测任务训练的模型中，而这个任务并没有特别指向翻译。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型能够执行它没有被明确训练去执行的任务的能力被称为“涌现现象”。这种能力并不是在训练过程中明确教授的，而是作为模型接触到大量多语言数据和多样化语境的自然结果而出现的。GPT模型能够“学习”语言之间的翻译模式并执行翻译任务，尽管它们并没有特别为此进行训练，这展示了这些大规模生成性语言模型的好处和能力。我们可以不使用不同的模型就执行多样化的任务。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
