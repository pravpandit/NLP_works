{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.7 构建大型语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本章中，我们奠定了理解 LLMs 的基础。在本书的剩余部分，我们将从头开始编写一个 LLM 。我们将以 GPT 背后的基本思想作为蓝图，并按照图1.9中概述的三个阶段来解决这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图 1.9 本书涵盖的构建大型语言模型（LLM）的阶段包括实现LLM架构和数据准备过程、预训练LLM以创建基础模型，以及微调基础模型，使其成为个人助理或文本分类器。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig-1.7-1](../img/fig-1.7-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "首先，我们将了解基本的数据预处理步骤，并编写每个LLM核心的注意力机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，在第二阶段，我们将学习如何编写和预训练一个类似GPT的LLM，这种模型能够生成新文本。我们还将讨论评估LLM的基本原则，这对于开发能力强大的自然语言处理系统至关重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，从头开始预训练一个大型LLM是一项重大的工作，对于类似GPT的模型，计算成本可能需要数千到数百万美元。因此，第二阶段的重点是使用小数据集实施训练，目的是用于教育。此外，本书还将提供加载公开可用模型权重的代码示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，在第三阶段，我们将采用预训练的LLM，并微调它以执行诸如回答查询或分类文本之类的指令——这是许多实际应用和研究中最常见的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "希望您期待着开始这一激动人心的旅程！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
