{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e4e650-e036-4ca1-83a7-806911fdf0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, json, time, types, copy, sys, os\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=200)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d189546c-4d6e-4643-91fb-aab36cfd1935",
   "metadata": {},
   "source": [
    "模型下载地址：https://hf-mirror.com/BlinkDL/rwkv-2-pile-430m/resolve/main/20220615-10803.pth?download=true\n",
    "\n",
    "请修改模型路径\n",
    "例如我的路径是/data1/ckw/20220615-10803\n",
    "如果想使用cuda加速，请参考：https://github.com/BlinkDL/RWKV-v2-RNN-Pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c02901b-63f9-41fd-bf0b-0c28a2ee57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* running on cpu\n"
     ]
    }
   ],
   "source": [
    "RUN_DEVICE = 'cpu'\n",
    "ctx_len = 768\n",
    "n_layer = 24\n",
    "n_embd = 1024\n",
    "\n",
    "MODEL_NAME = '/data1/ckw/20220615-10803' #修改为自己的模型路径\n",
    "\n",
    "vocab_size = 50277\n",
    "VOCAB_NAME = '20B_tokenizer.json'\n",
    "\n",
    "print(f'\\n* running on {RUN_DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ece3b5-1682-4bf0-a4b0-67192230cd47",
   "metadata": {},
   "source": [
    "### What is RWKV?\n",
    "\n",
    "RWKV, short for Receptance Weighted Key Value, is a new neural network architecture that combines the advantages of RNN (recurrent neural network) and Transformer. It is designed to solve the memory and computational complexity problems of Transformer when processing long sequences, while retaining the computational efficiency of RNN in the inference phase. RWKV utilizes a linear attention mechanism, which can be formalized as a Transformer or RNN, thereby achieving parallel computation during training and maintaining constant computational and memory complexity during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5130fdf-306d-404c-ad0b-35ec4bc07e7f",
   "metadata": {},
   "source": [
    "RWKV's ChannelMix implementation combines time mixing and channel mixing operations. Here is a detailed explanation of the code and its corresponding formula:\n",
    "\n",
    "1. **Time Mixing**:\n",
    "Time mixing is implemented through the `time_mix` parameter and the `time_shift` operation. The purpose of this step is to combine the input of the current time step with the input of the previous time step.\n",
    "\n",
    "Formula:\n",
    "\n",
    "\\begin{align*}\n",
    "x' = x \\cdot \\text{time\\_mix} + \\text{time\\_shift}(x) \\cdot (1 - \\text{time\\_mix})\n",
    "\\end{align*}\n",
    "\n",
    "Where `time_shift` operation is a time step shift operation, and `time_mix` is a trainable parameter.\n",
    "\n",
    "3. **Key Generation**:\n",
    "Use a linear layer `self.key` to transform the input `x'` into a key `k`, and then apply the ReLU activation function and the square operation.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "k = \\text{ReLU}(\\text{key}(x'))^2\n",
    "\\end{align*}\n",
    "\n",
    "4. **Value Generation**:\n",
    "Input the key `k` to the value linear layer `self.value` to generate the value `kv`.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "kv = \\text{value}(k)\n",
    "\\end{align*}\n",
    "\n",
    "5. **Receptance Function**:\n",
    "Use a linear layer `self.receptance` to calculate the reception function `r`, and then apply the Sigmoid activation function.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "r = \\sigma(\\text{receptance}(x'))\n",
    "\\end{align*}\n",
    "\n",
    "6. **Final Output**:\n",
    "Multiply the reception function `r` with the value `kv` to generate the final output `rkv`.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "rkv = r \\cdot kv\n",
    "\\end{align*}\n",
    "\n",
    "Combining these steps, the entire ChannelMix calculation process can be expressed by the following formula:\n",
    "\n",
    "\\begin{align*}\n",
    "x' & = x \\cdot \\text{time\\_mix} + \\text{time\\_shift}(x) \\cdot (1 - \\text{time\\_mix}) \\\\\n",
    "k & = \\text{ReLU}(\\text{key}(x'))^2 \\\\\n",
    "kv & = \\text{value}(k) \\\\\n",
    "r & = \\sigma(\\text{receptance}(x')) \\\\\n",
    "\\text{output} & = r \\cdot kv\n",
    "\\end{align*}\n",
    "\n",
    "The above formula explains the details of ChannelMix implementation of RWKV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4599dc46-75c5-4e47-af1f-012bb72954e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV_ChannelMix(nn.Module):\n",
    "    def __init__(self, layer_id):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "\n",
    "        self.time_shift = nn.ZeroPad2d((0,0,1,-1))\n",
    "        self.time_mix = nn.Parameter(torch.ones(1, 1, n_embd))\n",
    "\n",
    "        hidden_sz = 4 * n_embd\n",
    "        self.key = nn.Linear(n_embd, hidden_sz, bias=False)\n",
    "        self.receptance = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.value = nn.Linear(hidden_sz, n_embd, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.time_mix + self.time_shift(x) * (1 - self.time_mix)\n",
    "\n",
    "        k = self.key(x)\n",
    "        k = torch.square(torch.relu(k))\n",
    "        kv = self.value(k)\n",
    "        \n",
    "        rkv = torch.sigmoid(self.receptance(x)) * kv\n",
    "        return rkv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3accc-60a8-4118-97ea-b20abe14b6ad",
   "metadata": {},
   "source": [
    "In the implementation of RWKV, `RWKV_TimeMix` processes the input data through time mixing. The following is the specific implementation and the corresponding formula description:\n",
    "\n",
    "1. **Time Mixing**:\n",
    "Time mixing is achieved through the `time_mix` parameter and the `time_shift` operation. The purpose of this step is to combine the input of the current time step with the input of the previous time step.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "x' = x \\cdot \\text{time\\_mix} + \\text{time\\_shift}(x) \\cdot (1 - \\text{time\\_mix})\n",
    "\\end{align*}\n",
    "\n",
    "2. **Key Generation**:\n",
    "Use a linear layer `self.key` to convert the input `x'` into a key `k`, and then transpose it.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "k = \\text{key}(x')^T\n",
    "\\end{align*}\n",
    "\n",
    "3. **Value generation**:\n",
    "Use a linear layer `self.value` to convert the input `x'` into a value `v`, and then transpose it.Formula:\n",
    "\\begin{align*}\n",
    "v = \\text{value}(x')^T\n",
    "\\end{align*}\n",
    "\n",
    "4. **Receptance Function**:\n",
    "Use a linear layer `self.receptance` to calculate the reception function `r`.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "r = \\text{receptance}(x')\n",
    "\\end{align*}\n",
    "\n",
    "5. **Key-value multiplication**:\n",
    "Multiply the key `k` and the value `v` to get `kv`.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "kv = k \\cdot v\n",
    "\\end{align*}\n",
    "\n",
    "6. **Time weight calculation**:\n",
    "Calculate the time weight `w`, where `self.time_w` is calculated by `time_decay` and `time_curve`.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "\\text{self.time\\_w} &= \\exp(\\text{time\\_decay}) \\cdot \\text{time\\_curve} \\\\\n",
    "w &= \\exp(\\text{self.time\\_w})\n",
    "\\end{align*}\n",
    "\n",
    "7. **Convolution operation**:\n",
    "Use one-dimensional convolution to calculate weighted key and weighted key.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "wkv &= \\text{conv1d}(\\text{ZeroPad2d}(kv), w, \\text{groups}=C) \\\\\n",
    "wk &= \\text{conv1d}(\\text{ZeroPad2d}(k), w, \\text{groups}=C) + 1e-9\n",
    "\\end{align*}\n",
    "\n",
    "8. **Final output**:\n",
    "Multiply the receiving function `r` with the weighted key ratio `wkv / wk`, and pass it through the output linear layer to get the final output `rwkv`.\n",
    "\n",
    "Formula:\n",
    "\\begin{align*}\n",
    "rwkv &= \\sigma(r) \\cdot \\left( \\frac{wkv}{wk} \\right)^T \\\\\n",
    "rwkv &= \\text{output}(rwkv)\n",
    "\\end{align*}\n",
    "\n",
    "Combining these steps, `RThe entire calculation process of WKV_TimeMix` can be expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "x' &= x \\cdot \\text{time\\_mix} + \\text{time\\_shift}(x) \\cdot (1 - \\text{time\\_mix}) \\\\\n",
    "k &= \\text{key}(x')^T \\\\\n",
    "v &= \\text{value}(x')^T \\\\\n",
    "r &= \\text{receptance}(x') \\\\\n",
    "kv &= k \\cdot v \\\\\n",
    "\\text{self.time\\_w} &= \\exp(\\text{time\\_decay}) \\cdot \\text{time\\_curve} \\\\\n",
    "w &= \\exp(\\text{self.time\\_w}) \\\\\n",
    "wkv &= \\text{conv1d}(\\text{ZeroPad2d}(kv), w, \\text{groups}=C) \\\\\n",
    "wk &= \\text{conv1d}(\\text{ZeroPad2d}(k), w, \\text{groups}=C) + 1e-9 \\\\\n",
    "rwkv &= \\sigma(r) \\cdot \\left( \\frac{wkv}{wk} \\right)^T \\\\\n",
    "rwkv &= \\text{output}(rwkv)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bb098-eb18-4365-a69f-349a9d9709f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV_TimeMix(nn.Module):\n",
    "    def __init__(self, layer_id):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        self.time_decay = nn.Parameter(torch.ones(n_embd, 1))\n",
    "        self.time_curve = torch.tensor([-(ctx_len - 2 - i) for i in range(ctx_len-1)]).unsqueeze(0)\n",
    "        self.time_first = nn.Parameter(torch.ones(n_embd, 1) * math.log(0.3))\n",
    "        \n",
    "        self.time_shift = nn.ZeroPad2d((0,0,1,-1))\n",
    "        self.time_mix = nn.Parameter(torch.ones(1,1,n_embd))\n",
    "\n",
    "        self.key = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.value = nn.Linear(n_embd, n_embd, bias=False)\n",
    "        self.receptance = nn.Linear(n_embd, n_embd, bias=False)\n",
    "\n",
    "        self.output = nn.Linear(n_embd, n_embd, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        x = x * self.time_mix + self.time_shift(x) * (1 - self.time_mix)\n",
    "\n",
    "        k = self.key(x).transpose(-1, -2)\n",
    "        v = self.value(x).transpose(-1, -2)\n",
    "        r = self.receptance(x)\n",
    "\n",
    "        k = torch.clamp(k, max=60)\n",
    "        k = torch.exp(k)\n",
    "\n",
    "        kv = k * v\n",
    "\n",
    "        self.time_w = torch.cat([torch.exp(self.time_decay) * self.time_curve.to(self.time_decay.device), self.time_first], dim=-1)\n",
    "        w = torch.exp(self.time_w)\n",
    "        \n",
    "        w = w[:,-T:].unsqueeze(1)\n",
    "        wkv = F.conv1d(nn.ZeroPad2d((T-1, 0, 0, 0))(kv), w, groups=C)\n",
    "        wk = F.conv1d(nn.ZeroPad2d((T-1, 0, 0, 0))(k), w, groups=C) + 1e-9\n",
    "\n",
    "        rwkv = torch.sigmoid(r) * (wkv / wk).transpose(-1, -2)\n",
    "        \n",
    "        rwkv = self.output(rwkv)\n",
    "        return rwkv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3e83c-1fda-498b-92f9-0e98744fd999",
   "metadata": {},
   "source": [
    "### RWKV Block\n",
    "\n",
    "RWKV Block is a basic module that combines TimeMix and ChannelMix operations. Each module in Block (TimeMix and ChannelMix) processes input data through normalization and residual connection to enhance the stability and performance of the model.\n",
    "\n",
    "### Main components and operations\n",
    "\n",
    "1. **LayerNorm**: used to normalize input and enhance the stability of training.\n",
    "\n",
    "- `self.ln1` and `self.ln2` normalize the input before TimeMix and ChannelMix, respectively.\n",
    "\n",
    "2. **TimeMix**: Combine the information of the current time step and the previous time step to capture the time dependency.\n",
    "\n",
    "- `self.att = RWKV_TimeMix(layer_id)` initializes the TimeMix module.\n",
    "\n",
    "3. **ChannelMix**: Mix between different channels to enhance the expressiveness of the model.\n",
    "- `self.ffn = RWKV_ChannelMix(layer_id)` initializes the channel mixing module.\n",
    "\n",
    "4. **Residual connection**: By adding the output of the mixing operation back to the original input, it maintains the information flow and enhances the gradient propagation ability of the model.\n",
    "\n",
    "Through this settingRWKV's Block can efficiently process sequence data, combine time and channel information, and improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2630a3ff-6a8c-49d9-a4d9-05098b424d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, layer_id):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id  # 存储当前层的ID\n",
    "\n",
    "# Define two LayerNorm layers to normalize the input\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "# Define time mixing and channel mixing modules\n",
    "        self.att = RWKV_TimeMix(layer_id)\n",
    "        self.ffn = RWKV_ChannelMix(layer_id)\n",
    "\n",
    "    def forward(self, x):\n",
    "# First, perform LayerNorm normalization on the input\n",
    "        x = self.ln1(x)\n",
    "        \n",
    "# Perform the time blending operation and add the result back to the input via the residual connection\n",
    "        x = x + self.att(x)\n",
    "        \n",
    "# Normalize the input again using LayerNorm\n",
    "        x = self.ln2(x)\n",
    "        \n",
    "# Perform channel mixing and add the result back to the input through the residual connection\n",
    "        x = x + self.ffn(x)\n",
    "        \n",
    "# Return the final output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3d877-9847-450b-8c92-5fd5c19a1811",
   "metadata": {},
   "source": [
    "Next, the main parts of the RWKV model are implemented:\n",
    "\n",
    "1. **Model loading and preprocessing**: The code loads the model weights and preprocesses the time-related weights.\n",
    "2. **LayerNorm**: Layer normalization is implemented in the `LN` method, about the use of LayerNorm.\n",
    "3. **Feedforward network (FF) and self-attention (SA)**: The `FF` method implements the calculation of the feedforward network, and the `SA` method implements the calculation of the self-attention mechanism. These two parts correspond to the detailed calculation of TimeMix and ChannelMix.\n",
    "4. **Running the model**: The `run` method implements the overall operation logic of the model, passes through each layer in turn, and finally outputs the results. That is, the operation and reasoning process of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c04132-b0de-4a8e-9769-2b4619e2e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_buf = {}  # 用于缓存时间相关信息的全局字典\n",
    "\n",
    "class RWKV_RNN():\n",
    "    def __init__(self, MODEL_NAME=MODEL_NAME):\n",
    "        print('\\nloading RWKV-RNN', MODEL_NAME)\n",
    "        self.ctx_len = ctx_len  # 上下文长度\n",
    "        self.n_layer = n_layer  # 网络层数\n",
    "        self.n_embd = n_embd    # 嵌入维度\n",
    "        self.tokenizer = PreTrainedTokenizerFast(tokenizer_file=VOCAB_NAME)  # 初始化分词器\n",
    "\n",
    "        self.w = types.SimpleNamespace()  # 用于存储模型权重的命名空间\n",
    "        \n",
    "# Load model weight file\n",
    "        w = torch.load(MODEL_NAME + '.pth', map_location=torch.device(RUN_DEVICE))\n",
    "\n",
    "# Handling time-dependent weights\n",
    "        for x in w.keys():\n",
    "            if '.time_' in x:\n",
    "                w[x] = w[x].squeeze()  # 压缩维度\n",
    "            if '.time_decay' in x:\n",
    "                w[x] = torch.exp(-torch.exp(w[x]))  # 对时间衰减进行双重指数运算\n",
    "            if '.time_first' in x:\n",
    "                w[x] = torch.exp(w[x])  # 对时间初始值进行指数运算\n",
    "                    \n",
    "# Store weights in namespace\n",
    "            xx = x.split('.')\n",
    "            here = self.w\n",
    "            for i in range(len(xx)):\n",
    "                if xx[i].isdigit():\n",
    "                    ii = int(xx[i])\n",
    "                    if ii not in here:\n",
    "                        here[ii] = types.SimpleNamespace()  # 初始化命名空间\n",
    "                    here = here[ii]\n",
    "                else:\n",
    "                    if i == len(xx) - 1:\n",
    "                        setattr(here, xx[i], w[x])\n",
    "                    elif not hasattr(here, xx[i]):\n",
    "                        if xx[i+1].isdigit():\n",
    "                            setattr(here, xx[i], {})\n",
    "                        else:\n",
    "                            setattr(here, xx[i], types.SimpleNamespace())\n",
    "                    here = getattr(here, xx[i])\n",
    "    \n",
    "        self.clear()  # 初始化缓存\n",
    "    \n",
    "    def clear(self):\n",
    "        self.xx = {}  # 清空缓存\n",
    "        self.aa = {}\n",
    "        self.bb = {}\n",
    "    \n",
    "    def save(self, target):\n",
    "# Deep copy the current state to the target\n",
    "        target.xx = copy.deepcopy(self.xx)\n",
    "        target.aa = copy.deepcopy(self.aa)\n",
    "        target.bb = copy.deepcopy(self.bb)\n",
    "    \n",
    "    def load(self, target):\n",
    "# Deep copy state from target to current instance\n",
    "        self.xx = copy.deepcopy(target.xx)\n",
    "        self.aa = copy.deepcopy(target.aa)\n",
    "        self.bb = copy.deepcopy(target.bb)\n",
    "\n",
    "    def LN(self, xx, w):\n",
    "# Perform LayerNorm normalization\n",
    "        return F.layer_norm(xx, (n_embd,), weight=w.weight, bias=w.bias)\n",
    "\n",
    "    def FF(self, xx, w, name):\n",
    "# Feedforward network calculation\n",
    "        if name not in self.xx:\n",
    "            self.xx[name] = torch.zeros(n_embd, device=RUN_DEVICE)\n",
    "        x = xx * w.time_mix + self.xx[name] * (1 - w.time_mix)  # 混合当前输入和缓存\n",
    "\n",
    "        self.xx[name] = xx  # 更新缓存\n",
    "\n",
    "        r = torch.sigmoid(w.receptance.weight @ x)  # 计算接收向量\n",
    "        k = torch.square(torch.relu(w.key.weight @ x))  # 计算键向量\n",
    "        kv = w.value.weight @ k  # 计算值向量\n",
    "\n",
    "        return r * kv  # 返回前馈网络输出\n",
    "\n",
    "    def SA(self, xx, w, name):\n",
    "# Self-attention calculation\n",
    "        if name not in self.xx:\n",
    "            self.xx[name] = torch.zeros(n_embd, device=RUN_DEVICE)\n",
    "            self.aa[name] = torch.zeros(n_embd, device=RUN_DEVICE)\n",
    "            self.bb[name] = torch.zeros(n_embd, device=RUN_DEVICE)\n",
    "        x = xx * w.time_mix + self.xx[name] * (1 - w.time_mix)  # 混合当前输入和缓存\n",
    "        self.xx[name] = xx  # 更新缓存\n",
    "\n",
    "        r = torch.sigmoid(w.receptance.weight @ x)  # 计算接收向量\n",
    "\n",
    "        k = torch.exp(torch.clamp(w.key.weight @ x, max=60))  # 计算键向量\n",
    "        v = w.value.weight @ x  # 计算值向量\n",
    "        kv = k * v  # 计算键值对\n",
    "\n",
    "        a = self.aa[name] + w.time_first * kv  # 计算新的a值\n",
    "        b = self.bb[name] + w.time_first * k  # 计算新的b值\n",
    "        self.aa[name] = w.time_decay * self.aa[name] + kv  # 更新缓存中的a值\n",
    "        self.bb[name] = w.time_decay * self.bb[name] + k  # 更新缓存中的b值\n",
    "\n",
    "        rwkv = r * a / (b + 1e-9)  # 计算自注意力输出\n",
    "\n",
    "        return w.output.weight @ rwkv  # 返回自注意力输出\n",
    "\n",
    "    def run(self, ctx):\n",
    "# Run the model\n",
    "        w = self.w\n",
    "        x = w.emb.weight[ctx[-1]]  # 获取当前token的嵌入\n",
    "\n",
    "# Go through each layer in turn\n",
    "        for i in range(n_layer):\n",
    "            x = self.LN(x, w.blocks[i].ln1)  # 归一化\n",
    "            x = x + self.SA(x, w.blocks[i].att, f'att.{i}')  # 自注意力计算并残差连接\n",
    "            x = self.LN(x, w.blocks[i].ln2)  # 归一化\n",
    "            x = x + self.FF(x, w.blocks[i].ffn, f'ffn.{i}')  # 前馈网络计算并残差连接\n",
    "\n",
    "        x = self.LN(x, w.ln_out)  # 最后一层归一化\n",
    "\n",
    "        x = w.head.weight @ x  # 计算输出\n",
    "        x = x.tolist()  # 转换为列表\n",
    "\n",
    "        return x  # 返回最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38decbf1-12ee-4a89-b97a-d5e580c10c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "* This is a preview of RWKV-v2-RNN trained on the Pile for only 50B tokens.\n",
      "* It is NOT indicative of the final performance (which requires 300B tokens).\n",
      "******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "******************************************************************************\n",
    "* This is a preview of RWKV-v2-RNN trained on the Pile for only 50B tokens.\n",
    "* It is NOT indicative of the final performance (which requires 300B tokens).\n",
    "******************************************************************************''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e34d05-8296-4d2f-9f45-29912ddde8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit model.py to set CPU / CUDA mode. Runs on CPU by default.\n",
    "\n",
    "TEMPERATURE = 1.0\n",
    "TOP_P = 0.7\n",
    "\n",
    "DEBUG_DEBUG = False\n",
    "LENGTH_OF_EACH = 333\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "context = '\\nDataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence.'\n",
    "\n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a620d9b-e93e-4c6e-b015-99246c1e036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading RWKV-RNN /data1/ckw/20220615-10803\n"
     ]
    }
   ],
   "source": [
    "model = RWKV_RNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546efbe-600b-47de-8873-1174686beaa4",
   "metadata": {},
   "source": [
    "Next, we sample from the given output logits to generate a new token. It implements **temperature adjustment sampling** and **core sampling (Top-p sampling)**. The specific steps are as follows:\n",
    "\n",
    "1. **Softmax conversion**: Convert the logits output by the model to a probability distribution through the softmax function.\n",
    "2. **Sorting and cumulative probability calculation**: Sort the probabilities from high to low and calculate the cumulative probability distribution.\n",
    "3. **Core sampling**:\n",
    "- Calculate the minimum value of the cumulative probability exceeding `top_p` and determine the cutoff value `cutoff`.\n",
    "- Set all probabilities below the cutoff value to 0, thereby retaining the most important `top_p` part of the probability.\n",
    "4. **Temperature adjustment**: If `temperature` is not 1, adjust the probability distribution to make it smoother or sharper.\n",
    "5. **Sampling**: Sample a value from the adjusted probability distribution and return the corresponding index.\n",
    "\n",
    "This method is particularly commonly used in text generation tasks. By adjusting the `temperature` and `top_p` parameters, the diversity and quality of the generated text can be controlled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c528e4-ef2f-4136-9022-5c1fc08b185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_logits(out, temperature=1.0, top_p=None):\n",
    "# Convert the output into a probability distribution (via the softmax function)\n",
    "    probs = F.softmax(torch.tensor(out), dim=-1)\n",
    "    \n",
    "# Sort by probability from high to low\n",
    "    sorted_probs, _ = torch.sort(probs, descending=True)\n",
    "\n",
    "# Calculate the cumulative probability distribution\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1).numpy()\n",
    "    \n",
    "# Calculate the cutoff value (cutoff) based on the cumulative probability and top_p\n",
    "    cutoff = float(sorted_probs[np.argmax(cumulative_probs > top_p)])\n",
    "    \n",
    "# Set the probability below the cutoff value to 0\n",
    "    probs[probs < cutoff] = 0\n",
    "\n",
    "# If temperature is not equal to 1, the probability is adjusted by temperature\n",
    "    if temperature != 1.0:\n",
    "        probs = probs.pow(1.0 / temperature)\n",
    "\n",
    "# Sample a value from the adjusted probability distribution and return it\n",
    "    return torch.multinomial(probs, num_samples=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14581d92-4590-4303-9405-d56f65a3c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence. We want to change the way students learn artificial intelligence. We are very committed to the idea of artificial intelligence. We have already taken part in a joint research project with the European Research Council. This will bring us closer to our goal. We hope that this research project will give us the opportunity to develop a framework for a data-driven approach in artificial intelligence.\n",
      "\n",
      "I.C. Pfeifer\n",
      "\n",
      "Research Fellow\n",
      "\n",
      "Our work in data science and machine learning has a strong connection with the Human Brain Project, an initiative of the University of California at Berkeley. The focus of our work is on the research of language and language learning, with an emphasis on language acquisition. Our research is directed at the development of technology to improve the language acquisition skills of students and their parents.\n",
      "\n",
      "The Joint Data-Science-Technology Partnership between the Joint Data Science-Technology Partnership and the International Research Center for Education and Business in the Humanities and Social Sciences (Institute for Learning and Human-Computer Interaction, LBI, JIU) is a collaboration between the JIU and the University of California at Berkeley, the University of California at Los Angeles, the University of Oxford, and the University of Oxford.\n",
      "\n",
      "In the Humanities and Social Science-Technology Partnership, we have been working with our partners in the Humanities and Social Science-Technology Partnership, the Institute for Learning and Brain Science, the National Science Foundation, the National Science Foundation, and the United States Department of Education on a series of projects focused on the application of artificial intelligence and data mining for educational research.\n",
      "\n",
      "My wife and I have always believed that data\n",
      "----------------------------------------------------------------------\n",
      "DataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence. DataWhalechina’s first project, called DataWidener, was started in 2011 to help undergraduate and graduate students develop their research skills.\n",
      "\n",
      "DataWhalechina.com\n",
      "\n",
      "In 2016, DataWidener joined the AI-enabled Project Checkup. It was set up to investigate the data used in AI projects and to help prevent missteps.\n",
      "\n",
      "The data scientists at DataWidener’s first project checkup are learning how to use artificial intelligence to analyze natural language data and how to understand the problem-solving ability of artificial intelligence.\n",
      "\n",
      "DataWidener’s second project checkup is using artificial intelligence to help students understand the information that they are learning. The AI-powered project checkup helps students understand how to use artificial intelligence to learn.\n",
      "\n",
      "DataWidener’s third project checkup was in 2016. The AI-powered project checkup helps learners understand how to analyze natural language data.\n",
      "\n",
      "DataWidener’s fourth project checkup was in 2016. The AI-powered project checkup helps learners understand how to use natural language data.\n",
      "\n",
      "DataWidener’s fifth project checkup was in 2016. The AI-powered project checkup helps learners understand how to use natural language data.\n",
      "\n",
      "DataWidener’s sixth project checkup was in 2017. The AI-powered project checkup helps learners understand how to use natural language data.\n",
      "\n",
      "The AI-powered project checkup helps learners understand how to use natural language data. The AI-powered project checkup helps learners understand how to use natural language data.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence. The organization focuses on promoting artificial intelligence as a way of learning, as well as on promoting skills that are essential for future job opportunities.\n",
      "\n",
      "DataWhalechina has more than 1.2 million members and reaches more than 50 million members. The company has been listed on the Shanghai Stock Exchange since 2010 and has a market capitalization of $26 billion.\n",
      "\n",
      "The company has invested $2.7 billion in more than 100 projects since 2009. The company also works on various areas such as industry standardization, artificial intelligence and data mining.\n",
      "\n",
      "The company’s focus is to create a learning environment that is better for learning and more productive.\n",
      "\n",
      "DataWhalechina’s AI applications and software are developed and used by over 30,000 teachers, students and learners in China. DataWhalechina has been awarded the “Top 10 Under 50 in China” by the Center for Training in China.\n",
      "\n",
      "DataWhalechina is the only company in China that has created and published AI solutions to solve real-world problems, such as energy efficiency, smart buildings, social media, and the Internet of Things.\n",
      "\n",
      "DataWhalechina is backed by an initial public offering in April. It is scheduled to be listed on the Shanghai Stock Exchange in early 2020.\n",
      "\n",
      "This article was originally published by iPro and was first published by iPro on April 10, 2020.\n",
      "\n",
      "Learn more about iPro at iPro.org.\n",
      "\n",
      "Learn more about datawhalechina at datawhalechina.org.\n",
      "\n",
      "© 2020 iPro. All Rights Reserved.\n",
      "\n",
      "Share\n",
      "----------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "for TRIAL in range(1 if DEBUG_DEBUG else NUM_TRIALS):\n",
    "    ctx = [model.tokenizer.encode(context)][0]\n",
    "    src_len = len(ctx)\n",
    "    print(context, end='')\n",
    "\n",
    "    model.clear()\n",
    "    if TRIAL == 0:\n",
    "        init_state = types.SimpleNamespace()\n",
    "        for i in range(src_len if DEBUG_DEBUG else src_len):\n",
    "            x = ctx[:i+1]\n",
    "            if i == src_len - 1:\n",
    "                init_state.out = model.run(x)\n",
    "            else:\n",
    "                model.run(x)\n",
    "        model.save(init_state)\n",
    "    else:\n",
    "        model.load(init_state)\n",
    "\n",
    "    if DEBUG_DEBUG:\n",
    "        out = init_state.out\n",
    "        print('\\n', np.array(x), '==>', np.array(\n",
    "            out), np.max(out), np.min(out))\n",
    "\n",
    "    for i in range(src_len, src_len + (0 if DEBUG_DEBUG else LENGTH_OF_EACH)):\n",
    "        x = ctx[:i+1]\n",
    "        x = x[-model.ctx_len:]\n",
    "\n",
    "        if i == src_len:\n",
    "            out = copy.deepcopy(init_state.out)\n",
    "        else:\n",
    "            out = model.run(x)\n",
    "\n",
    "        out[0] = -999999999  # disable <|endoftext|>\n",
    "\n",
    "        char = sample_logits(out, temperature=TEMPERATURE, top_p=TOP_P)\n",
    "        char = char.item()\n",
    "        print(model.tokenizer.decode(char), end='', flush=True)\n",
    "\n",
    "        ctx += [char]\n",
    "    print('\\n' + '-' * 70, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37dfc5-71c7-44a5-a4d4-b71534574872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kewei-ai",
   "language": "python",
   "name": "kewei-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
